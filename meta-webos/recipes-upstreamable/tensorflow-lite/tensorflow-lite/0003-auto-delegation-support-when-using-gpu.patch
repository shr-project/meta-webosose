From 8d0276f9baa39188206a9503243709504d7633e8 Mon Sep 17 00:00:00 2001
From: "kijoong.lee" <kijoong.lee@lge.com>
Date: Mon, 13 Jun 2022 18:43:31 +0900
Subject: [PATCH] auto delegation support when using gpu

---
 tensorflow/lite/delegates/gpu/delegate.cc | 23 +++++++++++++++++++++++
 tensorflow/lite/delegates/gpu/delegate.h  |  5 +++++
 2 files changed, 28 insertions(+)

diff --git a/tensorflow/lite/delegates/gpu/delegate.cc b/tensorflow/lite/delegates/gpu/delegate.cc
index 9fdb1a88d12..7a3615a1aca 100644
--- a/tensorflow/lite/delegates/gpu/delegate.cc
+++ b/tensorflow/lite/delegates/gpu/delegate.cc
@@ -103,6 +103,11 @@ class Delegate {
       params.cache_dir = options_.serialization_dir;
       serialization_.reset(new Serialization(params));
     }
+    if (options_.cpu_fallback_percentage < 0) {
+      options_.cpu_fallback_percentage = 0;
+    } else if (options_.cpu_fallback_percentage > 100) {
+      options_.cpu_fallback_percentage = 100;
+    }
   }
 
   TfLiteDelegate* tflite_delegate() { return &delegate_; }
@@ -116,6 +121,7 @@ class Delegate {
   int MaxDelegatedPartitions() const {
     return options_.max_delegated_partitions;
   }
+  int CPUFallbackPercentage() const { return options_.cpu_fallback_percentage; }
   int num_delegate_kernels() const { return num_delegate_kernels_; }
 
  private:
@@ -570,6 +576,22 @@ TfLiteStatus DelegatePrepare(TfLiteContext* context, TfLiteDelegate* delegate) {
   TfLiteIntArray* ops_to_replace =
       GetOpsToReplace(context, gpu_delegate->IsQuantOpsAllowed(),
                       gpu_delegate->MaxDelegatedPartitions(), &excluded_ops);
+  if (gpu_delegate->CPUFallbackPercentage() != 0) {
+    auto partition_size =
+        ops_to_replace->size -
+        ops_to_replace->size * gpu_delegate->CPUFallbackPercentage() / 100;
+    TfLiteIntArray* partitioned_ops_to_replace =
+        TfLiteIntArrayCreate(partition_size);
+    for (int i = 0; i < partition_size; i++) {
+      partitioned_ops_to_replace->data[i] = ops_to_replace->data[i];
+    }
+    TFLITE_LOG_PROD(
+        TFLITE_LOG_INFO,
+        "GPU Load Balancing: %d operations are forced to run on CPU.",
+        ops_to_replace->size * gpu_delegate->CPUFallbackPercentage() / 100);
+    TfLiteIntArrayFree(ops_to_replace);
+    ops_to_replace = partitioned_ops_to_replace;
+  }
   const auto status = context->ReplaceNodeSubsetsWithDelegateKernels(
       context, kRegistration, ops_to_replace, delegate);
   TFLITE_LOG_PROD(TFLITE_LOG_INFO, "Created %d GPU delegate kernels.",
@@ -595,6 +617,7 @@ TfLiteGpuDelegateOptionsV2 TfLiteGpuDelegateOptionsV2Default() {
   options.max_delegated_partitions = 1;
   options.model_token = nullptr;
   options.serialization_dir = nullptr;
+  options.cpu_fallback_percentage = 0;
   return options;
 }
 
diff --git a/tensorflow/lite/delegates/gpu/delegate.h b/tensorflow/lite/delegates/gpu/delegate.h
index 3a1e1811478..3abb0c5ed2f 100644
--- a/tensorflow/lite/delegates/gpu/delegate.h
+++ b/tensorflow/lite/delegates/gpu/delegate.h
@@ -131,6 +131,11 @@ typedef struct {
   // Set to nullptr in TfLiteGpuDelegateOptionsV2Default(), which implies the
   // delegate will not try serialization.
   const char* model_token;
+
+  // A value between 0 and 100, that represents percentage of nodes that are
+  // forced to run on CPU despite it is supported in GPU.
+  // it's set to 0 in TfLiteGpuDelegateOptionsV2Default().
+  int32_t cpu_fallback_percentage;
 } TfLiteGpuDelegateOptionsV2;
 
 // Populates TfLiteGpuDelegateOptionsV2 as follows:
