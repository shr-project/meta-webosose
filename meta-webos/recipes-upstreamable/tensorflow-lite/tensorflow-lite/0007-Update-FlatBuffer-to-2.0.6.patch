From 89336e77dc543a9c816b6e394a75cb791b7a4c6c Mon Sep 17 00:00:00 2001
From: Terry Heo <terryheo@google.com>
Date: Wed, 15 Jun 2022 17:11:02 -0700
Subject: [PATCH] Update FlatBuffer to 2.0.6

- Update build rules.
- Update generated schema headers.
---
 .../configuration/configuration_generated.h   | 1851 +++++++++++++----
 tensorflow/lite/schema/schema_generated.h     |  436 ++--
 .../tools/cmake/modules/flatbuffers.cmake     |    2 +-
 third_party/flatbuffers/build_defs.bzl        |   10 +-
 4 files changed, 1748 insertions(+), 551 deletions(-)

diff --git a/tensorflow/lite/experimental/acceleration/configuration/configuration_generated.h b/tensorflow/lite/experimental/acceleration/configuration/configuration_generated.h
index f66b88a73e4..9d4d2629bf7 100644
--- a/tensorflow/lite/experimental/acceleration/configuration/configuration_generated.h
+++ b/tensorflow/lite/experimental/acceleration/configuration/configuration_generated.h
@@ -15,6 +15,7 @@ limitations under the License.
 // clang-format off
 // automatically generated by the FlatBuffers compiler, do not modify
 
+
 #ifndef FLATBUFFERS_GENERATED_CONFIGURATIONFORGENERATION_TFLITE_H_
 #define FLATBUFFERS_GENERATED_CONFIGURATIONFORGENERATION_TFLITE_H_
 
@@ -23,65 +24,101 @@ limitations under the License.
 namespace tflite {
 
 struct ComputeSettings;
+struct ComputeSettingsBuilder;
 struct ComputeSettingsT;
 
 struct NNAPISettings;
+struct NNAPISettingsBuilder;
 struct NNAPISettingsT;
 
 struct GPUSettings;
+struct GPUSettingsBuilder;
 struct GPUSettingsT;
 
 struct HexagonSettings;
+struct HexagonSettingsBuilder;
 struct HexagonSettingsT;
 
 struct XNNPackSettings;
+struct XNNPackSettingsBuilder;
 struct XNNPackSettingsT;
 
+struct CoreMLSettings;
+struct CoreMLSettingsBuilder;
+struct CoreMLSettingsT;
+
 struct EdgeTpuDeviceSpec;
+struct EdgeTpuDeviceSpecBuilder;
 struct EdgeTpuDeviceSpecT;
 
 struct EdgeTpuInactivePowerConfig;
+struct EdgeTpuInactivePowerConfigBuilder;
 struct EdgeTpuInactivePowerConfigT;
 
 struct EdgeTpuSettings;
+struct EdgeTpuSettingsBuilder;
 struct EdgeTpuSettingsT;
 
 struct CoralSettings;
+struct CoralSettingsBuilder;
 struct CoralSettingsT;
 
 struct CPUSettings;
+struct CPUSettingsBuilder;
 struct CPUSettingsT;
 
 struct TFLiteSettings;
+struct TFLiteSettingsBuilder;
 struct TFLiteSettingsT;
 
 struct FallbackSettings;
+struct FallbackSettingsBuilder;
 struct FallbackSettingsT;
 
 struct BenchmarkMetric;
+struct BenchmarkMetricBuilder;
 struct BenchmarkMetricT;
 
 struct BenchmarkResult;
+struct BenchmarkResultBuilder;
 struct BenchmarkResultT;
 
 struct ErrorCode;
+struct ErrorCodeBuilder;
 struct ErrorCodeT;
 
 struct BenchmarkError;
+struct BenchmarkErrorBuilder;
 struct BenchmarkErrorT;
 
 struct BenchmarkEvent;
+struct BenchmarkEventBuilder;
 struct BenchmarkEventT;
 
 struct BestAccelerationDecision;
+struct BestAccelerationDecisionBuilder;
 struct BestAccelerationDecisionT;
 
 struct BenchmarkInitializationFailure;
+struct BenchmarkInitializationFailureBuilder;
 struct BenchmarkInitializationFailureT;
 
 struct MiniBenchmarkEvent;
+struct MiniBenchmarkEventBuilder;
 struct MiniBenchmarkEventT;
 
+struct ModelFile;
+struct ModelFileBuilder;
+struct ModelFileT;
+
+struct BenchmarkStoragePaths;
+struct BenchmarkStoragePathsBuilder;
+struct BenchmarkStoragePathsT;
+
+struct MinibenchmarkSettings;
+struct MinibenchmarkSettingsBuilder;
+struct MinibenchmarkSettingsT;
+
 bool operator==(const ComputeSettingsT &lhs, const ComputeSettingsT &rhs);
 bool operator!=(const ComputeSettingsT &lhs, const ComputeSettingsT &rhs);
 bool operator==(const NNAPISettingsT &lhs, const NNAPISettingsT &rhs);
@@ -92,6 +129,8 @@ bool operator==(const HexagonSettingsT &lhs, const HexagonSettingsT &rhs);
 bool operator!=(const HexagonSettingsT &lhs, const HexagonSettingsT &rhs);
 bool operator==(const XNNPackSettingsT &lhs, const XNNPackSettingsT &rhs);
 bool operator!=(const XNNPackSettingsT &lhs, const XNNPackSettingsT &rhs);
+bool operator==(const CoreMLSettingsT &lhs, const CoreMLSettingsT &rhs);
+bool operator!=(const CoreMLSettingsT &lhs, const CoreMLSettingsT &rhs);
 bool operator==(const EdgeTpuDeviceSpecT &lhs, const EdgeTpuDeviceSpecT &rhs);
 bool operator!=(const EdgeTpuDeviceSpecT &lhs, const EdgeTpuDeviceSpecT &rhs);
 bool operator==(const EdgeTpuInactivePowerConfigT &lhs, const EdgeTpuInactivePowerConfigT &rhs);
@@ -122,8 +161,14 @@ bool operator==(const BenchmarkInitializationFailureT &lhs, const BenchmarkIniti
 bool operator!=(const BenchmarkInitializationFailureT &lhs, const BenchmarkInitializationFailureT &rhs);
 bool operator==(const MiniBenchmarkEventT &lhs, const MiniBenchmarkEventT &rhs);
 bool operator!=(const MiniBenchmarkEventT &lhs, const MiniBenchmarkEventT &rhs);
-
-enum ExecutionPreference {
+bool operator==(const ModelFileT &lhs, const ModelFileT &rhs);
+bool operator!=(const ModelFileT &lhs, const ModelFileT &rhs);
+bool operator==(const BenchmarkStoragePathsT &lhs, const BenchmarkStoragePathsT &rhs);
+bool operator!=(const BenchmarkStoragePathsT &lhs, const BenchmarkStoragePathsT &rhs);
+bool operator==(const MinibenchmarkSettingsT &lhs, const MinibenchmarkSettingsT &rhs);
+bool operator!=(const MinibenchmarkSettingsT &lhs, const MinibenchmarkSettingsT &rhs);
+
+enum ExecutionPreference : int32_t {
   ExecutionPreference_ANY = 0,
   ExecutionPreference_LOW_LATENCY = 1,
   ExecutionPreference_LOW_POWER = 2,
@@ -159,7 +204,7 @@ inline const char *EnumNameExecutionPreference(ExecutionPreference e) {
   return EnumNamesExecutionPreference()[index];
 }
 
-enum Delegate {
+enum Delegate : int32_t {
   Delegate_NONE = 0,
   Delegate_NNAPI = 1,
   Delegate_GPU = 2,
@@ -167,11 +212,12 @@ enum Delegate {
   Delegate_XNNPACK = 4,
   Delegate_EDGETPU = 5,
   Delegate_EDGETPU_CORAL = 6,
+  Delegate_CORE_ML = 7,
   Delegate_MIN = Delegate_NONE,
-  Delegate_MAX = Delegate_EDGETPU_CORAL
+  Delegate_MAX = Delegate_CORE_ML
 };
 
-inline const Delegate (&EnumValuesDelegate())[7] {
+inline const Delegate (&EnumValuesDelegate())[8] {
   static const Delegate values[] = {
     Delegate_NONE,
     Delegate_NNAPI,
@@ -179,13 +225,14 @@ inline const Delegate (&EnumValuesDelegate())[7] {
     Delegate_HEXAGON,
     Delegate_XNNPACK,
     Delegate_EDGETPU,
-    Delegate_EDGETPU_CORAL
+    Delegate_EDGETPU_CORAL,
+    Delegate_CORE_ML
   };
   return values;
 }
 
 inline const char * const *EnumNamesDelegate() {
-  static const char * const names[8] = {
+  static const char * const names[9] = {
     "NONE",
     "NNAPI",
     "GPU",
@@ -193,18 +240,19 @@ inline const char * const *EnumNamesDelegate() {
     "XNNPACK",
     "EDGETPU",
     "EDGETPU_CORAL",
+    "CORE_ML",
     nullptr
   };
   return names;
 }
 
 inline const char *EnumNameDelegate(Delegate e) {
-  if (flatbuffers::IsOutRange(e, Delegate_NONE, Delegate_EDGETPU_CORAL)) return "";
+  if (flatbuffers::IsOutRange(e, Delegate_NONE, Delegate_CORE_ML)) return "";
   const size_t index = static_cast<size_t>(e);
   return EnumNamesDelegate()[index];
 }
 
-enum NNAPIExecutionPreference {
+enum NNAPIExecutionPreference : int32_t {
   NNAPIExecutionPreference_UNDEFINED = 0,
   NNAPIExecutionPreference_NNAPI_LOW_POWER = 1,
   NNAPIExecutionPreference_NNAPI_FAST_SINGLE_ANSWER = 2,
@@ -240,7 +288,7 @@ inline const char *EnumNameNNAPIExecutionPreference(NNAPIExecutionPreference e)
   return EnumNamesNNAPIExecutionPreference()[index];
 }
 
-enum NNAPIExecutionPriority {
+enum NNAPIExecutionPriority : int32_t {
   NNAPIExecutionPriority_NNAPI_PRIORITY_UNDEFINED = 0,
   NNAPIExecutionPriority_NNAPI_PRIORITY_LOW = 1,
   NNAPIExecutionPriority_NNAPI_PRIORITY_MEDIUM = 2,
@@ -276,7 +324,7 @@ inline const char *EnumNameNNAPIExecutionPriority(NNAPIExecutionPriority e) {
   return EnumNamesNNAPIExecutionPriority()[index];
 }
 
-enum GPUBackend {
+enum GPUBackend : int32_t {
   GPUBackend_UNSET = 0,
   GPUBackend_OPENCL = 1,
   GPUBackend_OPENGL = 2,
@@ -309,7 +357,7 @@ inline const char *EnumNameGPUBackend(GPUBackend e) {
   return EnumNamesGPUBackend()[index];
 }
 
-enum GPUInferencePriority {
+enum GPUInferencePriority : int32_t {
   GPUInferencePriority_GPU_PRIORITY_AUTO = 0,
   GPUInferencePriority_GPU_PRIORITY_MAX_PRECISION = 1,
   GPUInferencePriority_GPU_PRIORITY_MIN_LATENCY = 2,
@@ -345,9 +393,112 @@ inline const char *EnumNameGPUInferencePriority(GPUInferencePriority e) {
   return EnumNamesGPUInferencePriority()[index];
 }
 
+enum GPUInferenceUsage : int32_t {
+  GPUInferenceUsage_GPU_INFERENCE_PREFERENCE_FAST_SINGLE_ANSWER = 0,
+  GPUInferenceUsage_GPU_INFERENCE_PREFERENCE_SUSTAINED_SPEED = 1,
+  GPUInferenceUsage_MIN = GPUInferenceUsage_GPU_INFERENCE_PREFERENCE_FAST_SINGLE_ANSWER,
+  GPUInferenceUsage_MAX = GPUInferenceUsage_GPU_INFERENCE_PREFERENCE_SUSTAINED_SPEED
+};
+
+inline const GPUInferenceUsage (&EnumValuesGPUInferenceUsage())[2] {
+  static const GPUInferenceUsage values[] = {
+    GPUInferenceUsage_GPU_INFERENCE_PREFERENCE_FAST_SINGLE_ANSWER,
+    GPUInferenceUsage_GPU_INFERENCE_PREFERENCE_SUSTAINED_SPEED
+  };
+  return values;
+}
+
+inline const char * const *EnumNamesGPUInferenceUsage() {
+  static const char * const names[3] = {
+    "GPU_INFERENCE_PREFERENCE_FAST_SINGLE_ANSWER",
+    "GPU_INFERENCE_PREFERENCE_SUSTAINED_SPEED",
+    nullptr
+  };
+  return names;
+}
+
+inline const char *EnumNameGPUInferenceUsage(GPUInferenceUsage e) {
+  if (flatbuffers::IsOutRange(e, GPUInferenceUsage_GPU_INFERENCE_PREFERENCE_FAST_SINGLE_ANSWER, GPUInferenceUsage_GPU_INFERENCE_PREFERENCE_SUSTAINED_SPEED)) return "";
+  const size_t index = static_cast<size_t>(e);
+  return EnumNamesGPUInferenceUsage()[index];
+}
+
+enum XNNPackFlags : int32_t {
+  XNNPackFlags_TFLITE_XNNPACK_DELEGATE_NO_FLAGS = 0,
+  XNNPackFlags_TFLITE_XNNPACK_DELEGATE_FLAG_QS8 = 1,
+  XNNPackFlags_TFLITE_XNNPACK_DELEGATE_FLAG_QU8 = 2,
+  XNNPackFlags_TFLITE_XNNPACK_DELEGATE_FLAG_QS8_QU8 = 3,
+  XNNPackFlags_TFLITE_XNNPACK_DELEGATE_FLAG_FORCE_FP16 = 4,
+  XNNPackFlags_MIN = XNNPackFlags_TFLITE_XNNPACK_DELEGATE_NO_FLAGS,
+  XNNPackFlags_MAX = XNNPackFlags_TFLITE_XNNPACK_DELEGATE_FLAG_FORCE_FP16
+};
+
+inline const XNNPackFlags (&EnumValuesXNNPackFlags())[5] {
+  static const XNNPackFlags values[] = {
+    XNNPackFlags_TFLITE_XNNPACK_DELEGATE_NO_FLAGS,
+    XNNPackFlags_TFLITE_XNNPACK_DELEGATE_FLAG_QS8,
+    XNNPackFlags_TFLITE_XNNPACK_DELEGATE_FLAG_QU8,
+    XNNPackFlags_TFLITE_XNNPACK_DELEGATE_FLAG_QS8_QU8,
+    XNNPackFlags_TFLITE_XNNPACK_DELEGATE_FLAG_FORCE_FP16
+  };
+  return values;
+}
+
+inline const char * const *EnumNamesXNNPackFlags() {
+  static const char * const names[6] = {
+    "TFLITE_XNNPACK_DELEGATE_NO_FLAGS",
+    "TFLITE_XNNPACK_DELEGATE_FLAG_QS8",
+    "TFLITE_XNNPACK_DELEGATE_FLAG_QU8",
+    "TFLITE_XNNPACK_DELEGATE_FLAG_QS8_QU8",
+    "TFLITE_XNNPACK_DELEGATE_FLAG_FORCE_FP16",
+    nullptr
+  };
+  return names;
+}
+
+inline const char *EnumNameXNNPackFlags(XNNPackFlags e) {
+  if (flatbuffers::IsOutRange(e, XNNPackFlags_TFLITE_XNNPACK_DELEGATE_NO_FLAGS, XNNPackFlags_TFLITE_XNNPACK_DELEGATE_FLAG_FORCE_FP16)) return "";
+  const size_t index = static_cast<size_t>(e);
+  return EnumNamesXNNPackFlags()[index];
+}
+
+namespace CoreMLSettings_ {
+
+enum EnabledDevices : int32_t {
+  EnabledDevices_DEVICES_ALL = 0,
+  EnabledDevices_DEVICES_WITH_NEURAL_ENGINE = 1,
+  EnabledDevices_MIN = EnabledDevices_DEVICES_ALL,
+  EnabledDevices_MAX = EnabledDevices_DEVICES_WITH_NEURAL_ENGINE
+};
+
+inline const EnabledDevices (&EnumValuesEnabledDevices())[2] {
+  static const EnabledDevices values[] = {
+    EnabledDevices_DEVICES_ALL,
+    EnabledDevices_DEVICES_WITH_NEURAL_ENGINE
+  };
+  return values;
+}
+
+inline const char * const *EnumNamesEnabledDevices() {
+  static const char * const names[3] = {
+    "DEVICES_ALL",
+    "DEVICES_WITH_NEURAL_ENGINE",
+    nullptr
+  };
+  return names;
+}
+
+inline const char *EnumNameEnabledDevices(EnabledDevices e) {
+  if (flatbuffers::IsOutRange(e, EnabledDevices_DEVICES_ALL, EnabledDevices_DEVICES_WITH_NEURAL_ENGINE)) return "";
+  const size_t index = static_cast<size_t>(e);
+  return EnumNamesEnabledDevices()[index];
+}
+
+}  // namespace CoreMLSettings_
+
 namespace EdgeTpuDeviceSpec_ {
 
-enum PlatformType {
+enum PlatformType : int32_t {
   PlatformType_MMIO = 0,
   PlatformType_REFERENCE = 1,
   PlatformType_SIMULATOR = 2,
@@ -385,7 +536,7 @@ inline const char *EnumNamePlatformType(PlatformType e) {
 
 }  // namespace EdgeTpuDeviceSpec_
 
-enum EdgeTpuPowerState {
+enum EdgeTpuPowerState : int32_t {
   EdgeTpuPowerState_UNDEFINED_POWERSTATE = 0,
   EdgeTpuPowerState_TPU_CORE_OFF = 1,
   EdgeTpuPowerState_READY = 2,
@@ -435,7 +586,7 @@ inline const char *EnumNameEdgeTpuPowerState(EdgeTpuPowerState e) {
 
 namespace EdgeTpuSettings_ {
 
-enum FloatTruncationType {
+enum FloatTruncationType : int32_t {
   FloatTruncationType_UNSPECIFIED = 0,
   FloatTruncationType_NO_TRUNCATION = 1,
   FloatTruncationType_BFLOAT16 = 2,
@@ -471,11 +622,44 @@ inline const char *EnumNameFloatTruncationType(FloatTruncationType e) {
   return EnumNamesFloatTruncationType()[index];
 }
 
+enum QosClass : int32_t {
+  QosClass_QOS_UNDEFINED = 0,
+  QosClass_BEST_EFFORT = 1,
+  QosClass_REALTIME = 2,
+  QosClass_MIN = QosClass_QOS_UNDEFINED,
+  QosClass_MAX = QosClass_REALTIME
+};
+
+inline const QosClass (&EnumValuesQosClass())[3] {
+  static const QosClass values[] = {
+    QosClass_QOS_UNDEFINED,
+    QosClass_BEST_EFFORT,
+    QosClass_REALTIME
+  };
+  return values;
+}
+
+inline const char * const *EnumNamesQosClass() {
+  static const char * const names[4] = {
+    "QOS_UNDEFINED",
+    "BEST_EFFORT",
+    "REALTIME",
+    nullptr
+  };
+  return names;
+}
+
+inline const char *EnumNameQosClass(QosClass e) {
+  if (flatbuffers::IsOutRange(e, QosClass_QOS_UNDEFINED, QosClass_REALTIME)) return "";
+  const size_t index = static_cast<size_t>(e);
+  return EnumNamesQosClass()[index];
+}
+
 }  // namespace EdgeTpuSettings_
 
 namespace CoralSettings_ {
 
-enum Performance {
+enum Performance : int32_t {
   Performance_UNDEFINED = 0,
   Performance_MAXIMUM = 1,
   Performance_HIGH = 2,
@@ -516,46 +700,49 @@ inline const char *EnumNamePerformance(Performance e) {
 
 }  // namespace CoralSettings_
 
-enum BenchmarkEventType {
+enum BenchmarkEventType : int32_t {
   BenchmarkEventType_UNDEFINED_BENCHMARK_EVENT_TYPE = 0,
   BenchmarkEventType_START = 1,
   BenchmarkEventType_END = 2,
   BenchmarkEventType_ERROR = 3,
   BenchmarkEventType_LOGGED = 4,
+  BenchmarkEventType_RECOVERED_ERROR = 5,
   BenchmarkEventType_MIN = BenchmarkEventType_UNDEFINED_BENCHMARK_EVENT_TYPE,
-  BenchmarkEventType_MAX = BenchmarkEventType_LOGGED
+  BenchmarkEventType_MAX = BenchmarkEventType_RECOVERED_ERROR
 };
 
-inline const BenchmarkEventType (&EnumValuesBenchmarkEventType())[5] {
+inline const BenchmarkEventType (&EnumValuesBenchmarkEventType())[6] {
   static const BenchmarkEventType values[] = {
     BenchmarkEventType_UNDEFINED_BENCHMARK_EVENT_TYPE,
     BenchmarkEventType_START,
     BenchmarkEventType_END,
     BenchmarkEventType_ERROR,
-    BenchmarkEventType_LOGGED
+    BenchmarkEventType_LOGGED,
+    BenchmarkEventType_RECOVERED_ERROR
   };
   return values;
 }
 
 inline const char * const *EnumNamesBenchmarkEventType() {
-  static const char * const names[6] = {
+  static const char * const names[7] = {
     "UNDEFINED_BENCHMARK_EVENT_TYPE",
     "START",
     "END",
     "ERROR",
     "LOGGED",
+    "RECOVERED_ERROR",
     nullptr
   };
   return names;
 }
 
 inline const char *EnumNameBenchmarkEventType(BenchmarkEventType e) {
-  if (flatbuffers::IsOutRange(e, BenchmarkEventType_UNDEFINED_BENCHMARK_EVENT_TYPE, BenchmarkEventType_LOGGED)) return "";
+  if (flatbuffers::IsOutRange(e, BenchmarkEventType_UNDEFINED_BENCHMARK_EVENT_TYPE, BenchmarkEventType_RECOVERED_ERROR)) return "";
   const size_t index = static_cast<size_t>(e);
   return EnumNamesBenchmarkEventType()[index];
 }
 
-enum BenchmarkStage {
+enum BenchmarkStage : int32_t {
   BenchmarkStage_UNKNOWN = 0,
   BenchmarkStage_INITIALIZATION = 1,
   BenchmarkStage_INFERENCE = 2,
@@ -590,22 +777,26 @@ inline const char *EnumNameBenchmarkStage(BenchmarkStage e) {
 
 struct ComputeSettingsT : public flatbuffers::NativeTable {
   typedef ComputeSettings TableType;
-  tflite::ExecutionPreference preference;
-  std::unique_ptr<tflite::TFLiteSettingsT> tflite_settings;
-  std::string model_namespace_for_statistics;
-  std::string model_identifier_for_statistics;
-  ComputeSettingsT()
-      : preference(tflite::ExecutionPreference_ANY) {
-  }
+  tflite::ExecutionPreference preference = tflite::ExecutionPreference_ANY;
+  std::unique_ptr<tflite::TFLiteSettingsT> tflite_settings{};
+  std::string model_namespace_for_statistics{};
+  std::string model_identifier_for_statistics{};
+  std::unique_ptr<tflite::MinibenchmarkSettingsT> settings_to_test_locally{};
+  ComputeSettingsT() = default;
+  ComputeSettingsT(const ComputeSettingsT &o);
+  ComputeSettingsT(ComputeSettingsT&&) FLATBUFFERS_NOEXCEPT = default;
+  ComputeSettingsT &operator=(ComputeSettingsT o) FLATBUFFERS_NOEXCEPT;
 };
 
 struct ComputeSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef ComputeSettingsT NativeTableType;
+  typedef ComputeSettingsBuilder Builder;
   enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
     VT_PREFERENCE = 4,
     VT_TFLITE_SETTINGS = 6,
     VT_MODEL_NAMESPACE_FOR_STATISTICS = 8,
-    VT_MODEL_IDENTIFIER_FOR_STATISTICS = 10
+    VT_MODEL_IDENTIFIER_FOR_STATISTICS = 10,
+    VT_SETTINGS_TO_TEST_LOCALLY = 12
   };
   tflite::ExecutionPreference preference() const {
     return static_cast<tflite::ExecutionPreference>(GetField<int32_t>(VT_PREFERENCE, 0));
@@ -619,15 +810,20 @@ struct ComputeSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   const flatbuffers::String *model_identifier_for_statistics() const {
     return GetPointer<const flatbuffers::String *>(VT_MODEL_IDENTIFIER_FOR_STATISTICS);
   }
+  const tflite::MinibenchmarkSettings *settings_to_test_locally() const {
+    return GetPointer<const tflite::MinibenchmarkSettings *>(VT_SETTINGS_TO_TEST_LOCALLY);
+  }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_PREFERENCE) &&
+           VerifyField<int32_t>(verifier, VT_PREFERENCE, 4) &&
            VerifyOffset(verifier, VT_TFLITE_SETTINGS) &&
            verifier.VerifyTable(tflite_settings()) &&
            VerifyOffset(verifier, VT_MODEL_NAMESPACE_FOR_STATISTICS) &&
            verifier.VerifyString(model_namespace_for_statistics()) &&
            VerifyOffset(verifier, VT_MODEL_IDENTIFIER_FOR_STATISTICS) &&
            verifier.VerifyString(model_identifier_for_statistics()) &&
+           VerifyOffset(verifier, VT_SETTINGS_TO_TEST_LOCALLY) &&
+           verifier.VerifyTable(settings_to_test_locally()) &&
            verifier.EndTable();
   }
   ComputeSettingsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -636,6 +832,7 @@ struct ComputeSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct ComputeSettingsBuilder {
+  typedef ComputeSettings Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_preference(tflite::ExecutionPreference preference) {
@@ -650,11 +847,13 @@ struct ComputeSettingsBuilder {
   void add_model_identifier_for_statistics(flatbuffers::Offset<flatbuffers::String> model_identifier_for_statistics) {
     fbb_.AddOffset(ComputeSettings::VT_MODEL_IDENTIFIER_FOR_STATISTICS, model_identifier_for_statistics);
   }
+  void add_settings_to_test_locally(flatbuffers::Offset<tflite::MinibenchmarkSettings> settings_to_test_locally) {
+    fbb_.AddOffset(ComputeSettings::VT_SETTINGS_TO_TEST_LOCALLY, settings_to_test_locally);
+  }
   explicit ComputeSettingsBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  ComputeSettingsBuilder &operator=(const ComputeSettingsBuilder &);
   flatbuffers::Offset<ComputeSettings> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<ComputeSettings>(end);
@@ -667,8 +866,10 @@ inline flatbuffers::Offset<ComputeSettings> CreateComputeSettings(
     tflite::ExecutionPreference preference = tflite::ExecutionPreference_ANY,
     flatbuffers::Offset<tflite::TFLiteSettings> tflite_settings = 0,
     flatbuffers::Offset<flatbuffers::String> model_namespace_for_statistics = 0,
-    flatbuffers::Offset<flatbuffers::String> model_identifier_for_statistics = 0) {
+    flatbuffers::Offset<flatbuffers::String> model_identifier_for_statistics = 0,
+    flatbuffers::Offset<tflite::MinibenchmarkSettings> settings_to_test_locally = 0) {
   ComputeSettingsBuilder builder_(_fbb);
+  builder_.add_settings_to_test_locally(settings_to_test_locally);
   builder_.add_model_identifier_for_statistics(model_identifier_for_statistics);
   builder_.add_model_namespace_for_statistics(model_namespace_for_statistics);
   builder_.add_tflite_settings(tflite_settings);
@@ -681,7 +882,8 @@ inline flatbuffers::Offset<ComputeSettings> CreateComputeSettingsDirect(
     tflite::ExecutionPreference preference = tflite::ExecutionPreference_ANY,
     flatbuffers::Offset<tflite::TFLiteSettings> tflite_settings = 0,
     const char *model_namespace_for_statistics = nullptr,
-    const char *model_identifier_for_statistics = nullptr) {
+    const char *model_identifier_for_statistics = nullptr,
+    flatbuffers::Offset<tflite::MinibenchmarkSettings> settings_to_test_locally = 0) {
   auto model_namespace_for_statistics__ = model_namespace_for_statistics ? _fbb.CreateString(model_namespace_for_statistics) : 0;
   auto model_identifier_for_statistics__ = model_identifier_for_statistics ? _fbb.CreateString(model_identifier_for_statistics) : 0;
   return tflite::CreateComputeSettings(
@@ -689,37 +891,35 @@ inline flatbuffers::Offset<ComputeSettings> CreateComputeSettingsDirect(
       preference,
       tflite_settings,
       model_namespace_for_statistics__,
-      model_identifier_for_statistics__);
+      model_identifier_for_statistics__,
+      settings_to_test_locally);
 }
 
 flatbuffers::Offset<ComputeSettings> CreateComputeSettings(flatbuffers::FlatBufferBuilder &_fbb, const ComputeSettingsT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
 
 struct NNAPISettingsT : public flatbuffers::NativeTable {
   typedef NNAPISettings TableType;
-  std::string accelerator_name;
-  std::string cache_directory;
-  std::string model_token;
-  tflite::NNAPIExecutionPreference execution_preference;
-  int32_t no_of_nnapi_instances_to_cache;
-  std::unique_ptr<tflite::FallbackSettingsT> fallback_settings;
-  bool allow_nnapi_cpu_on_android_10_plus;
-  tflite::NNAPIExecutionPriority execution_priority;
-  bool allow_dynamic_dimensions;
-  bool allow_fp16_precision_for_fp32;
-  bool use_burst_computation;
-  NNAPISettingsT()
-      : execution_preference(tflite::NNAPIExecutionPreference_UNDEFINED),
-        no_of_nnapi_instances_to_cache(0),
-        allow_nnapi_cpu_on_android_10_plus(false),
-        execution_priority(tflite::NNAPIExecutionPriority_NNAPI_PRIORITY_UNDEFINED),
-        allow_dynamic_dimensions(false),
-        allow_fp16_precision_for_fp32(false),
-        use_burst_computation(false) {
-  }
+  std::string accelerator_name{};
+  std::string cache_directory{};
+  std::string model_token{};
+  tflite::NNAPIExecutionPreference execution_preference = tflite::NNAPIExecutionPreference_UNDEFINED;
+  int32_t no_of_nnapi_instances_to_cache = 0;
+  std::unique_ptr<tflite::FallbackSettingsT> fallback_settings{};
+  bool allow_nnapi_cpu_on_android_10_plus = false;
+  tflite::NNAPIExecutionPriority execution_priority = tflite::NNAPIExecutionPriority_NNAPI_PRIORITY_UNDEFINED;
+  bool allow_dynamic_dimensions = false;
+  bool allow_fp16_precision_for_fp32 = false;
+  bool use_burst_computation = false;
+  int64_t support_library_handle = 0;
+  NNAPISettingsT() = default;
+  NNAPISettingsT(const NNAPISettingsT &o);
+  NNAPISettingsT(NNAPISettingsT&&) FLATBUFFERS_NOEXCEPT = default;
+  NNAPISettingsT &operator=(NNAPISettingsT o) FLATBUFFERS_NOEXCEPT;
 };
 
 struct NNAPISettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef NNAPISettingsT NativeTableType;
+  typedef NNAPISettingsBuilder Builder;
   enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
     VT_ACCELERATOR_NAME = 4,
     VT_CACHE_DIRECTORY = 6,
@@ -731,7 +931,8 @@ struct NNAPISettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     VT_EXECUTION_PRIORITY = 18,
     VT_ALLOW_DYNAMIC_DIMENSIONS = 20,
     VT_ALLOW_FP16_PRECISION_FOR_FP32 = 22,
-    VT_USE_BURST_COMPUTATION = 24
+    VT_USE_BURST_COMPUTATION = 24,
+    VT_SUPPORT_LIBRARY_HANDLE = 26
   };
   const flatbuffers::String *accelerator_name() const {
     return GetPointer<const flatbuffers::String *>(VT_ACCELERATOR_NAME);
@@ -766,6 +967,9 @@ struct NNAPISettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   bool use_burst_computation() const {
     return GetField<uint8_t>(VT_USE_BURST_COMPUTATION, 0) != 0;
   }
+  int64_t support_library_handle() const {
+    return GetField<int64_t>(VT_SUPPORT_LIBRARY_HANDLE, 0);
+  }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
            VerifyOffset(verifier, VT_ACCELERATOR_NAME) &&
@@ -774,15 +978,16 @@ struct NNAPISettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
            verifier.VerifyString(cache_directory()) &&
            VerifyOffset(verifier, VT_MODEL_TOKEN) &&
            verifier.VerifyString(model_token()) &&
-           VerifyField<int32_t>(verifier, VT_EXECUTION_PREFERENCE) &&
-           VerifyField<int32_t>(verifier, VT_NO_OF_NNAPI_INSTANCES_TO_CACHE) &&
+           VerifyField<int32_t>(verifier, VT_EXECUTION_PREFERENCE, 4) &&
+           VerifyField<int32_t>(verifier, VT_NO_OF_NNAPI_INSTANCES_TO_CACHE, 4) &&
            VerifyOffset(verifier, VT_FALLBACK_SETTINGS) &&
            verifier.VerifyTable(fallback_settings()) &&
-           VerifyField<uint8_t>(verifier, VT_ALLOW_NNAPI_CPU_ON_ANDROID_10_PLUS) &&
-           VerifyField<int32_t>(verifier, VT_EXECUTION_PRIORITY) &&
-           VerifyField<uint8_t>(verifier, VT_ALLOW_DYNAMIC_DIMENSIONS) &&
-           VerifyField<uint8_t>(verifier, VT_ALLOW_FP16_PRECISION_FOR_FP32) &&
-           VerifyField<uint8_t>(verifier, VT_USE_BURST_COMPUTATION) &&
+           VerifyField<uint8_t>(verifier, VT_ALLOW_NNAPI_CPU_ON_ANDROID_10_PLUS, 1) &&
+           VerifyField<int32_t>(verifier, VT_EXECUTION_PRIORITY, 4) &&
+           VerifyField<uint8_t>(verifier, VT_ALLOW_DYNAMIC_DIMENSIONS, 1) &&
+           VerifyField<uint8_t>(verifier, VT_ALLOW_FP16_PRECISION_FOR_FP32, 1) &&
+           VerifyField<uint8_t>(verifier, VT_USE_BURST_COMPUTATION, 1) &&
+           VerifyField<int64_t>(verifier, VT_SUPPORT_LIBRARY_HANDLE, 8) &&
            verifier.EndTable();
   }
   NNAPISettingsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -791,6 +996,7 @@ struct NNAPISettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct NNAPISettingsBuilder {
+  typedef NNAPISettings Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_accelerator_name(flatbuffers::Offset<flatbuffers::String> accelerator_name) {
@@ -826,11 +1032,13 @@ struct NNAPISettingsBuilder {
   void add_use_burst_computation(bool use_burst_computation) {
     fbb_.AddElement<uint8_t>(NNAPISettings::VT_USE_BURST_COMPUTATION, static_cast<uint8_t>(use_burst_computation), 0);
   }
+  void add_support_library_handle(int64_t support_library_handle) {
+    fbb_.AddElement<int64_t>(NNAPISettings::VT_SUPPORT_LIBRARY_HANDLE, support_library_handle, 0);
+  }
   explicit NNAPISettingsBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  NNAPISettingsBuilder &operator=(const NNAPISettingsBuilder &);
   flatbuffers::Offset<NNAPISettings> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<NNAPISettings>(end);
@@ -850,8 +1058,10 @@ inline flatbuffers::Offset<NNAPISettings> CreateNNAPISettings(
     tflite::NNAPIExecutionPriority execution_priority = tflite::NNAPIExecutionPriority_NNAPI_PRIORITY_UNDEFINED,
     bool allow_dynamic_dimensions = false,
     bool allow_fp16_precision_for_fp32 = false,
-    bool use_burst_computation = false) {
+    bool use_burst_computation = false,
+    int64_t support_library_handle = 0) {
   NNAPISettingsBuilder builder_(_fbb);
+  builder_.add_support_library_handle(support_library_handle);
   builder_.add_execution_priority(execution_priority);
   builder_.add_fallback_settings(fallback_settings);
   builder_.add_no_of_nnapi_instances_to_cache(no_of_nnapi_instances_to_cache);
@@ -878,7 +1088,8 @@ inline flatbuffers::Offset<NNAPISettings> CreateNNAPISettingsDirect(
     tflite::NNAPIExecutionPriority execution_priority = tflite::NNAPIExecutionPriority_NNAPI_PRIORITY_UNDEFINED,
     bool allow_dynamic_dimensions = false,
     bool allow_fp16_precision_for_fp32 = false,
-    bool use_burst_computation = false) {
+    bool use_burst_computation = false,
+    int64_t support_library_handle = 0) {
   auto accelerator_name__ = accelerator_name ? _fbb.CreateString(accelerator_name) : 0;
   auto cache_directory__ = cache_directory ? _fbb.CreateString(cache_directory) : 0;
   auto model_token__ = model_token ? _fbb.CreateString(model_token) : 0;
@@ -894,38 +1105,38 @@ inline flatbuffers::Offset<NNAPISettings> CreateNNAPISettingsDirect(
       execution_priority,
       allow_dynamic_dimensions,
       allow_fp16_precision_for_fp32,
-      use_burst_computation);
+      use_burst_computation,
+      support_library_handle);
 }
 
 flatbuffers::Offset<NNAPISettings> CreateNNAPISettings(flatbuffers::FlatBufferBuilder &_fbb, const NNAPISettingsT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
 
 struct GPUSettingsT : public flatbuffers::NativeTable {
   typedef GPUSettings TableType;
-  bool is_precision_loss_allowed;
-  bool enable_quantized_inference;
-  tflite::GPUBackend force_backend;
-  tflite::GPUInferencePriority inference_priority1;
-  tflite::GPUInferencePriority inference_priority2;
-  tflite::GPUInferencePriority inference_priority3;
-  GPUSettingsT()
-      : is_precision_loss_allowed(false),
-        enable_quantized_inference(true),
-        force_backend(tflite::GPUBackend_UNSET),
-        inference_priority1(tflite::GPUInferencePriority_GPU_PRIORITY_AUTO),
-        inference_priority2(tflite::GPUInferencePriority_GPU_PRIORITY_AUTO),
-        inference_priority3(tflite::GPUInferencePriority_GPU_PRIORITY_AUTO) {
-  }
+  bool is_precision_loss_allowed = false;
+  bool enable_quantized_inference = true;
+  tflite::GPUBackend force_backend = tflite::GPUBackend_UNSET;
+  tflite::GPUInferencePriority inference_priority1 = tflite::GPUInferencePriority_GPU_PRIORITY_AUTO;
+  tflite::GPUInferencePriority inference_priority2 = tflite::GPUInferencePriority_GPU_PRIORITY_AUTO;
+  tflite::GPUInferencePriority inference_priority3 = tflite::GPUInferencePriority_GPU_PRIORITY_AUTO;
+  tflite::GPUInferenceUsage inference_preference = tflite::GPUInferenceUsage_GPU_INFERENCE_PREFERENCE_FAST_SINGLE_ANSWER;
+  std::string cache_directory{};
+  std::string model_token{};
 };
 
 struct GPUSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef GPUSettingsT NativeTableType;
+  typedef GPUSettingsBuilder Builder;
   enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
     VT_IS_PRECISION_LOSS_ALLOWED = 4,
     VT_ENABLE_QUANTIZED_INFERENCE = 6,
     VT_FORCE_BACKEND = 8,
     VT_INFERENCE_PRIORITY1 = 10,
     VT_INFERENCE_PRIORITY2 = 12,
-    VT_INFERENCE_PRIORITY3 = 14
+    VT_INFERENCE_PRIORITY3 = 14,
+    VT_INFERENCE_PREFERENCE = 16,
+    VT_CACHE_DIRECTORY = 18,
+    VT_MODEL_TOKEN = 20
   };
   bool is_precision_loss_allowed() const {
     return GetField<uint8_t>(VT_IS_PRECISION_LOSS_ALLOWED, 0) != 0;
@@ -945,14 +1156,28 @@ struct GPUSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   tflite::GPUInferencePriority inference_priority3() const {
     return static_cast<tflite::GPUInferencePriority>(GetField<int32_t>(VT_INFERENCE_PRIORITY3, 0));
   }
+  tflite::GPUInferenceUsage inference_preference() const {
+    return static_cast<tflite::GPUInferenceUsage>(GetField<int32_t>(VT_INFERENCE_PREFERENCE, 0));
+  }
+  const flatbuffers::String *cache_directory() const {
+    return GetPointer<const flatbuffers::String *>(VT_CACHE_DIRECTORY);
+  }
+  const flatbuffers::String *model_token() const {
+    return GetPointer<const flatbuffers::String *>(VT_MODEL_TOKEN);
+  }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<uint8_t>(verifier, VT_IS_PRECISION_LOSS_ALLOWED) &&
-           VerifyField<uint8_t>(verifier, VT_ENABLE_QUANTIZED_INFERENCE) &&
-           VerifyField<int32_t>(verifier, VT_FORCE_BACKEND) &&
-           VerifyField<int32_t>(verifier, VT_INFERENCE_PRIORITY1) &&
-           VerifyField<int32_t>(verifier, VT_INFERENCE_PRIORITY2) &&
-           VerifyField<int32_t>(verifier, VT_INFERENCE_PRIORITY3) &&
+           VerifyField<uint8_t>(verifier, VT_IS_PRECISION_LOSS_ALLOWED, 1) &&
+           VerifyField<uint8_t>(verifier, VT_ENABLE_QUANTIZED_INFERENCE, 1) &&
+           VerifyField<int32_t>(verifier, VT_FORCE_BACKEND, 4) &&
+           VerifyField<int32_t>(verifier, VT_INFERENCE_PRIORITY1, 4) &&
+           VerifyField<int32_t>(verifier, VT_INFERENCE_PRIORITY2, 4) &&
+           VerifyField<int32_t>(verifier, VT_INFERENCE_PRIORITY3, 4) &&
+           VerifyField<int32_t>(verifier, VT_INFERENCE_PREFERENCE, 4) &&
+           VerifyOffset(verifier, VT_CACHE_DIRECTORY) &&
+           verifier.VerifyString(cache_directory()) &&
+           VerifyOffset(verifier, VT_MODEL_TOKEN) &&
+           verifier.VerifyString(model_token()) &&
            verifier.EndTable();
   }
   GPUSettingsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -961,6 +1186,7 @@ struct GPUSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct GPUSettingsBuilder {
+  typedef GPUSettings Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_is_precision_loss_allowed(bool is_precision_loss_allowed) {
@@ -981,11 +1207,19 @@ struct GPUSettingsBuilder {
   void add_inference_priority3(tflite::GPUInferencePriority inference_priority3) {
     fbb_.AddElement<int32_t>(GPUSettings::VT_INFERENCE_PRIORITY3, static_cast<int32_t>(inference_priority3), 0);
   }
+  void add_inference_preference(tflite::GPUInferenceUsage inference_preference) {
+    fbb_.AddElement<int32_t>(GPUSettings::VT_INFERENCE_PREFERENCE, static_cast<int32_t>(inference_preference), 0);
+  }
+  void add_cache_directory(flatbuffers::Offset<flatbuffers::String> cache_directory) {
+    fbb_.AddOffset(GPUSettings::VT_CACHE_DIRECTORY, cache_directory);
+  }
+  void add_model_token(flatbuffers::Offset<flatbuffers::String> model_token) {
+    fbb_.AddOffset(GPUSettings::VT_MODEL_TOKEN, model_token);
+  }
   explicit GPUSettingsBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  GPUSettingsBuilder &operator=(const GPUSettingsBuilder &);
   flatbuffers::Offset<GPUSettings> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<GPUSettings>(end);
@@ -1000,8 +1234,14 @@ inline flatbuffers::Offset<GPUSettings> CreateGPUSettings(
     tflite::GPUBackend force_backend = tflite::GPUBackend_UNSET,
     tflite::GPUInferencePriority inference_priority1 = tflite::GPUInferencePriority_GPU_PRIORITY_AUTO,
     tflite::GPUInferencePriority inference_priority2 = tflite::GPUInferencePriority_GPU_PRIORITY_AUTO,
-    tflite::GPUInferencePriority inference_priority3 = tflite::GPUInferencePriority_GPU_PRIORITY_AUTO) {
+    tflite::GPUInferencePriority inference_priority3 = tflite::GPUInferencePriority_GPU_PRIORITY_AUTO,
+    tflite::GPUInferenceUsage inference_preference = tflite::GPUInferenceUsage_GPU_INFERENCE_PREFERENCE_FAST_SINGLE_ANSWER,
+    flatbuffers::Offset<flatbuffers::String> cache_directory = 0,
+    flatbuffers::Offset<flatbuffers::String> model_token = 0) {
   GPUSettingsBuilder builder_(_fbb);
+  builder_.add_model_token(model_token);
+  builder_.add_cache_directory(cache_directory);
+  builder_.add_inference_preference(inference_preference);
   builder_.add_inference_priority3(inference_priority3);
   builder_.add_inference_priority2(inference_priority2);
   builder_.add_inference_priority1(inference_priority1);
@@ -1011,24 +1251,45 @@ inline flatbuffers::Offset<GPUSettings> CreateGPUSettings(
   return builder_.Finish();
 }
 
+inline flatbuffers::Offset<GPUSettings> CreateGPUSettingsDirect(
+    flatbuffers::FlatBufferBuilder &_fbb,
+    bool is_precision_loss_allowed = false,
+    bool enable_quantized_inference = true,
+    tflite::GPUBackend force_backend = tflite::GPUBackend_UNSET,
+    tflite::GPUInferencePriority inference_priority1 = tflite::GPUInferencePriority_GPU_PRIORITY_AUTO,
+    tflite::GPUInferencePriority inference_priority2 = tflite::GPUInferencePriority_GPU_PRIORITY_AUTO,
+    tflite::GPUInferencePriority inference_priority3 = tflite::GPUInferencePriority_GPU_PRIORITY_AUTO,
+    tflite::GPUInferenceUsage inference_preference = tflite::GPUInferenceUsage_GPU_INFERENCE_PREFERENCE_FAST_SINGLE_ANSWER,
+    const char *cache_directory = nullptr,
+    const char *model_token = nullptr) {
+  auto cache_directory__ = cache_directory ? _fbb.CreateString(cache_directory) : 0;
+  auto model_token__ = model_token ? _fbb.CreateString(model_token) : 0;
+  return tflite::CreateGPUSettings(
+      _fbb,
+      is_precision_loss_allowed,
+      enable_quantized_inference,
+      force_backend,
+      inference_priority1,
+      inference_priority2,
+      inference_priority3,
+      inference_preference,
+      cache_directory__,
+      model_token__);
+}
+
 flatbuffers::Offset<GPUSettings> CreateGPUSettings(flatbuffers::FlatBufferBuilder &_fbb, const GPUSettingsT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
 
 struct HexagonSettingsT : public flatbuffers::NativeTable {
   typedef HexagonSettings TableType;
-  int32_t debug_level;
-  int32_t powersave_level;
-  bool print_graph_profile;
-  bool print_graph_debug;
-  HexagonSettingsT()
-      : debug_level(0),
-        powersave_level(0),
-        print_graph_profile(false),
-        print_graph_debug(false) {
-  }
+  int32_t debug_level = 0;
+  int32_t powersave_level = 0;
+  bool print_graph_profile = false;
+  bool print_graph_debug = false;
 };
 
 struct HexagonSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef HexagonSettingsT NativeTableType;
+  typedef HexagonSettingsBuilder Builder;
   enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
     VT_DEBUG_LEVEL = 4,
     VT_POWERSAVE_LEVEL = 6,
@@ -1049,10 +1310,10 @@ struct HexagonSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_DEBUG_LEVEL) &&
-           VerifyField<int32_t>(verifier, VT_POWERSAVE_LEVEL) &&
-           VerifyField<uint8_t>(verifier, VT_PRINT_GRAPH_PROFILE) &&
-           VerifyField<uint8_t>(verifier, VT_PRINT_GRAPH_DEBUG) &&
+           VerifyField<int32_t>(verifier, VT_DEBUG_LEVEL, 4) &&
+           VerifyField<int32_t>(verifier, VT_POWERSAVE_LEVEL, 4) &&
+           VerifyField<uint8_t>(verifier, VT_PRINT_GRAPH_PROFILE, 1) &&
+           VerifyField<uint8_t>(verifier, VT_PRINT_GRAPH_DEBUG, 1) &&
            verifier.EndTable();
   }
   HexagonSettingsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -1061,6 +1322,7 @@ struct HexagonSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct HexagonSettingsBuilder {
+  typedef HexagonSettings Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_debug_level(int32_t debug_level) {
@@ -1079,7 +1341,6 @@ struct HexagonSettingsBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  HexagonSettingsBuilder &operator=(const HexagonSettingsBuilder &);
   flatbuffers::Offset<HexagonSettings> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<HexagonSettings>(end);
@@ -1105,23 +1366,27 @@ flatbuffers::Offset<HexagonSettings> CreateHexagonSettings(flatbuffers::FlatBuff
 
 struct XNNPackSettingsT : public flatbuffers::NativeTable {
   typedef XNNPackSettings TableType;
-  int32_t num_threads;
-  XNNPackSettingsT()
-      : num_threads(0) {
-  }
+  int32_t num_threads = 0;
+  tflite::XNNPackFlags flags = tflite::XNNPackFlags_TFLITE_XNNPACK_DELEGATE_NO_FLAGS;
 };
 
 struct XNNPackSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef XNNPackSettingsT NativeTableType;
+  typedef XNNPackSettingsBuilder Builder;
   enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
-    VT_NUM_THREADS = 4
+    VT_NUM_THREADS = 4,
+    VT_FLAGS = 6
   };
   int32_t num_threads() const {
     return GetField<int32_t>(VT_NUM_THREADS, 0);
   }
+  tflite::XNNPackFlags flags() const {
+    return static_cast<tflite::XNNPackFlags>(GetField<int32_t>(VT_FLAGS, 0));
+  }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_NUM_THREADS) &&
+           VerifyField<int32_t>(verifier, VT_NUM_THREADS, 4) &&
+           VerifyField<int32_t>(verifier, VT_FLAGS, 4) &&
            verifier.EndTable();
   }
   XNNPackSettingsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -1130,16 +1395,19 @@ struct XNNPackSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct XNNPackSettingsBuilder {
+  typedef XNNPackSettings Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_num_threads(int32_t num_threads) {
     fbb_.AddElement<int32_t>(XNNPackSettings::VT_NUM_THREADS, num_threads, 0);
   }
+  void add_flags(tflite::XNNPackFlags flags) {
+    fbb_.AddElement<int32_t>(XNNPackSettings::VT_FLAGS, static_cast<int32_t>(flags), 0);
+  }
   explicit XNNPackSettingsBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  XNNPackSettingsBuilder &operator=(const XNNPackSettingsBuilder &);
   flatbuffers::Offset<XNNPackSettings> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<XNNPackSettings>(end);
@@ -1149,29 +1417,112 @@ struct XNNPackSettingsBuilder {
 
 inline flatbuffers::Offset<XNNPackSettings> CreateXNNPackSettings(
     flatbuffers::FlatBufferBuilder &_fbb,
-    int32_t num_threads = 0) {
+    int32_t num_threads = 0,
+    tflite::XNNPackFlags flags = tflite::XNNPackFlags_TFLITE_XNNPACK_DELEGATE_NO_FLAGS) {
   XNNPackSettingsBuilder builder_(_fbb);
+  builder_.add_flags(flags);
   builder_.add_num_threads(num_threads);
   return builder_.Finish();
 }
 
 flatbuffers::Offset<XNNPackSettings> CreateXNNPackSettings(flatbuffers::FlatBufferBuilder &_fbb, const XNNPackSettingsT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
 
+struct CoreMLSettingsT : public flatbuffers::NativeTable {
+  typedef CoreMLSettings TableType;
+  tflite::CoreMLSettings_::EnabledDevices enabled_devices = tflite::CoreMLSettings_::EnabledDevices_DEVICES_ALL;
+  int32_t coreml_version = 0;
+  int32_t max_delegated_partitions = 0;
+  int32_t min_nodes_per_partition = 2;
+};
+
+struct CoreMLSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
+  typedef CoreMLSettingsT NativeTableType;
+  typedef CoreMLSettingsBuilder Builder;
+  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
+    VT_ENABLED_DEVICES = 4,
+    VT_COREML_VERSION = 6,
+    VT_MAX_DELEGATED_PARTITIONS = 8,
+    VT_MIN_NODES_PER_PARTITION = 10
+  };
+  tflite::CoreMLSettings_::EnabledDevices enabled_devices() const {
+    return static_cast<tflite::CoreMLSettings_::EnabledDevices>(GetField<int32_t>(VT_ENABLED_DEVICES, 0));
+  }
+  int32_t coreml_version() const {
+    return GetField<int32_t>(VT_COREML_VERSION, 0);
+  }
+  int32_t max_delegated_partitions() const {
+    return GetField<int32_t>(VT_MAX_DELEGATED_PARTITIONS, 0);
+  }
+  int32_t min_nodes_per_partition() const {
+    return GetField<int32_t>(VT_MIN_NODES_PER_PARTITION, 2);
+  }
+  bool Verify(flatbuffers::Verifier &verifier) const {
+    return VerifyTableStart(verifier) &&
+           VerifyField<int32_t>(verifier, VT_ENABLED_DEVICES, 4) &&
+           VerifyField<int32_t>(verifier, VT_COREML_VERSION, 4) &&
+           VerifyField<int32_t>(verifier, VT_MAX_DELEGATED_PARTITIONS, 4) &&
+           VerifyField<int32_t>(verifier, VT_MIN_NODES_PER_PARTITION, 4) &&
+           verifier.EndTable();
+  }
+  CoreMLSettingsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
+  void UnPackTo(CoreMLSettingsT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
+  static flatbuffers::Offset<CoreMLSettings> Pack(flatbuffers::FlatBufferBuilder &_fbb, const CoreMLSettingsT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
+};
+
+struct CoreMLSettingsBuilder {
+  typedef CoreMLSettings Table;
+  flatbuffers::FlatBufferBuilder &fbb_;
+  flatbuffers::uoffset_t start_;
+  void add_enabled_devices(tflite::CoreMLSettings_::EnabledDevices enabled_devices) {
+    fbb_.AddElement<int32_t>(CoreMLSettings::VT_ENABLED_DEVICES, static_cast<int32_t>(enabled_devices), 0);
+  }
+  void add_coreml_version(int32_t coreml_version) {
+    fbb_.AddElement<int32_t>(CoreMLSettings::VT_COREML_VERSION, coreml_version, 0);
+  }
+  void add_max_delegated_partitions(int32_t max_delegated_partitions) {
+    fbb_.AddElement<int32_t>(CoreMLSettings::VT_MAX_DELEGATED_PARTITIONS, max_delegated_partitions, 0);
+  }
+  void add_min_nodes_per_partition(int32_t min_nodes_per_partition) {
+    fbb_.AddElement<int32_t>(CoreMLSettings::VT_MIN_NODES_PER_PARTITION, min_nodes_per_partition, 2);
+  }
+  explicit CoreMLSettingsBuilder(flatbuffers::FlatBufferBuilder &_fbb)
+        : fbb_(_fbb) {
+    start_ = fbb_.StartTable();
+  }
+  flatbuffers::Offset<CoreMLSettings> Finish() {
+    const auto end = fbb_.EndTable(start_);
+    auto o = flatbuffers::Offset<CoreMLSettings>(end);
+    return o;
+  }
+};
+
+inline flatbuffers::Offset<CoreMLSettings> CreateCoreMLSettings(
+    flatbuffers::FlatBufferBuilder &_fbb,
+    tflite::CoreMLSettings_::EnabledDevices enabled_devices = tflite::CoreMLSettings_::EnabledDevices_DEVICES_ALL,
+    int32_t coreml_version = 0,
+    int32_t max_delegated_partitions = 0,
+    int32_t min_nodes_per_partition = 2) {
+  CoreMLSettingsBuilder builder_(_fbb);
+  builder_.add_min_nodes_per_partition(min_nodes_per_partition);
+  builder_.add_max_delegated_partitions(max_delegated_partitions);
+  builder_.add_coreml_version(coreml_version);
+  builder_.add_enabled_devices(enabled_devices);
+  return builder_.Finish();
+}
+
+flatbuffers::Offset<CoreMLSettings> CreateCoreMLSettings(flatbuffers::FlatBufferBuilder &_fbb, const CoreMLSettingsT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
+
 struct EdgeTpuDeviceSpecT : public flatbuffers::NativeTable {
   typedef EdgeTpuDeviceSpec TableType;
-  tflite::EdgeTpuDeviceSpec_::PlatformType platform_type;
-  int32_t num_chips;
-  std::vector<std::string> device_paths;
-  int32_t chip_family;
-  EdgeTpuDeviceSpecT()
-      : platform_type(tflite::EdgeTpuDeviceSpec_::PlatformType_MMIO),
-        num_chips(0),
-        chip_family(0) {
-  }
+  tflite::EdgeTpuDeviceSpec_::PlatformType platform_type = tflite::EdgeTpuDeviceSpec_::PlatformType_MMIO;
+  int32_t num_chips = 0;
+  std::vector<std::string> device_paths{};
+  int32_t chip_family = 0;
 };
 
 struct EdgeTpuDeviceSpec FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef EdgeTpuDeviceSpecT NativeTableType;
+  typedef EdgeTpuDeviceSpecBuilder Builder;
   enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
     VT_PLATFORM_TYPE = 4,
     VT_NUM_CHIPS = 6,
@@ -1192,12 +1543,12 @@ struct EdgeTpuDeviceSpec FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_PLATFORM_TYPE) &&
-           VerifyField<int32_t>(verifier, VT_NUM_CHIPS) &&
+           VerifyField<int32_t>(verifier, VT_PLATFORM_TYPE, 4) &&
+           VerifyField<int32_t>(verifier, VT_NUM_CHIPS, 4) &&
            VerifyOffset(verifier, VT_DEVICE_PATHS) &&
            verifier.VerifyVector(device_paths()) &&
            verifier.VerifyVectorOfStrings(device_paths()) &&
-           VerifyField<int32_t>(verifier, VT_CHIP_FAMILY) &&
+           VerifyField<int32_t>(verifier, VT_CHIP_FAMILY, 4) &&
            verifier.EndTable();
   }
   EdgeTpuDeviceSpecT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -1206,6 +1557,7 @@ struct EdgeTpuDeviceSpec FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct EdgeTpuDeviceSpecBuilder {
+  typedef EdgeTpuDeviceSpec Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_platform_type(tflite::EdgeTpuDeviceSpec_::PlatformType platform_type) {
@@ -1224,7 +1576,6 @@ struct EdgeTpuDeviceSpecBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  EdgeTpuDeviceSpecBuilder &operator=(const EdgeTpuDeviceSpecBuilder &);
   flatbuffers::Offset<EdgeTpuDeviceSpec> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<EdgeTpuDeviceSpec>(end);
@@ -1265,16 +1616,13 @@ flatbuffers::Offset<EdgeTpuDeviceSpec> CreateEdgeTpuDeviceSpec(flatbuffers::Flat
 
 struct EdgeTpuInactivePowerConfigT : public flatbuffers::NativeTable {
   typedef EdgeTpuInactivePowerConfig TableType;
-  tflite::EdgeTpuPowerState inactive_power_state;
-  int64_t inactive_timeout_us;
-  EdgeTpuInactivePowerConfigT()
-      : inactive_power_state(tflite::EdgeTpuPowerState_UNDEFINED_POWERSTATE),
-        inactive_timeout_us(0) {
-  }
+  tflite::EdgeTpuPowerState inactive_power_state = tflite::EdgeTpuPowerState_UNDEFINED_POWERSTATE;
+  int64_t inactive_timeout_us = 0;
 };
 
 struct EdgeTpuInactivePowerConfig FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef EdgeTpuInactivePowerConfigT NativeTableType;
+  typedef EdgeTpuInactivePowerConfigBuilder Builder;
   enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
     VT_INACTIVE_POWER_STATE = 4,
     VT_INACTIVE_TIMEOUT_US = 6
@@ -1287,8 +1635,8 @@ struct EdgeTpuInactivePowerConfig FLATBUFFERS_FINAL_CLASS : private flatbuffers:
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_INACTIVE_POWER_STATE) &&
-           VerifyField<int64_t>(verifier, VT_INACTIVE_TIMEOUT_US) &&
+           VerifyField<int32_t>(verifier, VT_INACTIVE_POWER_STATE, 4) &&
+           VerifyField<int64_t>(verifier, VT_INACTIVE_TIMEOUT_US, 8) &&
            verifier.EndTable();
   }
   EdgeTpuInactivePowerConfigT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -1297,6 +1645,7 @@ struct EdgeTpuInactivePowerConfig FLATBUFFERS_FINAL_CLASS : private flatbuffers:
 };
 
 struct EdgeTpuInactivePowerConfigBuilder {
+  typedef EdgeTpuInactivePowerConfig Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_inactive_power_state(tflite::EdgeTpuPowerState inactive_power_state) {
@@ -1309,7 +1658,6 @@ struct EdgeTpuInactivePowerConfigBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  EdgeTpuInactivePowerConfigBuilder &operator=(const EdgeTpuInactivePowerConfigBuilder &);
   flatbuffers::Offset<EdgeTpuInactivePowerConfig> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<EdgeTpuInactivePowerConfig>(end);
@@ -1331,28 +1679,30 @@ flatbuffers::Offset<EdgeTpuInactivePowerConfig> CreateEdgeTpuInactivePowerConfig
 
 struct EdgeTpuSettingsT : public flatbuffers::NativeTable {
   typedef EdgeTpuSettings TableType;
-  tflite::EdgeTpuPowerState inference_power_state;
-  std::vector<std::unique_ptr<tflite::EdgeTpuInactivePowerConfigT>> inactive_power_configs;
-  int32_t inference_priority;
-  std::unique_ptr<tflite::EdgeTpuDeviceSpecT> edgetpu_device_spec;
-  std::string model_token;
-  tflite::EdgeTpuSettings_::FloatTruncationType float_truncation_type;
-  EdgeTpuSettingsT()
-      : inference_power_state(tflite::EdgeTpuPowerState_UNDEFINED_POWERSTATE),
-        inference_priority(-1),
-        float_truncation_type(tflite::EdgeTpuSettings_::FloatTruncationType_UNSPECIFIED) {
-  }
+  tflite::EdgeTpuPowerState inference_power_state = tflite::EdgeTpuPowerState_UNDEFINED_POWERSTATE;
+  std::vector<std::unique_ptr<tflite::EdgeTpuInactivePowerConfigT>> inactive_power_configs{};
+  int32_t inference_priority = -1;
+  std::unique_ptr<tflite::EdgeTpuDeviceSpecT> edgetpu_device_spec{};
+  std::string model_token{};
+  tflite::EdgeTpuSettings_::FloatTruncationType float_truncation_type = tflite::EdgeTpuSettings_::FloatTruncationType_UNSPECIFIED;
+  tflite::EdgeTpuSettings_::QosClass qos_class = tflite::EdgeTpuSettings_::QosClass_QOS_UNDEFINED;
+  EdgeTpuSettingsT() = default;
+  EdgeTpuSettingsT(const EdgeTpuSettingsT &o);
+  EdgeTpuSettingsT(EdgeTpuSettingsT&&) FLATBUFFERS_NOEXCEPT = default;
+  EdgeTpuSettingsT &operator=(EdgeTpuSettingsT o) FLATBUFFERS_NOEXCEPT;
 };
 
 struct EdgeTpuSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef EdgeTpuSettingsT NativeTableType;
+  typedef EdgeTpuSettingsBuilder Builder;
   enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
     VT_INFERENCE_POWER_STATE = 4,
     VT_INACTIVE_POWER_CONFIGS = 6,
     VT_INFERENCE_PRIORITY = 8,
     VT_EDGETPU_DEVICE_SPEC = 10,
     VT_MODEL_TOKEN = 12,
-    VT_FLOAT_TRUNCATION_TYPE = 14
+    VT_FLOAT_TRUNCATION_TYPE = 14,
+    VT_QOS_CLASS = 16
   };
   tflite::EdgeTpuPowerState inference_power_state() const {
     return static_cast<tflite::EdgeTpuPowerState>(GetField<int32_t>(VT_INFERENCE_POWER_STATE, 0));
@@ -1372,18 +1722,22 @@ struct EdgeTpuSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   tflite::EdgeTpuSettings_::FloatTruncationType float_truncation_type() const {
     return static_cast<tflite::EdgeTpuSettings_::FloatTruncationType>(GetField<int32_t>(VT_FLOAT_TRUNCATION_TYPE, 0));
   }
+  tflite::EdgeTpuSettings_::QosClass qos_class() const {
+    return static_cast<tflite::EdgeTpuSettings_::QosClass>(GetField<int32_t>(VT_QOS_CLASS, 0));
+  }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_INFERENCE_POWER_STATE) &&
+           VerifyField<int32_t>(verifier, VT_INFERENCE_POWER_STATE, 4) &&
            VerifyOffset(verifier, VT_INACTIVE_POWER_CONFIGS) &&
            verifier.VerifyVector(inactive_power_configs()) &&
            verifier.VerifyVectorOfTables(inactive_power_configs()) &&
-           VerifyField<int32_t>(verifier, VT_INFERENCE_PRIORITY) &&
+           VerifyField<int32_t>(verifier, VT_INFERENCE_PRIORITY, 4) &&
            VerifyOffset(verifier, VT_EDGETPU_DEVICE_SPEC) &&
            verifier.VerifyTable(edgetpu_device_spec()) &&
            VerifyOffset(verifier, VT_MODEL_TOKEN) &&
            verifier.VerifyString(model_token()) &&
-           VerifyField<int32_t>(verifier, VT_FLOAT_TRUNCATION_TYPE) &&
+           VerifyField<int32_t>(verifier, VT_FLOAT_TRUNCATION_TYPE, 4) &&
+           VerifyField<int32_t>(verifier, VT_QOS_CLASS, 4) &&
            verifier.EndTable();
   }
   EdgeTpuSettingsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -1392,6 +1746,7 @@ struct EdgeTpuSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct EdgeTpuSettingsBuilder {
+  typedef EdgeTpuSettings Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_inference_power_state(tflite::EdgeTpuPowerState inference_power_state) {
@@ -1412,11 +1767,13 @@ struct EdgeTpuSettingsBuilder {
   void add_float_truncation_type(tflite::EdgeTpuSettings_::FloatTruncationType float_truncation_type) {
     fbb_.AddElement<int32_t>(EdgeTpuSettings::VT_FLOAT_TRUNCATION_TYPE, static_cast<int32_t>(float_truncation_type), 0);
   }
+  void add_qos_class(tflite::EdgeTpuSettings_::QosClass qos_class) {
+    fbb_.AddElement<int32_t>(EdgeTpuSettings::VT_QOS_CLASS, static_cast<int32_t>(qos_class), 0);
+  }
   explicit EdgeTpuSettingsBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  EdgeTpuSettingsBuilder &operator=(const EdgeTpuSettingsBuilder &);
   flatbuffers::Offset<EdgeTpuSettings> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<EdgeTpuSettings>(end);
@@ -1431,8 +1788,10 @@ inline flatbuffers::Offset<EdgeTpuSettings> CreateEdgeTpuSettings(
     int32_t inference_priority = -1,
     flatbuffers::Offset<tflite::EdgeTpuDeviceSpec> edgetpu_device_spec = 0,
     flatbuffers::Offset<flatbuffers::String> model_token = 0,
-    tflite::EdgeTpuSettings_::FloatTruncationType float_truncation_type = tflite::EdgeTpuSettings_::FloatTruncationType_UNSPECIFIED) {
+    tflite::EdgeTpuSettings_::FloatTruncationType float_truncation_type = tflite::EdgeTpuSettings_::FloatTruncationType_UNSPECIFIED,
+    tflite::EdgeTpuSettings_::QosClass qos_class = tflite::EdgeTpuSettings_::QosClass_QOS_UNDEFINED) {
   EdgeTpuSettingsBuilder builder_(_fbb);
+  builder_.add_qos_class(qos_class);
   builder_.add_float_truncation_type(float_truncation_type);
   builder_.add_model_token(model_token);
   builder_.add_edgetpu_device_spec(edgetpu_device_spec);
@@ -1449,7 +1808,8 @@ inline flatbuffers::Offset<EdgeTpuSettings> CreateEdgeTpuSettingsDirect(
     int32_t inference_priority = -1,
     flatbuffers::Offset<tflite::EdgeTpuDeviceSpec> edgetpu_device_spec = 0,
     const char *model_token = nullptr,
-    tflite::EdgeTpuSettings_::FloatTruncationType float_truncation_type = tflite::EdgeTpuSettings_::FloatTruncationType_UNSPECIFIED) {
+    tflite::EdgeTpuSettings_::FloatTruncationType float_truncation_type = tflite::EdgeTpuSettings_::FloatTruncationType_UNSPECIFIED,
+    tflite::EdgeTpuSettings_::QosClass qos_class = tflite::EdgeTpuSettings_::QosClass_QOS_UNDEFINED) {
   auto inactive_power_configs__ = inactive_power_configs ? _fbb.CreateVector<flatbuffers::Offset<tflite::EdgeTpuInactivePowerConfig>>(*inactive_power_configs) : 0;
   auto model_token__ = model_token ? _fbb.CreateString(model_token) : 0;
   return tflite::CreateEdgeTpuSettings(
@@ -1459,26 +1819,23 @@ inline flatbuffers::Offset<EdgeTpuSettings> CreateEdgeTpuSettingsDirect(
       inference_priority,
       edgetpu_device_spec,
       model_token__,
-      float_truncation_type);
+      float_truncation_type,
+      qos_class);
 }
 
 flatbuffers::Offset<EdgeTpuSettings> CreateEdgeTpuSettings(flatbuffers::FlatBufferBuilder &_fbb, const EdgeTpuSettingsT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
 
 struct CoralSettingsT : public flatbuffers::NativeTable {
   typedef CoralSettings TableType;
-  std::string device;
-  tflite::CoralSettings_::Performance performance;
-  bool usb_always_dfu;
-  int32_t usb_max_bulk_in_queue_length;
-  CoralSettingsT()
-      : performance(tflite::CoralSettings_::Performance_UNDEFINED),
-        usb_always_dfu(false),
-        usb_max_bulk_in_queue_length(0) {
-  }
+  std::string device{};
+  tflite::CoralSettings_::Performance performance = tflite::CoralSettings_::Performance_UNDEFINED;
+  bool usb_always_dfu = false;
+  int32_t usb_max_bulk_in_queue_length = 0;
 };
 
 struct CoralSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef CoralSettingsT NativeTableType;
+  typedef CoralSettingsBuilder Builder;
   enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
     VT_DEVICE = 4,
     VT_PERFORMANCE = 6,
@@ -1501,9 +1858,9 @@ struct CoralSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     return VerifyTableStart(verifier) &&
            VerifyOffset(verifier, VT_DEVICE) &&
            verifier.VerifyString(device()) &&
-           VerifyField<int32_t>(verifier, VT_PERFORMANCE) &&
-           VerifyField<uint8_t>(verifier, VT_USB_ALWAYS_DFU) &&
-           VerifyField<int32_t>(verifier, VT_USB_MAX_BULK_IN_QUEUE_LENGTH) &&
+           VerifyField<int32_t>(verifier, VT_PERFORMANCE, 4) &&
+           VerifyField<uint8_t>(verifier, VT_USB_ALWAYS_DFU, 1) &&
+           VerifyField<int32_t>(verifier, VT_USB_MAX_BULK_IN_QUEUE_LENGTH, 4) &&
            verifier.EndTable();
   }
   CoralSettingsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -1512,6 +1869,7 @@ struct CoralSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct CoralSettingsBuilder {
+  typedef CoralSettings Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_device(flatbuffers::Offset<flatbuffers::String> device) {
@@ -1530,7 +1888,6 @@ struct CoralSettingsBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  CoralSettingsBuilder &operator=(const CoralSettingsBuilder &);
   flatbuffers::Offset<CoralSettings> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<CoralSettings>(end);
@@ -1571,14 +1928,12 @@ flatbuffers::Offset<CoralSettings> CreateCoralSettings(flatbuffers::FlatBufferBu
 
 struct CPUSettingsT : public flatbuffers::NativeTable {
   typedef CPUSettings TableType;
-  int32_t num_threads;
-  CPUSettingsT()
-      : num_threads(-1) {
-  }
+  int32_t num_threads = -1;
 };
 
 struct CPUSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef CPUSettingsT NativeTableType;
+  typedef CPUSettingsBuilder Builder;
   enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
     VT_NUM_THREADS = 4
   };
@@ -1587,7 +1942,7 @@ struct CPUSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_NUM_THREADS) &&
+           VerifyField<int32_t>(verifier, VT_NUM_THREADS, 4) &&
            verifier.EndTable();
   }
   CPUSettingsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -1596,6 +1951,7 @@ struct CPUSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct CPUSettingsBuilder {
+  typedef CPUSettings Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_num_threads(int32_t num_threads) {
@@ -1605,7 +1961,6 @@ struct CPUSettingsBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  CPUSettingsBuilder &operator=(const CPUSettingsBuilder &);
   flatbuffers::Offset<CPUSettings> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<CPUSettings>(end);
@@ -1625,35 +1980,40 @@ flatbuffers::Offset<CPUSettings> CreateCPUSettings(flatbuffers::FlatBufferBuilde
 
 struct TFLiteSettingsT : public flatbuffers::NativeTable {
   typedef TFLiteSettings TableType;
-  tflite::Delegate delegate;
-  std::unique_ptr<tflite::NNAPISettingsT> nnapi_settings;
-  std::unique_ptr<tflite::GPUSettingsT> gpu_settings;
-  std::unique_ptr<tflite::HexagonSettingsT> hexagon_settings;
-  std::unique_ptr<tflite::XNNPackSettingsT> xnnpack_settings;
-  std::unique_ptr<tflite::CPUSettingsT> cpu_settings;
-  int32_t max_delegated_partitions;
-  std::unique_ptr<tflite::EdgeTpuSettingsT> edgetpu_settings;
-  std::unique_ptr<tflite::CoralSettingsT> coral_settings;
-  std::unique_ptr<tflite::FallbackSettingsT> fallback_settings;
-  TFLiteSettingsT()
-      : delegate(tflite::Delegate_NONE),
-        max_delegated_partitions(0) {
-  }
+  tflite::Delegate delegate = tflite::Delegate_NONE;
+  std::unique_ptr<tflite::NNAPISettingsT> nnapi_settings{};
+  std::unique_ptr<tflite::GPUSettingsT> gpu_settings{};
+  std::unique_ptr<tflite::HexagonSettingsT> hexagon_settings{};
+  std::unique_ptr<tflite::XNNPackSettingsT> xnnpack_settings{};
+  std::unique_ptr<tflite::CoreMLSettingsT> coreml_settings{};
+  std::unique_ptr<tflite::CPUSettingsT> cpu_settings{};
+  int32_t max_delegated_partitions = 0;
+  std::unique_ptr<tflite::EdgeTpuSettingsT> edgetpu_settings{};
+  std::unique_ptr<tflite::CoralSettingsT> coral_settings{};
+  std::unique_ptr<tflite::FallbackSettingsT> fallback_settings{};
+  bool disable_default_delegates = false;
+  TFLiteSettingsT() = default;
+  TFLiteSettingsT(const TFLiteSettingsT &o);
+  TFLiteSettingsT(TFLiteSettingsT&&) FLATBUFFERS_NOEXCEPT = default;
+  TFLiteSettingsT &operator=(TFLiteSettingsT o) FLATBUFFERS_NOEXCEPT;
 };
 
 struct TFLiteSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef TFLiteSettingsT NativeTableType;
+  typedef TFLiteSettingsBuilder Builder;
   enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
     VT_DELEGATE = 4,
     VT_NNAPI_SETTINGS = 6,
     VT_GPU_SETTINGS = 8,
     VT_HEXAGON_SETTINGS = 10,
     VT_XNNPACK_SETTINGS = 12,
-    VT_CPU_SETTINGS = 14,
-    VT_MAX_DELEGATED_PARTITIONS = 16,
-    VT_EDGETPU_SETTINGS = 18,
-    VT_CORAL_SETTINGS = 20,
-    VT_FALLBACK_SETTINGS = 22
+    VT_COREML_SETTINGS = 14,
+    VT_CPU_SETTINGS = 16,
+    VT_MAX_DELEGATED_PARTITIONS = 18,
+    VT_EDGETPU_SETTINGS = 20,
+    VT_CORAL_SETTINGS = 22,
+    VT_FALLBACK_SETTINGS = 24,
+    VT_DISABLE_DEFAULT_DELEGATES = 26
   };
   tflite::Delegate delegate() const {
     return static_cast<tflite::Delegate>(GetField<int32_t>(VT_DELEGATE, 0));
@@ -1670,6 +2030,9 @@ struct TFLiteSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   const tflite::XNNPackSettings *xnnpack_settings() const {
     return GetPointer<const tflite::XNNPackSettings *>(VT_XNNPACK_SETTINGS);
   }
+  const tflite::CoreMLSettings *coreml_settings() const {
+    return GetPointer<const tflite::CoreMLSettings *>(VT_COREML_SETTINGS);
+  }
   const tflite::CPUSettings *cpu_settings() const {
     return GetPointer<const tflite::CPUSettings *>(VT_CPU_SETTINGS);
   }
@@ -1685,9 +2048,12 @@ struct TFLiteSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   const tflite::FallbackSettings *fallback_settings() const {
     return GetPointer<const tflite::FallbackSettings *>(VT_FALLBACK_SETTINGS);
   }
+  bool disable_default_delegates() const {
+    return GetField<uint8_t>(VT_DISABLE_DEFAULT_DELEGATES, 0) != 0;
+  }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_DELEGATE) &&
+           VerifyField<int32_t>(verifier, VT_DELEGATE, 4) &&
            VerifyOffset(verifier, VT_NNAPI_SETTINGS) &&
            verifier.VerifyTable(nnapi_settings()) &&
            VerifyOffset(verifier, VT_GPU_SETTINGS) &&
@@ -1696,15 +2062,18 @@ struct TFLiteSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
            verifier.VerifyTable(hexagon_settings()) &&
            VerifyOffset(verifier, VT_XNNPACK_SETTINGS) &&
            verifier.VerifyTable(xnnpack_settings()) &&
+           VerifyOffset(verifier, VT_COREML_SETTINGS) &&
+           verifier.VerifyTable(coreml_settings()) &&
            VerifyOffset(verifier, VT_CPU_SETTINGS) &&
            verifier.VerifyTable(cpu_settings()) &&
-           VerifyField<int32_t>(verifier, VT_MAX_DELEGATED_PARTITIONS) &&
+           VerifyField<int32_t>(verifier, VT_MAX_DELEGATED_PARTITIONS, 4) &&
            VerifyOffset(verifier, VT_EDGETPU_SETTINGS) &&
            verifier.VerifyTable(edgetpu_settings()) &&
            VerifyOffset(verifier, VT_CORAL_SETTINGS) &&
            verifier.VerifyTable(coral_settings()) &&
            VerifyOffset(verifier, VT_FALLBACK_SETTINGS) &&
            verifier.VerifyTable(fallback_settings()) &&
+           VerifyField<uint8_t>(verifier, VT_DISABLE_DEFAULT_DELEGATES, 1) &&
            verifier.EndTable();
   }
   TFLiteSettingsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -1713,6 +2082,7 @@ struct TFLiteSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct TFLiteSettingsBuilder {
+  typedef TFLiteSettings Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_delegate(tflite::Delegate delegate) {
@@ -1730,6 +2100,9 @@ struct TFLiteSettingsBuilder {
   void add_xnnpack_settings(flatbuffers::Offset<tflite::XNNPackSettings> xnnpack_settings) {
     fbb_.AddOffset(TFLiteSettings::VT_XNNPACK_SETTINGS, xnnpack_settings);
   }
+  void add_coreml_settings(flatbuffers::Offset<tflite::CoreMLSettings> coreml_settings) {
+    fbb_.AddOffset(TFLiteSettings::VT_COREML_SETTINGS, coreml_settings);
+  }
   void add_cpu_settings(flatbuffers::Offset<tflite::CPUSettings> cpu_settings) {
     fbb_.AddOffset(TFLiteSettings::VT_CPU_SETTINGS, cpu_settings);
   }
@@ -1745,11 +2118,13 @@ struct TFLiteSettingsBuilder {
   void add_fallback_settings(flatbuffers::Offset<tflite::FallbackSettings> fallback_settings) {
     fbb_.AddOffset(TFLiteSettings::VT_FALLBACK_SETTINGS, fallback_settings);
   }
+  void add_disable_default_delegates(bool disable_default_delegates) {
+    fbb_.AddElement<uint8_t>(TFLiteSettings::VT_DISABLE_DEFAULT_DELEGATES, static_cast<uint8_t>(disable_default_delegates), 0);
+  }
   explicit TFLiteSettingsBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  TFLiteSettingsBuilder &operator=(const TFLiteSettingsBuilder &);
   flatbuffers::Offset<TFLiteSettings> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<TFLiteSettings>(end);
@@ -1764,22 +2139,26 @@ inline flatbuffers::Offset<TFLiteSettings> CreateTFLiteSettings(
     flatbuffers::Offset<tflite::GPUSettings> gpu_settings = 0,
     flatbuffers::Offset<tflite::HexagonSettings> hexagon_settings = 0,
     flatbuffers::Offset<tflite::XNNPackSettings> xnnpack_settings = 0,
+    flatbuffers::Offset<tflite::CoreMLSettings> coreml_settings = 0,
     flatbuffers::Offset<tflite::CPUSettings> cpu_settings = 0,
     int32_t max_delegated_partitions = 0,
     flatbuffers::Offset<tflite::EdgeTpuSettings> edgetpu_settings = 0,
     flatbuffers::Offset<tflite::CoralSettings> coral_settings = 0,
-    flatbuffers::Offset<tflite::FallbackSettings> fallback_settings = 0) {
+    flatbuffers::Offset<tflite::FallbackSettings> fallback_settings = 0,
+    bool disable_default_delegates = false) {
   TFLiteSettingsBuilder builder_(_fbb);
   builder_.add_fallback_settings(fallback_settings);
   builder_.add_coral_settings(coral_settings);
   builder_.add_edgetpu_settings(edgetpu_settings);
   builder_.add_max_delegated_partitions(max_delegated_partitions);
   builder_.add_cpu_settings(cpu_settings);
+  builder_.add_coreml_settings(coreml_settings);
   builder_.add_xnnpack_settings(xnnpack_settings);
   builder_.add_hexagon_settings(hexagon_settings);
   builder_.add_gpu_settings(gpu_settings);
   builder_.add_nnapi_settings(nnapi_settings);
   builder_.add_delegate(delegate);
+  builder_.add_disable_default_delegates(disable_default_delegates);
   return builder_.Finish();
 }
 
@@ -1787,16 +2166,13 @@ flatbuffers::Offset<TFLiteSettings> CreateTFLiteSettings(flatbuffers::FlatBuffer
 
 struct FallbackSettingsT : public flatbuffers::NativeTable {
   typedef FallbackSettings TableType;
-  bool allow_automatic_fallback_on_compilation_error;
-  bool allow_automatic_fallback_on_execution_error;
-  FallbackSettingsT()
-      : allow_automatic_fallback_on_compilation_error(false),
-        allow_automatic_fallback_on_execution_error(false) {
-  }
+  bool allow_automatic_fallback_on_compilation_error = false;
+  bool allow_automatic_fallback_on_execution_error = false;
 };
 
 struct FallbackSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef FallbackSettingsT NativeTableType;
+  typedef FallbackSettingsBuilder Builder;
   enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
     VT_ALLOW_AUTOMATIC_FALLBACK_ON_COMPILATION_ERROR = 4,
     VT_ALLOW_AUTOMATIC_FALLBACK_ON_EXECUTION_ERROR = 6
@@ -1809,8 +2185,8 @@ struct FallbackSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<uint8_t>(verifier, VT_ALLOW_AUTOMATIC_FALLBACK_ON_COMPILATION_ERROR) &&
-           VerifyField<uint8_t>(verifier, VT_ALLOW_AUTOMATIC_FALLBACK_ON_EXECUTION_ERROR) &&
+           VerifyField<uint8_t>(verifier, VT_ALLOW_AUTOMATIC_FALLBACK_ON_COMPILATION_ERROR, 1) &&
+           VerifyField<uint8_t>(verifier, VT_ALLOW_AUTOMATIC_FALLBACK_ON_EXECUTION_ERROR, 1) &&
            verifier.EndTable();
   }
   FallbackSettingsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -1819,6 +2195,7 @@ struct FallbackSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct FallbackSettingsBuilder {
+  typedef FallbackSettings Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_allow_automatic_fallback_on_compilation_error(bool allow_automatic_fallback_on_compilation_error) {
@@ -1831,7 +2208,6 @@ struct FallbackSettingsBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  FallbackSettingsBuilder &operator=(const FallbackSettingsBuilder &);
   flatbuffers::Offset<FallbackSettings> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<FallbackSettings>(end);
@@ -1853,14 +2229,13 @@ flatbuffers::Offset<FallbackSettings> CreateFallbackSettings(flatbuffers::FlatBu
 
 struct BenchmarkMetricT : public flatbuffers::NativeTable {
   typedef BenchmarkMetric TableType;
-  std::string name;
-  std::vector<float> values;
-  BenchmarkMetricT() {
-  }
+  std::string name{};
+  std::vector<float> values{};
 };
 
 struct BenchmarkMetric FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef BenchmarkMetricT NativeTableType;
+  typedef BenchmarkMetricBuilder Builder;
   enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
     VT_NAME = 4,
     VT_VALUES = 6
@@ -1885,6 +2260,7 @@ struct BenchmarkMetric FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct BenchmarkMetricBuilder {
+  typedef BenchmarkMetric Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_name(flatbuffers::Offset<flatbuffers::String> name) {
@@ -1897,7 +2273,6 @@ struct BenchmarkMetricBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  BenchmarkMetricBuilder &operator=(const BenchmarkMetricBuilder &);
   flatbuffers::Offset<BenchmarkMetric> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<BenchmarkMetric>(end);
@@ -1931,19 +2306,20 @@ flatbuffers::Offset<BenchmarkMetric> CreateBenchmarkMetric(flatbuffers::FlatBuff
 
 struct BenchmarkResultT : public flatbuffers::NativeTable {
   typedef BenchmarkResult TableType;
-  std::vector<int64_t> initialization_time_us;
-  std::vector<int64_t> inference_time_us;
-  int32_t max_memory_kb;
-  bool ok;
-  std::vector<std::unique_ptr<tflite::BenchmarkMetricT>> metrics;
-  BenchmarkResultT()
-      : max_memory_kb(0),
-        ok(false) {
-  }
+  std::vector<int64_t> initialization_time_us{};
+  std::vector<int64_t> inference_time_us{};
+  int32_t max_memory_kb = 0;
+  bool ok = false;
+  std::vector<std::unique_ptr<tflite::BenchmarkMetricT>> metrics{};
+  BenchmarkResultT() = default;
+  BenchmarkResultT(const BenchmarkResultT &o);
+  BenchmarkResultT(BenchmarkResultT&&) FLATBUFFERS_NOEXCEPT = default;
+  BenchmarkResultT &operator=(BenchmarkResultT o) FLATBUFFERS_NOEXCEPT;
 };
 
 struct BenchmarkResult FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef BenchmarkResultT NativeTableType;
+  typedef BenchmarkResultBuilder Builder;
   enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
     VT_INITIALIZATION_TIME_US = 4,
     VT_INFERENCE_TIME_US = 6,
@@ -1972,8 +2348,8 @@ struct BenchmarkResult FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
            verifier.VerifyVector(initialization_time_us()) &&
            VerifyOffset(verifier, VT_INFERENCE_TIME_US) &&
            verifier.VerifyVector(inference_time_us()) &&
-           VerifyField<int32_t>(verifier, VT_MAX_MEMORY_KB) &&
-           VerifyField<uint8_t>(verifier, VT_OK) &&
+           VerifyField<int32_t>(verifier, VT_MAX_MEMORY_KB, 4) &&
+           VerifyField<uint8_t>(verifier, VT_OK, 1) &&
            VerifyOffset(verifier, VT_METRICS) &&
            verifier.VerifyVector(metrics()) &&
            verifier.VerifyVectorOfTables(metrics()) &&
@@ -1985,6 +2361,7 @@ struct BenchmarkResult FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct BenchmarkResultBuilder {
+  typedef BenchmarkResult Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_initialization_time_us(flatbuffers::Offset<flatbuffers::Vector<int64_t>> initialization_time_us) {
@@ -2006,7 +2383,6 @@ struct BenchmarkResultBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  BenchmarkResultBuilder &operator=(const BenchmarkResultBuilder &);
   flatbuffers::Offset<BenchmarkResult> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<BenchmarkResult>(end);
@@ -2053,18 +2429,14 @@ flatbuffers::Offset<BenchmarkResult> CreateBenchmarkResult(flatbuffers::FlatBuff
 
 struct ErrorCodeT : public flatbuffers::NativeTable {
   typedef ErrorCode TableType;
-  tflite::Delegate source;
-  int32_t tflite_error;
-  int64_t underlying_api_error;
-  ErrorCodeT()
-      : source(tflite::Delegate_NONE),
-        tflite_error(0),
-        underlying_api_error(0) {
-  }
+  tflite::Delegate source = tflite::Delegate_NONE;
+  int32_t tflite_error = 0;
+  int64_t underlying_api_error = 0;
 };
 
 struct ErrorCode FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef ErrorCodeT NativeTableType;
+  typedef ErrorCodeBuilder Builder;
   enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
     VT_SOURCE = 4,
     VT_TFLITE_ERROR = 6,
@@ -2081,9 +2453,9 @@ struct ErrorCode FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_SOURCE) &&
-           VerifyField<int32_t>(verifier, VT_TFLITE_ERROR) &&
-           VerifyField<int64_t>(verifier, VT_UNDERLYING_API_ERROR) &&
+           VerifyField<int32_t>(verifier, VT_SOURCE, 4) &&
+           VerifyField<int32_t>(verifier, VT_TFLITE_ERROR, 4) &&
+           VerifyField<int64_t>(verifier, VT_UNDERLYING_API_ERROR, 8) &&
            verifier.EndTable();
   }
   ErrorCodeT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -2092,6 +2464,7 @@ struct ErrorCode FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct ErrorCodeBuilder {
+  typedef ErrorCode Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_source(tflite::Delegate source) {
@@ -2107,7 +2480,6 @@ struct ErrorCodeBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  ErrorCodeBuilder &operator=(const ErrorCodeBuilder &);
   flatbuffers::Offset<ErrorCode> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<ErrorCode>(end);
@@ -2131,21 +2503,20 @@ flatbuffers::Offset<ErrorCode> CreateErrorCode(flatbuffers::FlatBufferBuilder &_
 
 struct BenchmarkErrorT : public flatbuffers::NativeTable {
   typedef BenchmarkError TableType;
-  tflite::BenchmarkStage stage;
-  int32_t exit_code;
-  int32_t signal;
-  std::vector<std::unique_ptr<tflite::ErrorCodeT>> error_code;
-  int32_t mini_benchmark_error_code;
-  BenchmarkErrorT()
-      : stage(tflite::BenchmarkStage_UNKNOWN),
-        exit_code(0),
-        signal(0),
-        mini_benchmark_error_code(0) {
-  }
+  tflite::BenchmarkStage stage = tflite::BenchmarkStage_UNKNOWN;
+  int32_t exit_code = 0;
+  int32_t signal = 0;
+  std::vector<std::unique_ptr<tflite::ErrorCodeT>> error_code{};
+  int32_t mini_benchmark_error_code = 0;
+  BenchmarkErrorT() = default;
+  BenchmarkErrorT(const BenchmarkErrorT &o);
+  BenchmarkErrorT(BenchmarkErrorT&&) FLATBUFFERS_NOEXCEPT = default;
+  BenchmarkErrorT &operator=(BenchmarkErrorT o) FLATBUFFERS_NOEXCEPT;
 };
 
 struct BenchmarkError FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef BenchmarkErrorT NativeTableType;
+  typedef BenchmarkErrorBuilder Builder;
   enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
     VT_STAGE = 4,
     VT_EXIT_CODE = 6,
@@ -2170,13 +2541,13 @@ struct BenchmarkError FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_STAGE) &&
-           VerifyField<int32_t>(verifier, VT_EXIT_CODE) &&
-           VerifyField<int32_t>(verifier, VT_SIGNAL) &&
+           VerifyField<int32_t>(verifier, VT_STAGE, 4) &&
+           VerifyField<int32_t>(verifier, VT_EXIT_CODE, 4) &&
+           VerifyField<int32_t>(verifier, VT_SIGNAL, 4) &&
            VerifyOffset(verifier, VT_ERROR_CODE) &&
            verifier.VerifyVector(error_code()) &&
            verifier.VerifyVectorOfTables(error_code()) &&
-           VerifyField<int32_t>(verifier, VT_MINI_BENCHMARK_ERROR_CODE) &&
+           VerifyField<int32_t>(verifier, VT_MINI_BENCHMARK_ERROR_CODE, 4) &&
            verifier.EndTable();
   }
   BenchmarkErrorT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -2185,6 +2556,7 @@ struct BenchmarkError FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct BenchmarkErrorBuilder {
+  typedef BenchmarkError Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_stage(tflite::BenchmarkStage stage) {
@@ -2206,7 +2578,6 @@ struct BenchmarkErrorBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  BenchmarkErrorBuilder &operator=(const BenchmarkErrorBuilder &);
   flatbuffers::Offset<BenchmarkError> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<BenchmarkError>(end);
@@ -2251,21 +2622,21 @@ flatbuffers::Offset<BenchmarkError> CreateBenchmarkError(flatbuffers::FlatBuffer
 
 struct BenchmarkEventT : public flatbuffers::NativeTable {
   typedef BenchmarkEvent TableType;
-  std::unique_ptr<tflite::TFLiteSettingsT> tflite_settings;
-  tflite::BenchmarkEventType event_type;
-  std::unique_ptr<tflite::BenchmarkResultT> result;
-  std::unique_ptr<tflite::BenchmarkErrorT> error;
-  int64_t boottime_us;
-  int64_t wallclock_us;
-  BenchmarkEventT()
-      : event_type(tflite::BenchmarkEventType_UNDEFINED_BENCHMARK_EVENT_TYPE),
-        boottime_us(0),
-        wallclock_us(0) {
-  }
+  std::unique_ptr<tflite::TFLiteSettingsT> tflite_settings{};
+  tflite::BenchmarkEventType event_type = tflite::BenchmarkEventType_UNDEFINED_BENCHMARK_EVENT_TYPE;
+  std::unique_ptr<tflite::BenchmarkResultT> result{};
+  std::unique_ptr<tflite::BenchmarkErrorT> error{};
+  int64_t boottime_us = 0;
+  int64_t wallclock_us = 0;
+  BenchmarkEventT() = default;
+  BenchmarkEventT(const BenchmarkEventT &o);
+  BenchmarkEventT(BenchmarkEventT&&) FLATBUFFERS_NOEXCEPT = default;
+  BenchmarkEventT &operator=(BenchmarkEventT o) FLATBUFFERS_NOEXCEPT;
 };
 
 struct BenchmarkEvent FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef BenchmarkEventT NativeTableType;
+  typedef BenchmarkEventBuilder Builder;
   enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
     VT_TFLITE_SETTINGS = 4,
     VT_EVENT_TYPE = 6,
@@ -2296,13 +2667,13 @@ struct BenchmarkEvent FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     return VerifyTableStart(verifier) &&
            VerifyOffset(verifier, VT_TFLITE_SETTINGS) &&
            verifier.VerifyTable(tflite_settings()) &&
-           VerifyField<int32_t>(verifier, VT_EVENT_TYPE) &&
+           VerifyField<int32_t>(verifier, VT_EVENT_TYPE, 4) &&
            VerifyOffset(verifier, VT_RESULT) &&
            verifier.VerifyTable(result()) &&
            VerifyOffset(verifier, VT_ERROR) &&
            verifier.VerifyTable(error()) &&
-           VerifyField<int64_t>(verifier, VT_BOOTTIME_US) &&
-           VerifyField<int64_t>(verifier, VT_WALLCLOCK_US) &&
+           VerifyField<int64_t>(verifier, VT_BOOTTIME_US, 8) &&
+           VerifyField<int64_t>(verifier, VT_WALLCLOCK_US, 8) &&
            verifier.EndTable();
   }
   BenchmarkEventT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -2311,6 +2682,7 @@ struct BenchmarkEvent FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct BenchmarkEventBuilder {
+  typedef BenchmarkEvent Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_tflite_settings(flatbuffers::Offset<tflite::TFLiteSettings> tflite_settings) {
@@ -2335,7 +2707,6 @@ struct BenchmarkEventBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  BenchmarkEventBuilder &operator=(const BenchmarkEventBuilder &);
   flatbuffers::Offset<BenchmarkEvent> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<BenchmarkEvent>(end);
@@ -2365,17 +2736,18 @@ flatbuffers::Offset<BenchmarkEvent> CreateBenchmarkEvent(flatbuffers::FlatBuffer
 
 struct BestAccelerationDecisionT : public flatbuffers::NativeTable {
   typedef BestAccelerationDecision TableType;
-  int32_t number_of_source_events;
-  std::unique_ptr<tflite::BenchmarkEventT> min_latency_event;
-  int64_t min_inference_time_us;
-  BestAccelerationDecisionT()
-      : number_of_source_events(0),
-        min_inference_time_us(0) {
-  }
+  int32_t number_of_source_events = 0;
+  std::unique_ptr<tflite::BenchmarkEventT> min_latency_event{};
+  int64_t min_inference_time_us = 0;
+  BestAccelerationDecisionT() = default;
+  BestAccelerationDecisionT(const BestAccelerationDecisionT &o);
+  BestAccelerationDecisionT(BestAccelerationDecisionT&&) FLATBUFFERS_NOEXCEPT = default;
+  BestAccelerationDecisionT &operator=(BestAccelerationDecisionT o) FLATBUFFERS_NOEXCEPT;
 };
 
 struct BestAccelerationDecision FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef BestAccelerationDecisionT NativeTableType;
+  typedef BestAccelerationDecisionBuilder Builder;
   enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
     VT_NUMBER_OF_SOURCE_EVENTS = 4,
     VT_MIN_LATENCY_EVENT = 6,
@@ -2392,10 +2764,10 @@ struct BestAccelerationDecision FLATBUFFERS_FINAL_CLASS : private flatbuffers::T
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_NUMBER_OF_SOURCE_EVENTS) &&
+           VerifyField<int32_t>(verifier, VT_NUMBER_OF_SOURCE_EVENTS, 4) &&
            VerifyOffset(verifier, VT_MIN_LATENCY_EVENT) &&
            verifier.VerifyTable(min_latency_event()) &&
-           VerifyField<int64_t>(verifier, VT_MIN_INFERENCE_TIME_US) &&
+           VerifyField<int64_t>(verifier, VT_MIN_INFERENCE_TIME_US, 8) &&
            verifier.EndTable();
   }
   BestAccelerationDecisionT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -2404,6 +2776,7 @@ struct BestAccelerationDecision FLATBUFFERS_FINAL_CLASS : private flatbuffers::T
 };
 
 struct BestAccelerationDecisionBuilder {
+  typedef BestAccelerationDecision Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_number_of_source_events(int32_t number_of_source_events) {
@@ -2419,7 +2792,6 @@ struct BestAccelerationDecisionBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  BestAccelerationDecisionBuilder &operator=(const BestAccelerationDecisionBuilder &);
   flatbuffers::Offset<BestAccelerationDecision> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<BestAccelerationDecision>(end);
@@ -2443,14 +2815,12 @@ flatbuffers::Offset<BestAccelerationDecision> CreateBestAccelerationDecision(fla
 
 struct BenchmarkInitializationFailureT : public flatbuffers::NativeTable {
   typedef BenchmarkInitializationFailure TableType;
-  int32_t initialization_status;
-  BenchmarkInitializationFailureT()
-      : initialization_status(0) {
-  }
+  int32_t initialization_status = 0;
 };
 
 struct BenchmarkInitializationFailure FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef BenchmarkInitializationFailureT NativeTableType;
+  typedef BenchmarkInitializationFailureBuilder Builder;
   enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
     VT_INITIALIZATION_STATUS = 4
   };
@@ -2459,7 +2829,7 @@ struct BenchmarkInitializationFailure FLATBUFFERS_FINAL_CLASS : private flatbuff
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_INITIALIZATION_STATUS) &&
+           VerifyField<int32_t>(verifier, VT_INITIALIZATION_STATUS, 4) &&
            verifier.EndTable();
   }
   BenchmarkInitializationFailureT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -2468,6 +2838,7 @@ struct BenchmarkInitializationFailure FLATBUFFERS_FINAL_CLASS : private flatbuff
 };
 
 struct BenchmarkInitializationFailureBuilder {
+  typedef BenchmarkInitializationFailure Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_initialization_status(int32_t initialization_status) {
@@ -2477,7 +2848,6 @@ struct BenchmarkInitializationFailureBuilder {
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  BenchmarkInitializationFailureBuilder &operator=(const BenchmarkInitializationFailureBuilder &);
   flatbuffers::Offset<BenchmarkInitializationFailure> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<BenchmarkInitializationFailure>(end);
@@ -2497,20 +2867,24 @@ flatbuffers::Offset<BenchmarkInitializationFailure> CreateBenchmarkInitializatio
 
 struct MiniBenchmarkEventT : public flatbuffers::NativeTable {
   typedef MiniBenchmarkEvent TableType;
-  bool is_log_flushing_event;
-  std::unique_ptr<tflite::BestAccelerationDecisionT> best_acceleration_decision;
-  std::unique_ptr<tflite::BenchmarkInitializationFailureT> initialization_failure;
-  MiniBenchmarkEventT()
-      : is_log_flushing_event(false) {
-  }
+  bool is_log_flushing_event = false;
+  std::unique_ptr<tflite::BestAccelerationDecisionT> best_acceleration_decision{};
+  std::unique_ptr<tflite::BenchmarkInitializationFailureT> initialization_failure{};
+  std::unique_ptr<tflite::BenchmarkEventT> benchmark_event{};
+  MiniBenchmarkEventT() = default;
+  MiniBenchmarkEventT(const MiniBenchmarkEventT &o);
+  MiniBenchmarkEventT(MiniBenchmarkEventT&&) FLATBUFFERS_NOEXCEPT = default;
+  MiniBenchmarkEventT &operator=(MiniBenchmarkEventT o) FLATBUFFERS_NOEXCEPT;
 };
 
 struct MiniBenchmarkEvent FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   typedef MiniBenchmarkEventT NativeTableType;
+  typedef MiniBenchmarkEventBuilder Builder;
   enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
     VT_IS_LOG_FLUSHING_EVENT = 4,
     VT_BEST_ACCELERATION_DECISION = 6,
-    VT_INITIALIZATION_FAILURE = 8
+    VT_INITIALIZATION_FAILURE = 8,
+    VT_BENCHMARK_EVENT = 10
   };
   bool is_log_flushing_event() const {
     return GetField<uint8_t>(VT_IS_LOG_FLUSHING_EVENT, 0) != 0;
@@ -2521,13 +2895,18 @@ struct MiniBenchmarkEvent FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   const tflite::BenchmarkInitializationFailure *initialization_failure() const {
     return GetPointer<const tflite::BenchmarkInitializationFailure *>(VT_INITIALIZATION_FAILURE);
   }
+  const tflite::BenchmarkEvent *benchmark_event() const {
+    return GetPointer<const tflite::BenchmarkEvent *>(VT_BENCHMARK_EVENT);
+  }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<uint8_t>(verifier, VT_IS_LOG_FLUSHING_EVENT) &&
+           VerifyField<uint8_t>(verifier, VT_IS_LOG_FLUSHING_EVENT, 1) &&
            VerifyOffset(verifier, VT_BEST_ACCELERATION_DECISION) &&
            verifier.VerifyTable(best_acceleration_decision()) &&
            VerifyOffset(verifier, VT_INITIALIZATION_FAILURE) &&
            verifier.VerifyTable(initialization_failure()) &&
+           VerifyOffset(verifier, VT_BENCHMARK_EVENT) &&
+           verifier.VerifyTable(benchmark_event()) &&
            verifier.EndTable();
   }
   MiniBenchmarkEventT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -2536,6 +2915,7 @@ struct MiniBenchmarkEvent FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
 };
 
 struct MiniBenchmarkEventBuilder {
+  typedef MiniBenchmarkEvent Table;
   flatbuffers::FlatBufferBuilder &fbb_;
   flatbuffers::uoffset_t start_;
   void add_is_log_flushing_event(bool is_log_flushing_event) {
@@ -2547,11 +2927,13 @@ struct MiniBenchmarkEventBuilder {
   void add_initialization_failure(flatbuffers::Offset<tflite::BenchmarkInitializationFailure> initialization_failure) {
     fbb_.AddOffset(MiniBenchmarkEvent::VT_INITIALIZATION_FAILURE, initialization_failure);
   }
+  void add_benchmark_event(flatbuffers::Offset<tflite::BenchmarkEvent> benchmark_event) {
+    fbb_.AddOffset(MiniBenchmarkEvent::VT_BENCHMARK_EVENT, benchmark_event);
+  }
   explicit MiniBenchmarkEventBuilder(flatbuffers::FlatBufferBuilder &_fbb)
         : fbb_(_fbb) {
     start_ = fbb_.StartTable();
   }
-  MiniBenchmarkEventBuilder &operator=(const MiniBenchmarkEventBuilder &);
   flatbuffers::Offset<MiniBenchmarkEvent> Finish() {
     const auto end = fbb_.EndTable(start_);
     auto o = flatbuffers::Offset<MiniBenchmarkEvent>(end);
@@ -2563,8 +2945,10 @@ inline flatbuffers::Offset<MiniBenchmarkEvent> CreateMiniBenchmarkEvent(
     flatbuffers::FlatBufferBuilder &_fbb,
     bool is_log_flushing_event = false,
     flatbuffers::Offset<tflite::BestAccelerationDecision> best_acceleration_decision = 0,
-    flatbuffers::Offset<tflite::BenchmarkInitializationFailure> initialization_failure = 0) {
+    flatbuffers::Offset<tflite::BenchmarkInitializationFailure> initialization_failure = 0,
+    flatbuffers::Offset<tflite::BenchmarkEvent> benchmark_event = 0) {
   MiniBenchmarkEventBuilder builder_(_fbb);
+  builder_.add_benchmark_event(benchmark_event);
   builder_.add_initialization_failure(initialization_failure);
   builder_.add_best_acceleration_decision(best_acceleration_decision);
   builder_.add_is_log_flushing_event(is_log_flushing_event);
@@ -2573,13 +2957,287 @@ inline flatbuffers::Offset<MiniBenchmarkEvent> CreateMiniBenchmarkEvent(
 
 flatbuffers::Offset<MiniBenchmarkEvent> CreateMiniBenchmarkEvent(flatbuffers::FlatBufferBuilder &_fbb, const MiniBenchmarkEventT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
 
+struct ModelFileT : public flatbuffers::NativeTable {
+  typedef ModelFile TableType;
+  std::string filename{};
+  int64_t fd = 0;
+  int64_t offset = 0;
+  int64_t length = 0;
+};
+
+struct ModelFile FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
+  typedef ModelFileT NativeTableType;
+  typedef ModelFileBuilder Builder;
+  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
+    VT_FILENAME = 4,
+    VT_FD = 6,
+    VT_OFFSET = 8,
+    VT_LENGTH = 10
+  };
+  const flatbuffers::String *filename() const {
+    return GetPointer<const flatbuffers::String *>(VT_FILENAME);
+  }
+  int64_t fd() const {
+    return GetField<int64_t>(VT_FD, 0);
+  }
+  int64_t offset() const {
+    return GetField<int64_t>(VT_OFFSET, 0);
+  }
+  int64_t length() const {
+    return GetField<int64_t>(VT_LENGTH, 0);
+  }
+  bool Verify(flatbuffers::Verifier &verifier) const {
+    return VerifyTableStart(verifier) &&
+           VerifyOffset(verifier, VT_FILENAME) &&
+           verifier.VerifyString(filename()) &&
+           VerifyField<int64_t>(verifier, VT_FD, 8) &&
+           VerifyField<int64_t>(verifier, VT_OFFSET, 8) &&
+           VerifyField<int64_t>(verifier, VT_LENGTH, 8) &&
+           verifier.EndTable();
+  }
+  ModelFileT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
+  void UnPackTo(ModelFileT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
+  static flatbuffers::Offset<ModelFile> Pack(flatbuffers::FlatBufferBuilder &_fbb, const ModelFileT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
+};
+
+struct ModelFileBuilder {
+  typedef ModelFile Table;
+  flatbuffers::FlatBufferBuilder &fbb_;
+  flatbuffers::uoffset_t start_;
+  void add_filename(flatbuffers::Offset<flatbuffers::String> filename) {
+    fbb_.AddOffset(ModelFile::VT_FILENAME, filename);
+  }
+  void add_fd(int64_t fd) {
+    fbb_.AddElement<int64_t>(ModelFile::VT_FD, fd, 0);
+  }
+  void add_offset(int64_t offset) {
+    fbb_.AddElement<int64_t>(ModelFile::VT_OFFSET, offset, 0);
+  }
+  void add_length(int64_t length) {
+    fbb_.AddElement<int64_t>(ModelFile::VT_LENGTH, length, 0);
+  }
+  explicit ModelFileBuilder(flatbuffers::FlatBufferBuilder &_fbb)
+        : fbb_(_fbb) {
+    start_ = fbb_.StartTable();
+  }
+  flatbuffers::Offset<ModelFile> Finish() {
+    const auto end = fbb_.EndTable(start_);
+    auto o = flatbuffers::Offset<ModelFile>(end);
+    return o;
+  }
+};
+
+inline flatbuffers::Offset<ModelFile> CreateModelFile(
+    flatbuffers::FlatBufferBuilder &_fbb,
+    flatbuffers::Offset<flatbuffers::String> filename = 0,
+    int64_t fd = 0,
+    int64_t offset = 0,
+    int64_t length = 0) {
+  ModelFileBuilder builder_(_fbb);
+  builder_.add_length(length);
+  builder_.add_offset(offset);
+  builder_.add_fd(fd);
+  builder_.add_filename(filename);
+  return builder_.Finish();
+}
+
+inline flatbuffers::Offset<ModelFile> CreateModelFileDirect(
+    flatbuffers::FlatBufferBuilder &_fbb,
+    const char *filename = nullptr,
+    int64_t fd = 0,
+    int64_t offset = 0,
+    int64_t length = 0) {
+  auto filename__ = filename ? _fbb.CreateString(filename) : 0;
+  return tflite::CreateModelFile(
+      _fbb,
+      filename__,
+      fd,
+      offset,
+      length);
+}
+
+flatbuffers::Offset<ModelFile> CreateModelFile(flatbuffers::FlatBufferBuilder &_fbb, const ModelFileT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
+
+struct BenchmarkStoragePathsT : public flatbuffers::NativeTable {
+  typedef BenchmarkStoragePaths TableType;
+  std::string storage_file_path{};
+  std::string data_directory_path{};
+};
+
+struct BenchmarkStoragePaths FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
+  typedef BenchmarkStoragePathsT NativeTableType;
+  typedef BenchmarkStoragePathsBuilder Builder;
+  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
+    VT_STORAGE_FILE_PATH = 4,
+    VT_DATA_DIRECTORY_PATH = 6
+  };
+  const flatbuffers::String *storage_file_path() const {
+    return GetPointer<const flatbuffers::String *>(VT_STORAGE_FILE_PATH);
+  }
+  const flatbuffers::String *data_directory_path() const {
+    return GetPointer<const flatbuffers::String *>(VT_DATA_DIRECTORY_PATH);
+  }
+  bool Verify(flatbuffers::Verifier &verifier) const {
+    return VerifyTableStart(verifier) &&
+           VerifyOffset(verifier, VT_STORAGE_FILE_PATH) &&
+           verifier.VerifyString(storage_file_path()) &&
+           VerifyOffset(verifier, VT_DATA_DIRECTORY_PATH) &&
+           verifier.VerifyString(data_directory_path()) &&
+           verifier.EndTable();
+  }
+  BenchmarkStoragePathsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
+  void UnPackTo(BenchmarkStoragePathsT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
+  static flatbuffers::Offset<BenchmarkStoragePaths> Pack(flatbuffers::FlatBufferBuilder &_fbb, const BenchmarkStoragePathsT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
+};
+
+struct BenchmarkStoragePathsBuilder {
+  typedef BenchmarkStoragePaths Table;
+  flatbuffers::FlatBufferBuilder &fbb_;
+  flatbuffers::uoffset_t start_;
+  void add_storage_file_path(flatbuffers::Offset<flatbuffers::String> storage_file_path) {
+    fbb_.AddOffset(BenchmarkStoragePaths::VT_STORAGE_FILE_PATH, storage_file_path);
+  }
+  void add_data_directory_path(flatbuffers::Offset<flatbuffers::String> data_directory_path) {
+    fbb_.AddOffset(BenchmarkStoragePaths::VT_DATA_DIRECTORY_PATH, data_directory_path);
+  }
+  explicit BenchmarkStoragePathsBuilder(flatbuffers::FlatBufferBuilder &_fbb)
+        : fbb_(_fbb) {
+    start_ = fbb_.StartTable();
+  }
+  flatbuffers::Offset<BenchmarkStoragePaths> Finish() {
+    const auto end = fbb_.EndTable(start_);
+    auto o = flatbuffers::Offset<BenchmarkStoragePaths>(end);
+    return o;
+  }
+};
+
+inline flatbuffers::Offset<BenchmarkStoragePaths> CreateBenchmarkStoragePaths(
+    flatbuffers::FlatBufferBuilder &_fbb,
+    flatbuffers::Offset<flatbuffers::String> storage_file_path = 0,
+    flatbuffers::Offset<flatbuffers::String> data_directory_path = 0) {
+  BenchmarkStoragePathsBuilder builder_(_fbb);
+  builder_.add_data_directory_path(data_directory_path);
+  builder_.add_storage_file_path(storage_file_path);
+  return builder_.Finish();
+}
+
+inline flatbuffers::Offset<BenchmarkStoragePaths> CreateBenchmarkStoragePathsDirect(
+    flatbuffers::FlatBufferBuilder &_fbb,
+    const char *storage_file_path = nullptr,
+    const char *data_directory_path = nullptr) {
+  auto storage_file_path__ = storage_file_path ? _fbb.CreateString(storage_file_path) : 0;
+  auto data_directory_path__ = data_directory_path ? _fbb.CreateString(data_directory_path) : 0;
+  return tflite::CreateBenchmarkStoragePaths(
+      _fbb,
+      storage_file_path__,
+      data_directory_path__);
+}
+
+flatbuffers::Offset<BenchmarkStoragePaths> CreateBenchmarkStoragePaths(flatbuffers::FlatBufferBuilder &_fbb, const BenchmarkStoragePathsT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
+
+struct MinibenchmarkSettingsT : public flatbuffers::NativeTable {
+  typedef MinibenchmarkSettings TableType;
+  std::vector<std::unique_ptr<tflite::TFLiteSettingsT>> settings_to_test{};
+  std::unique_ptr<tflite::ModelFileT> model_file{};
+  std::unique_ptr<tflite::BenchmarkStoragePathsT> storage_paths{};
+  MinibenchmarkSettingsT() = default;
+  MinibenchmarkSettingsT(const MinibenchmarkSettingsT &o);
+  MinibenchmarkSettingsT(MinibenchmarkSettingsT&&) FLATBUFFERS_NOEXCEPT = default;
+  MinibenchmarkSettingsT &operator=(MinibenchmarkSettingsT o) FLATBUFFERS_NOEXCEPT;
+};
+
+struct MinibenchmarkSettings FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
+  typedef MinibenchmarkSettingsT NativeTableType;
+  typedef MinibenchmarkSettingsBuilder Builder;
+  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
+    VT_SETTINGS_TO_TEST = 4,
+    VT_MODEL_FILE = 6,
+    VT_STORAGE_PATHS = 8
+  };
+  const flatbuffers::Vector<flatbuffers::Offset<tflite::TFLiteSettings>> *settings_to_test() const {
+    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<tflite::TFLiteSettings>> *>(VT_SETTINGS_TO_TEST);
+  }
+  const tflite::ModelFile *model_file() const {
+    return GetPointer<const tflite::ModelFile *>(VT_MODEL_FILE);
+  }
+  const tflite::BenchmarkStoragePaths *storage_paths() const {
+    return GetPointer<const tflite::BenchmarkStoragePaths *>(VT_STORAGE_PATHS);
+  }
+  bool Verify(flatbuffers::Verifier &verifier) const {
+    return VerifyTableStart(verifier) &&
+           VerifyOffset(verifier, VT_SETTINGS_TO_TEST) &&
+           verifier.VerifyVector(settings_to_test()) &&
+           verifier.VerifyVectorOfTables(settings_to_test()) &&
+           VerifyOffset(verifier, VT_MODEL_FILE) &&
+           verifier.VerifyTable(model_file()) &&
+           VerifyOffset(verifier, VT_STORAGE_PATHS) &&
+           verifier.VerifyTable(storage_paths()) &&
+           verifier.EndTable();
+  }
+  MinibenchmarkSettingsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
+  void UnPackTo(MinibenchmarkSettingsT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
+  static flatbuffers::Offset<MinibenchmarkSettings> Pack(flatbuffers::FlatBufferBuilder &_fbb, const MinibenchmarkSettingsT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
+};
+
+struct MinibenchmarkSettingsBuilder {
+  typedef MinibenchmarkSettings Table;
+  flatbuffers::FlatBufferBuilder &fbb_;
+  flatbuffers::uoffset_t start_;
+  void add_settings_to_test(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<tflite::TFLiteSettings>>> settings_to_test) {
+    fbb_.AddOffset(MinibenchmarkSettings::VT_SETTINGS_TO_TEST, settings_to_test);
+  }
+  void add_model_file(flatbuffers::Offset<tflite::ModelFile> model_file) {
+    fbb_.AddOffset(MinibenchmarkSettings::VT_MODEL_FILE, model_file);
+  }
+  void add_storage_paths(flatbuffers::Offset<tflite::BenchmarkStoragePaths> storage_paths) {
+    fbb_.AddOffset(MinibenchmarkSettings::VT_STORAGE_PATHS, storage_paths);
+  }
+  explicit MinibenchmarkSettingsBuilder(flatbuffers::FlatBufferBuilder &_fbb)
+        : fbb_(_fbb) {
+    start_ = fbb_.StartTable();
+  }
+  flatbuffers::Offset<MinibenchmarkSettings> Finish() {
+    const auto end = fbb_.EndTable(start_);
+    auto o = flatbuffers::Offset<MinibenchmarkSettings>(end);
+    return o;
+  }
+};
+
+inline flatbuffers::Offset<MinibenchmarkSettings> CreateMinibenchmarkSettings(
+    flatbuffers::FlatBufferBuilder &_fbb,
+    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<tflite::TFLiteSettings>>> settings_to_test = 0,
+    flatbuffers::Offset<tflite::ModelFile> model_file = 0,
+    flatbuffers::Offset<tflite::BenchmarkStoragePaths> storage_paths = 0) {
+  MinibenchmarkSettingsBuilder builder_(_fbb);
+  builder_.add_storage_paths(storage_paths);
+  builder_.add_model_file(model_file);
+  builder_.add_settings_to_test(settings_to_test);
+  return builder_.Finish();
+}
+
+inline flatbuffers::Offset<MinibenchmarkSettings> CreateMinibenchmarkSettingsDirect(
+    flatbuffers::FlatBufferBuilder &_fbb,
+    const std::vector<flatbuffers::Offset<tflite::TFLiteSettings>> *settings_to_test = nullptr,
+    flatbuffers::Offset<tflite::ModelFile> model_file = 0,
+    flatbuffers::Offset<tflite::BenchmarkStoragePaths> storage_paths = 0) {
+  auto settings_to_test__ = settings_to_test ? _fbb.CreateVector<flatbuffers::Offset<tflite::TFLiteSettings>>(*settings_to_test) : 0;
+  return tflite::CreateMinibenchmarkSettings(
+      _fbb,
+      settings_to_test__,
+      model_file,
+      storage_paths);
+}
+
+flatbuffers::Offset<MinibenchmarkSettings> CreateMinibenchmarkSettings(flatbuffers::FlatBufferBuilder &_fbb, const MinibenchmarkSettingsT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
+
 
 inline bool operator==(const ComputeSettingsT &lhs, const ComputeSettingsT &rhs) {
   return
       (lhs.preference == rhs.preference) &&
       ((lhs.tflite_settings == rhs.tflite_settings) || (lhs.tflite_settings && rhs.tflite_settings && *lhs.tflite_settings == *rhs.tflite_settings)) &&
       (lhs.model_namespace_for_statistics == rhs.model_namespace_for_statistics) &&
-      (lhs.model_identifier_for_statistics == rhs.model_identifier_for_statistics);
+      (lhs.model_identifier_for_statistics == rhs.model_identifier_for_statistics) &&
+      ((lhs.settings_to_test_locally == rhs.settings_to_test_locally) || (lhs.settings_to_test_locally && rhs.settings_to_test_locally && *lhs.settings_to_test_locally == *rhs.settings_to_test_locally));
 }
 
 inline bool operator!=(const ComputeSettingsT &lhs, const ComputeSettingsT &rhs) {
@@ -2587,19 +3245,37 @@ inline bool operator!=(const ComputeSettingsT &lhs, const ComputeSettingsT &rhs)
 }
 
 
+inline ComputeSettingsT::ComputeSettingsT(const ComputeSettingsT &o)
+      : preference(o.preference),
+        tflite_settings((o.tflite_settings) ? new tflite::TFLiteSettingsT(*o.tflite_settings) : nullptr),
+        model_namespace_for_statistics(o.model_namespace_for_statistics),
+        model_identifier_for_statistics(o.model_identifier_for_statistics),
+        settings_to_test_locally((o.settings_to_test_locally) ? new tflite::MinibenchmarkSettingsT(*o.settings_to_test_locally) : nullptr) {
+}
+
+inline ComputeSettingsT &ComputeSettingsT::operator=(ComputeSettingsT o) FLATBUFFERS_NOEXCEPT {
+  std::swap(preference, o.preference);
+  std::swap(tflite_settings, o.tflite_settings);
+  std::swap(model_namespace_for_statistics, o.model_namespace_for_statistics);
+  std::swap(model_identifier_for_statistics, o.model_identifier_for_statistics);
+  std::swap(settings_to_test_locally, o.settings_to_test_locally);
+  return *this;
+}
+
 inline ComputeSettingsT *ComputeSettings::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new ComputeSettingsT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<ComputeSettingsT>(new ComputeSettingsT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void ComputeSettings::UnPackTo(ComputeSettingsT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
   { auto _e = preference(); _o->preference = _e; }
-  { auto _e = tflite_settings(); if (_e) _o->tflite_settings = std::unique_ptr<tflite::TFLiteSettingsT>(_e->UnPack(_resolver)); }
+  { auto _e = tflite_settings(); if (_e) { if(_o->tflite_settings) { _e->UnPackTo(_o->tflite_settings.get(), _resolver); } else { _o->tflite_settings = std::unique_ptr<tflite::TFLiteSettingsT>(_e->UnPack(_resolver)); } } }
   { auto _e = model_namespace_for_statistics(); if (_e) _o->model_namespace_for_statistics = _e->str(); }
   { auto _e = model_identifier_for_statistics(); if (_e) _o->model_identifier_for_statistics = _e->str(); }
+  { auto _e = settings_to_test_locally(); if (_e) { if(_o->settings_to_test_locally) { _e->UnPackTo(_o->settings_to_test_locally.get(), _resolver); } else { _o->settings_to_test_locally = std::unique_ptr<tflite::MinibenchmarkSettingsT>(_e->UnPack(_resolver)); } } }
 }
 
 inline flatbuffers::Offset<ComputeSettings> ComputeSettings::Pack(flatbuffers::FlatBufferBuilder &_fbb, const ComputeSettingsT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -2614,12 +3290,14 @@ inline flatbuffers::Offset<ComputeSettings> CreateComputeSettings(flatbuffers::F
   auto _tflite_settings = _o->tflite_settings ? CreateTFLiteSettings(_fbb, _o->tflite_settings.get(), _rehasher) : 0;
   auto _model_namespace_for_statistics = _o->model_namespace_for_statistics.empty() ? 0 : _fbb.CreateString(_o->model_namespace_for_statistics);
   auto _model_identifier_for_statistics = _o->model_identifier_for_statistics.empty() ? 0 : _fbb.CreateString(_o->model_identifier_for_statistics);
+  auto _settings_to_test_locally = _o->settings_to_test_locally ? CreateMinibenchmarkSettings(_fbb, _o->settings_to_test_locally.get(), _rehasher) : 0;
   return tflite::CreateComputeSettings(
       _fbb,
       _preference,
       _tflite_settings,
       _model_namespace_for_statistics,
-      _model_identifier_for_statistics);
+      _model_identifier_for_statistics,
+      _settings_to_test_locally);
 }
 
 
@@ -2635,7 +3313,8 @@ inline bool operator==(const NNAPISettingsT &lhs, const NNAPISettingsT &rhs) {
       (lhs.execution_priority == rhs.execution_priority) &&
       (lhs.allow_dynamic_dimensions == rhs.allow_dynamic_dimensions) &&
       (lhs.allow_fp16_precision_for_fp32 == rhs.allow_fp16_precision_for_fp32) &&
-      (lhs.use_burst_computation == rhs.use_burst_computation);
+      (lhs.use_burst_computation == rhs.use_burst_computation) &&
+      (lhs.support_library_handle == rhs.support_library_handle);
 }
 
 inline bool operator!=(const NNAPISettingsT &lhs, const NNAPISettingsT &rhs) {
@@ -2643,10 +3322,41 @@ inline bool operator!=(const NNAPISettingsT &lhs, const NNAPISettingsT &rhs) {
 }
 
 
+inline NNAPISettingsT::NNAPISettingsT(const NNAPISettingsT &o)
+      : accelerator_name(o.accelerator_name),
+        cache_directory(o.cache_directory),
+        model_token(o.model_token),
+        execution_preference(o.execution_preference),
+        no_of_nnapi_instances_to_cache(o.no_of_nnapi_instances_to_cache),
+        fallback_settings((o.fallback_settings) ? new tflite::FallbackSettingsT(*o.fallback_settings) : nullptr),
+        allow_nnapi_cpu_on_android_10_plus(o.allow_nnapi_cpu_on_android_10_plus),
+        execution_priority(o.execution_priority),
+        allow_dynamic_dimensions(o.allow_dynamic_dimensions),
+        allow_fp16_precision_for_fp32(o.allow_fp16_precision_for_fp32),
+        use_burst_computation(o.use_burst_computation),
+        support_library_handle(o.support_library_handle) {
+}
+
+inline NNAPISettingsT &NNAPISettingsT::operator=(NNAPISettingsT o) FLATBUFFERS_NOEXCEPT {
+  std::swap(accelerator_name, o.accelerator_name);
+  std::swap(cache_directory, o.cache_directory);
+  std::swap(model_token, o.model_token);
+  std::swap(execution_preference, o.execution_preference);
+  std::swap(no_of_nnapi_instances_to_cache, o.no_of_nnapi_instances_to_cache);
+  std::swap(fallback_settings, o.fallback_settings);
+  std::swap(allow_nnapi_cpu_on_android_10_plus, o.allow_nnapi_cpu_on_android_10_plus);
+  std::swap(execution_priority, o.execution_priority);
+  std::swap(allow_dynamic_dimensions, o.allow_dynamic_dimensions);
+  std::swap(allow_fp16_precision_for_fp32, o.allow_fp16_precision_for_fp32);
+  std::swap(use_burst_computation, o.use_burst_computation);
+  std::swap(support_library_handle, o.support_library_handle);
+  return *this;
+}
+
 inline NNAPISettingsT *NNAPISettings::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new NNAPISettingsT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<NNAPISettingsT>(new NNAPISettingsT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void NNAPISettings::UnPackTo(NNAPISettingsT *_o, const flatbuffers::resolver_function_t *_resolver) const {
@@ -2657,12 +3367,13 @@ inline void NNAPISettings::UnPackTo(NNAPISettingsT *_o, const flatbuffers::resol
   { auto _e = model_token(); if (_e) _o->model_token = _e->str(); }
   { auto _e = execution_preference(); _o->execution_preference = _e; }
   { auto _e = no_of_nnapi_instances_to_cache(); _o->no_of_nnapi_instances_to_cache = _e; }
-  { auto _e = fallback_settings(); if (_e) _o->fallback_settings = std::unique_ptr<tflite::FallbackSettingsT>(_e->UnPack(_resolver)); }
+  { auto _e = fallback_settings(); if (_e) { if(_o->fallback_settings) { _e->UnPackTo(_o->fallback_settings.get(), _resolver); } else { _o->fallback_settings = std::unique_ptr<tflite::FallbackSettingsT>(_e->UnPack(_resolver)); } } }
   { auto _e = allow_nnapi_cpu_on_android_10_plus(); _o->allow_nnapi_cpu_on_android_10_plus = _e; }
   { auto _e = execution_priority(); _o->execution_priority = _e; }
   { auto _e = allow_dynamic_dimensions(); _o->allow_dynamic_dimensions = _e; }
   { auto _e = allow_fp16_precision_for_fp32(); _o->allow_fp16_precision_for_fp32 = _e; }
   { auto _e = use_burst_computation(); _o->use_burst_computation = _e; }
+  { auto _e = support_library_handle(); _o->support_library_handle = _e; }
 }
 
 inline flatbuffers::Offset<NNAPISettings> NNAPISettings::Pack(flatbuffers::FlatBufferBuilder &_fbb, const NNAPISettingsT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -2684,6 +3395,7 @@ inline flatbuffers::Offset<NNAPISettings> CreateNNAPISettings(flatbuffers::FlatB
   auto _allow_dynamic_dimensions = _o->allow_dynamic_dimensions;
   auto _allow_fp16_precision_for_fp32 = _o->allow_fp16_precision_for_fp32;
   auto _use_burst_computation = _o->use_burst_computation;
+  auto _support_library_handle = _o->support_library_handle;
   return tflite::CreateNNAPISettings(
       _fbb,
       _accelerator_name,
@@ -2696,7 +3408,8 @@ inline flatbuffers::Offset<NNAPISettings> CreateNNAPISettings(flatbuffers::FlatB
       _execution_priority,
       _allow_dynamic_dimensions,
       _allow_fp16_precision_for_fp32,
-      _use_burst_computation);
+      _use_burst_computation,
+      _support_library_handle);
 }
 
 
@@ -2707,7 +3420,10 @@ inline bool operator==(const GPUSettingsT &lhs, const GPUSettingsT &rhs) {
       (lhs.force_backend == rhs.force_backend) &&
       (lhs.inference_priority1 == rhs.inference_priority1) &&
       (lhs.inference_priority2 == rhs.inference_priority2) &&
-      (lhs.inference_priority3 == rhs.inference_priority3);
+      (lhs.inference_priority3 == rhs.inference_priority3) &&
+      (lhs.inference_preference == rhs.inference_preference) &&
+      (lhs.cache_directory == rhs.cache_directory) &&
+      (lhs.model_token == rhs.model_token);
 }
 
 inline bool operator!=(const GPUSettingsT &lhs, const GPUSettingsT &rhs) {
@@ -2716,9 +3432,9 @@ inline bool operator!=(const GPUSettingsT &lhs, const GPUSettingsT &rhs) {
 
 
 inline GPUSettingsT *GPUSettings::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new GPUSettingsT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<GPUSettingsT>(new GPUSettingsT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void GPUSettings::UnPackTo(GPUSettingsT *_o, const flatbuffers::resolver_function_t *_resolver) const {
@@ -2730,6 +3446,9 @@ inline void GPUSettings::UnPackTo(GPUSettingsT *_o, const flatbuffers::resolver_
   { auto _e = inference_priority1(); _o->inference_priority1 = _e; }
   { auto _e = inference_priority2(); _o->inference_priority2 = _e; }
   { auto _e = inference_priority3(); _o->inference_priority3 = _e; }
+  { auto _e = inference_preference(); _o->inference_preference = _e; }
+  { auto _e = cache_directory(); if (_e) _o->cache_directory = _e->str(); }
+  { auto _e = model_token(); if (_e) _o->model_token = _e->str(); }
 }
 
 inline flatbuffers::Offset<GPUSettings> GPUSettings::Pack(flatbuffers::FlatBufferBuilder &_fbb, const GPUSettingsT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -2746,6 +3465,9 @@ inline flatbuffers::Offset<GPUSettings> CreateGPUSettings(flatbuffers::FlatBuffe
   auto _inference_priority1 = _o->inference_priority1;
   auto _inference_priority2 = _o->inference_priority2;
   auto _inference_priority3 = _o->inference_priority3;
+  auto _inference_preference = _o->inference_preference;
+  auto _cache_directory = _o->cache_directory.empty() ? 0 : _fbb.CreateString(_o->cache_directory);
+  auto _model_token = _o->model_token.empty() ? 0 : _fbb.CreateString(_o->model_token);
   return tflite::CreateGPUSettings(
       _fbb,
       _is_precision_loss_allowed,
@@ -2753,7 +3475,10 @@ inline flatbuffers::Offset<GPUSettings> CreateGPUSettings(flatbuffers::FlatBuffe
       _force_backend,
       _inference_priority1,
       _inference_priority2,
-      _inference_priority3);
+      _inference_priority3,
+      _inference_preference,
+      _cache_directory,
+      _model_token);
 }
 
 
@@ -2771,9 +3496,9 @@ inline bool operator!=(const HexagonSettingsT &lhs, const HexagonSettingsT &rhs)
 
 
 inline HexagonSettingsT *HexagonSettings::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new HexagonSettingsT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<HexagonSettingsT>(new HexagonSettingsT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void HexagonSettings::UnPackTo(HexagonSettingsT *_o, const flatbuffers::resolver_function_t *_resolver) const {
@@ -2808,7 +3533,8 @@ inline flatbuffers::Offset<HexagonSettings> CreateHexagonSettings(flatbuffers::F
 
 inline bool operator==(const XNNPackSettingsT &lhs, const XNNPackSettingsT &rhs) {
   return
-      (lhs.num_threads == rhs.num_threads);
+      (lhs.num_threads == rhs.num_threads) &&
+      (lhs.flags == rhs.flags);
 }
 
 inline bool operator!=(const XNNPackSettingsT &lhs, const XNNPackSettingsT &rhs) {
@@ -2817,15 +3543,16 @@ inline bool operator!=(const XNNPackSettingsT &lhs, const XNNPackSettingsT &rhs)
 
 
 inline XNNPackSettingsT *XNNPackSettings::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new XNNPackSettingsT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<XNNPackSettingsT>(new XNNPackSettingsT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void XNNPackSettings::UnPackTo(XNNPackSettingsT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
   { auto _e = num_threads(); _o->num_threads = _e; }
+  { auto _e = flags(); _o->flags = _e; }
 }
 
 inline flatbuffers::Offset<XNNPackSettings> XNNPackSettings::Pack(flatbuffers::FlatBufferBuilder &_fbb, const XNNPackSettingsT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -2837,9 +3564,60 @@ inline flatbuffers::Offset<XNNPackSettings> CreateXNNPackSettings(flatbuffers::F
   (void)_o;
   struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const XNNPackSettingsT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
   auto _num_threads = _o->num_threads;
+  auto _flags = _o->flags;
   return tflite::CreateXNNPackSettings(
       _fbb,
-      _num_threads);
+      _num_threads,
+      _flags);
+}
+
+
+inline bool operator==(const CoreMLSettingsT &lhs, const CoreMLSettingsT &rhs) {
+  return
+      (lhs.enabled_devices == rhs.enabled_devices) &&
+      (lhs.coreml_version == rhs.coreml_version) &&
+      (lhs.max_delegated_partitions == rhs.max_delegated_partitions) &&
+      (lhs.min_nodes_per_partition == rhs.min_nodes_per_partition);
+}
+
+inline bool operator!=(const CoreMLSettingsT &lhs, const CoreMLSettingsT &rhs) {
+    return !(lhs == rhs);
+}
+
+
+inline CoreMLSettingsT *CoreMLSettings::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
+  auto _o = std::unique_ptr<CoreMLSettingsT>(new CoreMLSettingsT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
+}
+
+inline void CoreMLSettings::UnPackTo(CoreMLSettingsT *_o, const flatbuffers::resolver_function_t *_resolver) const {
+  (void)_o;
+  (void)_resolver;
+  { auto _e = enabled_devices(); _o->enabled_devices = _e; }
+  { auto _e = coreml_version(); _o->coreml_version = _e; }
+  { auto _e = max_delegated_partitions(); _o->max_delegated_partitions = _e; }
+  { auto _e = min_nodes_per_partition(); _o->min_nodes_per_partition = _e; }
+}
+
+inline flatbuffers::Offset<CoreMLSettings> CoreMLSettings::Pack(flatbuffers::FlatBufferBuilder &_fbb, const CoreMLSettingsT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
+  return CreateCoreMLSettings(_fbb, _o, _rehasher);
+}
+
+inline flatbuffers::Offset<CoreMLSettings> CreateCoreMLSettings(flatbuffers::FlatBufferBuilder &_fbb, const CoreMLSettingsT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
+  (void)_rehasher;
+  (void)_o;
+  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const CoreMLSettingsT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
+  auto _enabled_devices = _o->enabled_devices;
+  auto _coreml_version = _o->coreml_version;
+  auto _max_delegated_partitions = _o->max_delegated_partitions;
+  auto _min_nodes_per_partition = _o->min_nodes_per_partition;
+  return tflite::CreateCoreMLSettings(
+      _fbb,
+      _enabled_devices,
+      _coreml_version,
+      _max_delegated_partitions,
+      _min_nodes_per_partition);
 }
 
 
@@ -2857,9 +3635,9 @@ inline bool operator!=(const EdgeTpuDeviceSpecT &lhs, const EdgeTpuDeviceSpecT &
 
 
 inline EdgeTpuDeviceSpecT *EdgeTpuDeviceSpec::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new EdgeTpuDeviceSpecT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<EdgeTpuDeviceSpecT>(new EdgeTpuDeviceSpecT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void EdgeTpuDeviceSpec::UnPackTo(EdgeTpuDeviceSpecT *_o, const flatbuffers::resolver_function_t *_resolver) const {
@@ -2904,9 +3682,9 @@ inline bool operator!=(const EdgeTpuInactivePowerConfigT &lhs, const EdgeTpuInac
 
 
 inline EdgeTpuInactivePowerConfigT *EdgeTpuInactivePowerConfig::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new EdgeTpuInactivePowerConfigT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<EdgeTpuInactivePowerConfigT>(new EdgeTpuInactivePowerConfigT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void EdgeTpuInactivePowerConfig::UnPackTo(EdgeTpuInactivePowerConfigT *_o, const flatbuffers::resolver_function_t *_resolver) const {
@@ -2940,7 +3718,8 @@ inline bool operator==(const EdgeTpuSettingsT &lhs, const EdgeTpuSettingsT &rhs)
       (lhs.inference_priority == rhs.inference_priority) &&
       ((lhs.edgetpu_device_spec == rhs.edgetpu_device_spec) || (lhs.edgetpu_device_spec && rhs.edgetpu_device_spec && *lhs.edgetpu_device_spec == *rhs.edgetpu_device_spec)) &&
       (lhs.model_token == rhs.model_token) &&
-      (lhs.float_truncation_type == rhs.float_truncation_type);
+      (lhs.float_truncation_type == rhs.float_truncation_type) &&
+      (lhs.qos_class == rhs.qos_class);
 }
 
 inline bool operator!=(const EdgeTpuSettingsT &lhs, const EdgeTpuSettingsT &rhs) {
@@ -2948,21 +3727,44 @@ inline bool operator!=(const EdgeTpuSettingsT &lhs, const EdgeTpuSettingsT &rhs)
 }
 
 
+inline EdgeTpuSettingsT::EdgeTpuSettingsT(const EdgeTpuSettingsT &o)
+      : inference_power_state(o.inference_power_state),
+        inference_priority(o.inference_priority),
+        edgetpu_device_spec((o.edgetpu_device_spec) ? new tflite::EdgeTpuDeviceSpecT(*o.edgetpu_device_spec) : nullptr),
+        model_token(o.model_token),
+        float_truncation_type(o.float_truncation_type),
+        qos_class(o.qos_class) {
+  inactive_power_configs.reserve(o.inactive_power_configs.size());
+  for (const auto &v : o.inactive_power_configs) { inactive_power_configs.emplace_back((v) ? new tflite::EdgeTpuInactivePowerConfigT(*v) : nullptr); }
+}
+
+inline EdgeTpuSettingsT &EdgeTpuSettingsT::operator=(EdgeTpuSettingsT o) FLATBUFFERS_NOEXCEPT {
+  std::swap(inference_power_state, o.inference_power_state);
+  std::swap(inactive_power_configs, o.inactive_power_configs);
+  std::swap(inference_priority, o.inference_priority);
+  std::swap(edgetpu_device_spec, o.edgetpu_device_spec);
+  std::swap(model_token, o.model_token);
+  std::swap(float_truncation_type, o.float_truncation_type);
+  std::swap(qos_class, o.qos_class);
+  return *this;
+}
+
 inline EdgeTpuSettingsT *EdgeTpuSettings::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new EdgeTpuSettingsT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<EdgeTpuSettingsT>(new EdgeTpuSettingsT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void EdgeTpuSettings::UnPackTo(EdgeTpuSettingsT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
   { auto _e = inference_power_state(); _o->inference_power_state = _e; }
-  { auto _e = inactive_power_configs(); if (_e) { _o->inactive_power_configs.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->inactive_power_configs[_i] = std::unique_ptr<tflite::EdgeTpuInactivePowerConfigT>(_e->Get(_i)->UnPack(_resolver)); } } }
+  { auto _e = inactive_power_configs(); if (_e) { _o->inactive_power_configs.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { if(_o->inactive_power_configs[_i]) { _e->Get(_i)->UnPackTo(_o->inactive_power_configs[_i].get(), _resolver); } else { _o->inactive_power_configs[_i] = std::unique_ptr<tflite::EdgeTpuInactivePowerConfigT>(_e->Get(_i)->UnPack(_resolver)); }; } } }
   { auto _e = inference_priority(); _o->inference_priority = _e; }
-  { auto _e = edgetpu_device_spec(); if (_e) _o->edgetpu_device_spec = std::unique_ptr<tflite::EdgeTpuDeviceSpecT>(_e->UnPack(_resolver)); }
+  { auto _e = edgetpu_device_spec(); if (_e) { if(_o->edgetpu_device_spec) { _e->UnPackTo(_o->edgetpu_device_spec.get(), _resolver); } else { _o->edgetpu_device_spec = std::unique_ptr<tflite::EdgeTpuDeviceSpecT>(_e->UnPack(_resolver)); } } }
   { auto _e = model_token(); if (_e) _o->model_token = _e->str(); }
   { auto _e = float_truncation_type(); _o->float_truncation_type = _e; }
+  { auto _e = qos_class(); _o->qos_class = _e; }
 }
 
 inline flatbuffers::Offset<EdgeTpuSettings> EdgeTpuSettings::Pack(flatbuffers::FlatBufferBuilder &_fbb, const EdgeTpuSettingsT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -2979,6 +3781,7 @@ inline flatbuffers::Offset<EdgeTpuSettings> CreateEdgeTpuSettings(flatbuffers::F
   auto _edgetpu_device_spec = _o->edgetpu_device_spec ? CreateEdgeTpuDeviceSpec(_fbb, _o->edgetpu_device_spec.get(), _rehasher) : 0;
   auto _model_token = _o->model_token.empty() ? 0 : _fbb.CreateString(_o->model_token);
   auto _float_truncation_type = _o->float_truncation_type;
+  auto _qos_class = _o->qos_class;
   return tflite::CreateEdgeTpuSettings(
       _fbb,
       _inference_power_state,
@@ -2986,7 +3789,8 @@ inline flatbuffers::Offset<EdgeTpuSettings> CreateEdgeTpuSettings(flatbuffers::F
       _inference_priority,
       _edgetpu_device_spec,
       _model_token,
-      _float_truncation_type);
+      _float_truncation_type,
+      _qos_class);
 }
 
 
@@ -3004,9 +3808,9 @@ inline bool operator!=(const CoralSettingsT &lhs, const CoralSettingsT &rhs) {
 
 
 inline CoralSettingsT *CoralSettings::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new CoralSettingsT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<CoralSettingsT>(new CoralSettingsT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void CoralSettings::UnPackTo(CoralSettingsT *_o, const flatbuffers::resolver_function_t *_resolver) const {
@@ -3050,9 +3854,9 @@ inline bool operator!=(const CPUSettingsT &lhs, const CPUSettingsT &rhs) {
 
 
 inline CPUSettingsT *CPUSettings::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new CPUSettingsT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<CPUSettingsT>(new CPUSettingsT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void CPUSettings::UnPackTo(CPUSettingsT *_o, const flatbuffers::resolver_function_t *_resolver) const {
@@ -3083,11 +3887,13 @@ inline bool operator==(const TFLiteSettingsT &lhs, const TFLiteSettingsT &rhs) {
       ((lhs.gpu_settings == rhs.gpu_settings) || (lhs.gpu_settings && rhs.gpu_settings && *lhs.gpu_settings == *rhs.gpu_settings)) &&
       ((lhs.hexagon_settings == rhs.hexagon_settings) || (lhs.hexagon_settings && rhs.hexagon_settings && *lhs.hexagon_settings == *rhs.hexagon_settings)) &&
       ((lhs.xnnpack_settings == rhs.xnnpack_settings) || (lhs.xnnpack_settings && rhs.xnnpack_settings && *lhs.xnnpack_settings == *rhs.xnnpack_settings)) &&
+      ((lhs.coreml_settings == rhs.coreml_settings) || (lhs.coreml_settings && rhs.coreml_settings && *lhs.coreml_settings == *rhs.coreml_settings)) &&
       ((lhs.cpu_settings == rhs.cpu_settings) || (lhs.cpu_settings && rhs.cpu_settings && *lhs.cpu_settings == *rhs.cpu_settings)) &&
       (lhs.max_delegated_partitions == rhs.max_delegated_partitions) &&
       ((lhs.edgetpu_settings == rhs.edgetpu_settings) || (lhs.edgetpu_settings && rhs.edgetpu_settings && *lhs.edgetpu_settings == *rhs.edgetpu_settings)) &&
       ((lhs.coral_settings == rhs.coral_settings) || (lhs.coral_settings && rhs.coral_settings && *lhs.coral_settings == *rhs.coral_settings)) &&
-      ((lhs.fallback_settings == rhs.fallback_settings) || (lhs.fallback_settings && rhs.fallback_settings && *lhs.fallback_settings == *rhs.fallback_settings));
+      ((lhs.fallback_settings == rhs.fallback_settings) || (lhs.fallback_settings && rhs.fallback_settings && *lhs.fallback_settings == *rhs.fallback_settings)) &&
+      (lhs.disable_default_delegates == rhs.disable_default_delegates);
 }
 
 inline bool operator!=(const TFLiteSettingsT &lhs, const TFLiteSettingsT &rhs) {
@@ -3095,25 +3901,58 @@ inline bool operator!=(const TFLiteSettingsT &lhs, const TFLiteSettingsT &rhs) {
 }
 
 
+inline TFLiteSettingsT::TFLiteSettingsT(const TFLiteSettingsT &o)
+      : delegate(o.delegate),
+        nnapi_settings((o.nnapi_settings) ? new tflite::NNAPISettingsT(*o.nnapi_settings) : nullptr),
+        gpu_settings((o.gpu_settings) ? new tflite::GPUSettingsT(*o.gpu_settings) : nullptr),
+        hexagon_settings((o.hexagon_settings) ? new tflite::HexagonSettingsT(*o.hexagon_settings) : nullptr),
+        xnnpack_settings((o.xnnpack_settings) ? new tflite::XNNPackSettingsT(*o.xnnpack_settings) : nullptr),
+        coreml_settings((o.coreml_settings) ? new tflite::CoreMLSettingsT(*o.coreml_settings) : nullptr),
+        cpu_settings((o.cpu_settings) ? new tflite::CPUSettingsT(*o.cpu_settings) : nullptr),
+        max_delegated_partitions(o.max_delegated_partitions),
+        edgetpu_settings((o.edgetpu_settings) ? new tflite::EdgeTpuSettingsT(*o.edgetpu_settings) : nullptr),
+        coral_settings((o.coral_settings) ? new tflite::CoralSettingsT(*o.coral_settings) : nullptr),
+        fallback_settings((o.fallback_settings) ? new tflite::FallbackSettingsT(*o.fallback_settings) : nullptr),
+        disable_default_delegates(o.disable_default_delegates) {
+}
+
+inline TFLiteSettingsT &TFLiteSettingsT::operator=(TFLiteSettingsT o) FLATBUFFERS_NOEXCEPT {
+  std::swap(delegate, o.delegate);
+  std::swap(nnapi_settings, o.nnapi_settings);
+  std::swap(gpu_settings, o.gpu_settings);
+  std::swap(hexagon_settings, o.hexagon_settings);
+  std::swap(xnnpack_settings, o.xnnpack_settings);
+  std::swap(coreml_settings, o.coreml_settings);
+  std::swap(cpu_settings, o.cpu_settings);
+  std::swap(max_delegated_partitions, o.max_delegated_partitions);
+  std::swap(edgetpu_settings, o.edgetpu_settings);
+  std::swap(coral_settings, o.coral_settings);
+  std::swap(fallback_settings, o.fallback_settings);
+  std::swap(disable_default_delegates, o.disable_default_delegates);
+  return *this;
+}
+
 inline TFLiteSettingsT *TFLiteSettings::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new TFLiteSettingsT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<TFLiteSettingsT>(new TFLiteSettingsT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void TFLiteSettings::UnPackTo(TFLiteSettingsT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
   { auto _e = delegate(); _o->delegate = _e; }
-  { auto _e = nnapi_settings(); if (_e) _o->nnapi_settings = std::unique_ptr<tflite::NNAPISettingsT>(_e->UnPack(_resolver)); }
-  { auto _e = gpu_settings(); if (_e) _o->gpu_settings = std::unique_ptr<tflite::GPUSettingsT>(_e->UnPack(_resolver)); }
-  { auto _e = hexagon_settings(); if (_e) _o->hexagon_settings = std::unique_ptr<tflite::HexagonSettingsT>(_e->UnPack(_resolver)); }
-  { auto _e = xnnpack_settings(); if (_e) _o->xnnpack_settings = std::unique_ptr<tflite::XNNPackSettingsT>(_e->UnPack(_resolver)); }
-  { auto _e = cpu_settings(); if (_e) _o->cpu_settings = std::unique_ptr<tflite::CPUSettingsT>(_e->UnPack(_resolver)); }
+  { auto _e = nnapi_settings(); if (_e) { if(_o->nnapi_settings) { _e->UnPackTo(_o->nnapi_settings.get(), _resolver); } else { _o->nnapi_settings = std::unique_ptr<tflite::NNAPISettingsT>(_e->UnPack(_resolver)); } } }
+  { auto _e = gpu_settings(); if (_e) { if(_o->gpu_settings) { _e->UnPackTo(_o->gpu_settings.get(), _resolver); } else { _o->gpu_settings = std::unique_ptr<tflite::GPUSettingsT>(_e->UnPack(_resolver)); } } }
+  { auto _e = hexagon_settings(); if (_e) { if(_o->hexagon_settings) { _e->UnPackTo(_o->hexagon_settings.get(), _resolver); } else { _o->hexagon_settings = std::unique_ptr<tflite::HexagonSettingsT>(_e->UnPack(_resolver)); } } }
+  { auto _e = xnnpack_settings(); if (_e) { if(_o->xnnpack_settings) { _e->UnPackTo(_o->xnnpack_settings.get(), _resolver); } else { _o->xnnpack_settings = std::unique_ptr<tflite::XNNPackSettingsT>(_e->UnPack(_resolver)); } } }
+  { auto _e = coreml_settings(); if (_e) { if(_o->coreml_settings) { _e->UnPackTo(_o->coreml_settings.get(), _resolver); } else { _o->coreml_settings = std::unique_ptr<tflite::CoreMLSettingsT>(_e->UnPack(_resolver)); } } }
+  { auto _e = cpu_settings(); if (_e) { if(_o->cpu_settings) { _e->UnPackTo(_o->cpu_settings.get(), _resolver); } else { _o->cpu_settings = std::unique_ptr<tflite::CPUSettingsT>(_e->UnPack(_resolver)); } } }
   { auto _e = max_delegated_partitions(); _o->max_delegated_partitions = _e; }
-  { auto _e = edgetpu_settings(); if (_e) _o->edgetpu_settings = std::unique_ptr<tflite::EdgeTpuSettingsT>(_e->UnPack(_resolver)); }
-  { auto _e = coral_settings(); if (_e) _o->coral_settings = std::unique_ptr<tflite::CoralSettingsT>(_e->UnPack(_resolver)); }
-  { auto _e = fallback_settings(); if (_e) _o->fallback_settings = std::unique_ptr<tflite::FallbackSettingsT>(_e->UnPack(_resolver)); }
+  { auto _e = edgetpu_settings(); if (_e) { if(_o->edgetpu_settings) { _e->UnPackTo(_o->edgetpu_settings.get(), _resolver); } else { _o->edgetpu_settings = std::unique_ptr<tflite::EdgeTpuSettingsT>(_e->UnPack(_resolver)); } } }
+  { auto _e = coral_settings(); if (_e) { if(_o->coral_settings) { _e->UnPackTo(_o->coral_settings.get(), _resolver); } else { _o->coral_settings = std::unique_ptr<tflite::CoralSettingsT>(_e->UnPack(_resolver)); } } }
+  { auto _e = fallback_settings(); if (_e) { if(_o->fallback_settings) { _e->UnPackTo(_o->fallback_settings.get(), _resolver); } else { _o->fallback_settings = std::unique_ptr<tflite::FallbackSettingsT>(_e->UnPack(_resolver)); } } }
+  { auto _e = disable_default_delegates(); _o->disable_default_delegates = _e; }
 }
 
 inline flatbuffers::Offset<TFLiteSettings> TFLiteSettings::Pack(flatbuffers::FlatBufferBuilder &_fbb, const TFLiteSettingsT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -3129,11 +3968,13 @@ inline flatbuffers::Offset<TFLiteSettings> CreateTFLiteSettings(flatbuffers::Fla
   auto _gpu_settings = _o->gpu_settings ? CreateGPUSettings(_fbb, _o->gpu_settings.get(), _rehasher) : 0;
   auto _hexagon_settings = _o->hexagon_settings ? CreateHexagonSettings(_fbb, _o->hexagon_settings.get(), _rehasher) : 0;
   auto _xnnpack_settings = _o->xnnpack_settings ? CreateXNNPackSettings(_fbb, _o->xnnpack_settings.get(), _rehasher) : 0;
+  auto _coreml_settings = _o->coreml_settings ? CreateCoreMLSettings(_fbb, _o->coreml_settings.get(), _rehasher) : 0;
   auto _cpu_settings = _o->cpu_settings ? CreateCPUSettings(_fbb, _o->cpu_settings.get(), _rehasher) : 0;
   auto _max_delegated_partitions = _o->max_delegated_partitions;
   auto _edgetpu_settings = _o->edgetpu_settings ? CreateEdgeTpuSettings(_fbb, _o->edgetpu_settings.get(), _rehasher) : 0;
   auto _coral_settings = _o->coral_settings ? CreateCoralSettings(_fbb, _o->coral_settings.get(), _rehasher) : 0;
   auto _fallback_settings = _o->fallback_settings ? CreateFallbackSettings(_fbb, _o->fallback_settings.get(), _rehasher) : 0;
+  auto _disable_default_delegates = _o->disable_default_delegates;
   return tflite::CreateTFLiteSettings(
       _fbb,
       _delegate,
@@ -3141,11 +3982,13 @@ inline flatbuffers::Offset<TFLiteSettings> CreateTFLiteSettings(flatbuffers::Fla
       _gpu_settings,
       _hexagon_settings,
       _xnnpack_settings,
+      _coreml_settings,
       _cpu_settings,
       _max_delegated_partitions,
       _edgetpu_settings,
       _coral_settings,
-      _fallback_settings);
+      _fallback_settings,
+      _disable_default_delegates);
 }
 
 
@@ -3161,9 +4004,9 @@ inline bool operator!=(const FallbackSettingsT &lhs, const FallbackSettingsT &rh
 
 
 inline FallbackSettingsT *FallbackSettings::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new FallbackSettingsT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<FallbackSettingsT>(new FallbackSettingsT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void FallbackSettings::UnPackTo(FallbackSettingsT *_o, const flatbuffers::resolver_function_t *_resolver) const {
@@ -3202,9 +4045,9 @@ inline bool operator!=(const BenchmarkMetricT &lhs, const BenchmarkMetricT &rhs)
 
 
 inline BenchmarkMetricT *BenchmarkMetric::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new BenchmarkMetricT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<BenchmarkMetricT>(new BenchmarkMetricT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void BenchmarkMetric::UnPackTo(BenchmarkMetricT *_o, const flatbuffers::resolver_function_t *_resolver) const {
@@ -3245,10 +4088,28 @@ inline bool operator!=(const BenchmarkResultT &lhs, const BenchmarkResultT &rhs)
 }
 
 
+inline BenchmarkResultT::BenchmarkResultT(const BenchmarkResultT &o)
+      : initialization_time_us(o.initialization_time_us),
+        inference_time_us(o.inference_time_us),
+        max_memory_kb(o.max_memory_kb),
+        ok(o.ok) {
+  metrics.reserve(o.metrics.size());
+  for (const auto &v : o.metrics) { metrics.emplace_back((v) ? new tflite::BenchmarkMetricT(*v) : nullptr); }
+}
+
+inline BenchmarkResultT &BenchmarkResultT::operator=(BenchmarkResultT o) FLATBUFFERS_NOEXCEPT {
+  std::swap(initialization_time_us, o.initialization_time_us);
+  std::swap(inference_time_us, o.inference_time_us);
+  std::swap(max_memory_kb, o.max_memory_kb);
+  std::swap(ok, o.ok);
+  std::swap(metrics, o.metrics);
+  return *this;
+}
+
 inline BenchmarkResultT *BenchmarkResult::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new BenchmarkResultT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<BenchmarkResultT>(new BenchmarkResultT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void BenchmarkResult::UnPackTo(BenchmarkResultT *_o, const flatbuffers::resolver_function_t *_resolver) const {
@@ -3258,7 +4119,7 @@ inline void BenchmarkResult::UnPackTo(BenchmarkResultT *_o, const flatbuffers::r
   { auto _e = inference_time_us(); if (_e) { _o->inference_time_us.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->inference_time_us[_i] = _e->Get(_i); } } }
   { auto _e = max_memory_kb(); _o->max_memory_kb = _e; }
   { auto _e = ok(); _o->ok = _e; }
-  { auto _e = metrics(); if (_e) { _o->metrics.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->metrics[_i] = std::unique_ptr<tflite::BenchmarkMetricT>(_e->Get(_i)->UnPack(_resolver)); } } }
+  { auto _e = metrics(); if (_e) { _o->metrics.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { if(_o->metrics[_i]) { _e->Get(_i)->UnPackTo(_o->metrics[_i].get(), _resolver); } else { _o->metrics[_i] = std::unique_ptr<tflite::BenchmarkMetricT>(_e->Get(_i)->UnPack(_resolver)); }; } } }
 }
 
 inline flatbuffers::Offset<BenchmarkResult> BenchmarkResult::Pack(flatbuffers::FlatBufferBuilder &_fbb, const BenchmarkResultT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -3297,9 +4158,9 @@ inline bool operator!=(const ErrorCodeT &lhs, const ErrorCodeT &rhs) {
 
 
 inline ErrorCodeT *ErrorCode::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new ErrorCodeT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<ErrorCodeT>(new ErrorCodeT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void ErrorCode::UnPackTo(ErrorCodeT *_o, const flatbuffers::resolver_function_t *_resolver) const {
@@ -3343,10 +4204,28 @@ inline bool operator!=(const BenchmarkErrorT &lhs, const BenchmarkErrorT &rhs) {
 }
 
 
+inline BenchmarkErrorT::BenchmarkErrorT(const BenchmarkErrorT &o)
+      : stage(o.stage),
+        exit_code(o.exit_code),
+        signal(o.signal),
+        mini_benchmark_error_code(o.mini_benchmark_error_code) {
+  error_code.reserve(o.error_code.size());
+  for (const auto &v : o.error_code) { error_code.emplace_back((v) ? new tflite::ErrorCodeT(*v) : nullptr); }
+}
+
+inline BenchmarkErrorT &BenchmarkErrorT::operator=(BenchmarkErrorT o) FLATBUFFERS_NOEXCEPT {
+  std::swap(stage, o.stage);
+  std::swap(exit_code, o.exit_code);
+  std::swap(signal, o.signal);
+  std::swap(error_code, o.error_code);
+  std::swap(mini_benchmark_error_code, o.mini_benchmark_error_code);
+  return *this;
+}
+
 inline BenchmarkErrorT *BenchmarkError::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new BenchmarkErrorT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<BenchmarkErrorT>(new BenchmarkErrorT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void BenchmarkError::UnPackTo(BenchmarkErrorT *_o, const flatbuffers::resolver_function_t *_resolver) const {
@@ -3355,7 +4234,7 @@ inline void BenchmarkError::UnPackTo(BenchmarkErrorT *_o, const flatbuffers::res
   { auto _e = stage(); _o->stage = _e; }
   { auto _e = exit_code(); _o->exit_code = _e; }
   { auto _e = signal(); _o->signal = _e; }
-  { auto _e = error_code(); if (_e) { _o->error_code.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->error_code[_i] = std::unique_ptr<tflite::ErrorCodeT>(_e->Get(_i)->UnPack(_resolver)); } } }
+  { auto _e = error_code(); if (_e) { _o->error_code.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { if(_o->error_code[_i]) { _e->Get(_i)->UnPackTo(_o->error_code[_i].get(), _resolver); } else { _o->error_code[_i] = std::unique_ptr<tflite::ErrorCodeT>(_e->Get(_i)->UnPack(_resolver)); }; } } }
   { auto _e = mini_benchmark_error_code(); _o->mini_benchmark_error_code = _e; }
 }
 
@@ -3397,19 +4276,38 @@ inline bool operator!=(const BenchmarkEventT &lhs, const BenchmarkEventT &rhs) {
 }
 
 
+inline BenchmarkEventT::BenchmarkEventT(const BenchmarkEventT &o)
+      : tflite_settings((o.tflite_settings) ? new tflite::TFLiteSettingsT(*o.tflite_settings) : nullptr),
+        event_type(o.event_type),
+        result((o.result) ? new tflite::BenchmarkResultT(*o.result) : nullptr),
+        error((o.error) ? new tflite::BenchmarkErrorT(*o.error) : nullptr),
+        boottime_us(o.boottime_us),
+        wallclock_us(o.wallclock_us) {
+}
+
+inline BenchmarkEventT &BenchmarkEventT::operator=(BenchmarkEventT o) FLATBUFFERS_NOEXCEPT {
+  std::swap(tflite_settings, o.tflite_settings);
+  std::swap(event_type, o.event_type);
+  std::swap(result, o.result);
+  std::swap(error, o.error);
+  std::swap(boottime_us, o.boottime_us);
+  std::swap(wallclock_us, o.wallclock_us);
+  return *this;
+}
+
 inline BenchmarkEventT *BenchmarkEvent::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new BenchmarkEventT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<BenchmarkEventT>(new BenchmarkEventT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void BenchmarkEvent::UnPackTo(BenchmarkEventT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
-  { auto _e = tflite_settings(); if (_e) _o->tflite_settings = std::unique_ptr<tflite::TFLiteSettingsT>(_e->UnPack(_resolver)); }
+  { auto _e = tflite_settings(); if (_e) { if(_o->tflite_settings) { _e->UnPackTo(_o->tflite_settings.get(), _resolver); } else { _o->tflite_settings = std::unique_ptr<tflite::TFLiteSettingsT>(_e->UnPack(_resolver)); } } }
   { auto _e = event_type(); _o->event_type = _e; }
-  { auto _e = result(); if (_e) _o->result = std::unique_ptr<tflite::BenchmarkResultT>(_e->UnPack(_resolver)); }
-  { auto _e = error(); if (_e) _o->error = std::unique_ptr<tflite::BenchmarkErrorT>(_e->UnPack(_resolver)); }
+  { auto _e = result(); if (_e) { if(_o->result) { _e->UnPackTo(_o->result.get(), _resolver); } else { _o->result = std::unique_ptr<tflite::BenchmarkResultT>(_e->UnPack(_resolver)); } } }
+  { auto _e = error(); if (_e) { if(_o->error) { _e->UnPackTo(_o->error.get(), _resolver); } else { _o->error = std::unique_ptr<tflite::BenchmarkErrorT>(_e->UnPack(_resolver)); } } }
   { auto _e = boottime_us(); _o->boottime_us = _e; }
   { auto _e = wallclock_us(); _o->wallclock_us = _e; }
 }
@@ -3451,17 +4349,30 @@ inline bool operator!=(const BestAccelerationDecisionT &lhs, const BestAccelerat
 }
 
 
+inline BestAccelerationDecisionT::BestAccelerationDecisionT(const BestAccelerationDecisionT &o)
+      : number_of_source_events(o.number_of_source_events),
+        min_latency_event((o.min_latency_event) ? new tflite::BenchmarkEventT(*o.min_latency_event) : nullptr),
+        min_inference_time_us(o.min_inference_time_us) {
+}
+
+inline BestAccelerationDecisionT &BestAccelerationDecisionT::operator=(BestAccelerationDecisionT o) FLATBUFFERS_NOEXCEPT {
+  std::swap(number_of_source_events, o.number_of_source_events);
+  std::swap(min_latency_event, o.min_latency_event);
+  std::swap(min_inference_time_us, o.min_inference_time_us);
+  return *this;
+}
+
 inline BestAccelerationDecisionT *BestAccelerationDecision::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new BestAccelerationDecisionT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<BestAccelerationDecisionT>(new BestAccelerationDecisionT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void BestAccelerationDecision::UnPackTo(BestAccelerationDecisionT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
   { auto _e = number_of_source_events(); _o->number_of_source_events = _e; }
-  { auto _e = min_latency_event(); if (_e) _o->min_latency_event = std::unique_ptr<tflite::BenchmarkEventT>(_e->UnPack(_resolver)); }
+  { auto _e = min_latency_event(); if (_e) { if(_o->min_latency_event) { _e->UnPackTo(_o->min_latency_event.get(), _resolver); } else { _o->min_latency_event = std::unique_ptr<tflite::BenchmarkEventT>(_e->UnPack(_resolver)); } } }
   { auto _e = min_inference_time_us(); _o->min_inference_time_us = _e; }
 }
 
@@ -3495,9 +4406,9 @@ inline bool operator!=(const BenchmarkInitializationFailureT &lhs, const Benchma
 
 
 inline BenchmarkInitializationFailureT *BenchmarkInitializationFailure::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new BenchmarkInitializationFailureT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<BenchmarkInitializationFailureT>(new BenchmarkInitializationFailureT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void BenchmarkInitializationFailure::UnPackTo(BenchmarkInitializationFailureT *_o, const flatbuffers::resolver_function_t *_resolver) const {
@@ -3525,7 +4436,8 @@ inline bool operator==(const MiniBenchmarkEventT &lhs, const MiniBenchmarkEventT
   return
       (lhs.is_log_flushing_event == rhs.is_log_flushing_event) &&
       ((lhs.best_acceleration_decision == rhs.best_acceleration_decision) || (lhs.best_acceleration_decision && rhs.best_acceleration_decision && *lhs.best_acceleration_decision == *rhs.best_acceleration_decision)) &&
-      ((lhs.initialization_failure == rhs.initialization_failure) || (lhs.initialization_failure && rhs.initialization_failure && *lhs.initialization_failure == *rhs.initialization_failure));
+      ((lhs.initialization_failure == rhs.initialization_failure) || (lhs.initialization_failure && rhs.initialization_failure && *lhs.initialization_failure == *rhs.initialization_failure)) &&
+      ((lhs.benchmark_event == rhs.benchmark_event) || (lhs.benchmark_event && rhs.benchmark_event && *lhs.benchmark_event == *rhs.benchmark_event));
 }
 
 inline bool operator!=(const MiniBenchmarkEventT &lhs, const MiniBenchmarkEventT &rhs) {
@@ -3533,18 +4445,34 @@ inline bool operator!=(const MiniBenchmarkEventT &lhs, const MiniBenchmarkEventT
 }
 
 
+inline MiniBenchmarkEventT::MiniBenchmarkEventT(const MiniBenchmarkEventT &o)
+      : is_log_flushing_event(o.is_log_flushing_event),
+        best_acceleration_decision((o.best_acceleration_decision) ? new tflite::BestAccelerationDecisionT(*o.best_acceleration_decision) : nullptr),
+        initialization_failure((o.initialization_failure) ? new tflite::BenchmarkInitializationFailureT(*o.initialization_failure) : nullptr),
+        benchmark_event((o.benchmark_event) ? new tflite::BenchmarkEventT(*o.benchmark_event) : nullptr) {
+}
+
+inline MiniBenchmarkEventT &MiniBenchmarkEventT::operator=(MiniBenchmarkEventT o) FLATBUFFERS_NOEXCEPT {
+  std::swap(is_log_flushing_event, o.is_log_flushing_event);
+  std::swap(best_acceleration_decision, o.best_acceleration_decision);
+  std::swap(initialization_failure, o.initialization_failure);
+  std::swap(benchmark_event, o.benchmark_event);
+  return *this;
+}
+
 inline MiniBenchmarkEventT *MiniBenchmarkEvent::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
-  auto _o = new MiniBenchmarkEventT();
-  UnPackTo(_o, _resolver);
-  return _o;
+  auto _o = std::unique_ptr<MiniBenchmarkEventT>(new MiniBenchmarkEventT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
 }
 
 inline void MiniBenchmarkEvent::UnPackTo(MiniBenchmarkEventT *_o, const flatbuffers::resolver_function_t *_resolver) const {
   (void)_o;
   (void)_resolver;
   { auto _e = is_log_flushing_event(); _o->is_log_flushing_event = _e; }
-  { auto _e = best_acceleration_decision(); if (_e) _o->best_acceleration_decision = std::unique_ptr<tflite::BestAccelerationDecisionT>(_e->UnPack(_resolver)); }
-  { auto _e = initialization_failure(); if (_e) _o->initialization_failure = std::unique_ptr<tflite::BenchmarkInitializationFailureT>(_e->UnPack(_resolver)); }
+  { auto _e = best_acceleration_decision(); if (_e) { if(_o->best_acceleration_decision) { _e->UnPackTo(_o->best_acceleration_decision.get(), _resolver); } else { _o->best_acceleration_decision = std::unique_ptr<tflite::BestAccelerationDecisionT>(_e->UnPack(_resolver)); } } }
+  { auto _e = initialization_failure(); if (_e) { if(_o->initialization_failure) { _e->UnPackTo(_o->initialization_failure.get(), _resolver); } else { _o->initialization_failure = std::unique_ptr<tflite::BenchmarkInitializationFailureT>(_e->UnPack(_resolver)); } } }
+  { auto _e = benchmark_event(); if (_e) { if(_o->benchmark_event) { _e->UnPackTo(_o->benchmark_event.get(), _resolver); } else { _o->benchmark_event = std::unique_ptr<tflite::BenchmarkEventT>(_e->UnPack(_resolver)); } } }
 }
 
 inline flatbuffers::Offset<MiniBenchmarkEvent> MiniBenchmarkEvent::Pack(flatbuffers::FlatBufferBuilder &_fbb, const MiniBenchmarkEventT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
@@ -3558,11 +4486,162 @@ inline flatbuffers::Offset<MiniBenchmarkEvent> CreateMiniBenchmarkEvent(flatbuff
   auto _is_log_flushing_event = _o->is_log_flushing_event;
   auto _best_acceleration_decision = _o->best_acceleration_decision ? CreateBestAccelerationDecision(_fbb, _o->best_acceleration_decision.get(), _rehasher) : 0;
   auto _initialization_failure = _o->initialization_failure ? CreateBenchmarkInitializationFailure(_fbb, _o->initialization_failure.get(), _rehasher) : 0;
+  auto _benchmark_event = _o->benchmark_event ? CreateBenchmarkEvent(_fbb, _o->benchmark_event.get(), _rehasher) : 0;
   return tflite::CreateMiniBenchmarkEvent(
       _fbb,
       _is_log_flushing_event,
       _best_acceleration_decision,
-      _initialization_failure);
+      _initialization_failure,
+      _benchmark_event);
+}
+
+
+inline bool operator==(const ModelFileT &lhs, const ModelFileT &rhs) {
+  return
+      (lhs.filename == rhs.filename) &&
+      (lhs.fd == rhs.fd) &&
+      (lhs.offset == rhs.offset) &&
+      (lhs.length == rhs.length);
+}
+
+inline bool operator!=(const ModelFileT &lhs, const ModelFileT &rhs) {
+    return !(lhs == rhs);
+}
+
+
+inline ModelFileT *ModelFile::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
+  auto _o = std::unique_ptr<ModelFileT>(new ModelFileT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
+}
+
+inline void ModelFile::UnPackTo(ModelFileT *_o, const flatbuffers::resolver_function_t *_resolver) const {
+  (void)_o;
+  (void)_resolver;
+  { auto _e = filename(); if (_e) _o->filename = _e->str(); }
+  { auto _e = fd(); _o->fd = _e; }
+  { auto _e = offset(); _o->offset = _e; }
+  { auto _e = length(); _o->length = _e; }
+}
+
+inline flatbuffers::Offset<ModelFile> ModelFile::Pack(flatbuffers::FlatBufferBuilder &_fbb, const ModelFileT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
+  return CreateModelFile(_fbb, _o, _rehasher);
+}
+
+inline flatbuffers::Offset<ModelFile> CreateModelFile(flatbuffers::FlatBufferBuilder &_fbb, const ModelFileT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
+  (void)_rehasher;
+  (void)_o;
+  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const ModelFileT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
+  auto _filename = _o->filename.empty() ? 0 : _fbb.CreateString(_o->filename);
+  auto _fd = _o->fd;
+  auto _offset = _o->offset;
+  auto _length = _o->length;
+  return tflite::CreateModelFile(
+      _fbb,
+      _filename,
+      _fd,
+      _offset,
+      _length);
+}
+
+
+inline bool operator==(const BenchmarkStoragePathsT &lhs, const BenchmarkStoragePathsT &rhs) {
+  return
+      (lhs.storage_file_path == rhs.storage_file_path) &&
+      (lhs.data_directory_path == rhs.data_directory_path);
+}
+
+inline bool operator!=(const BenchmarkStoragePathsT &lhs, const BenchmarkStoragePathsT &rhs) {
+    return !(lhs == rhs);
+}
+
+
+inline BenchmarkStoragePathsT *BenchmarkStoragePaths::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
+  auto _o = std::unique_ptr<BenchmarkStoragePathsT>(new BenchmarkStoragePathsT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
+}
+
+inline void BenchmarkStoragePaths::UnPackTo(BenchmarkStoragePathsT *_o, const flatbuffers::resolver_function_t *_resolver) const {
+  (void)_o;
+  (void)_resolver;
+  { auto _e = storage_file_path(); if (_e) _o->storage_file_path = _e->str(); }
+  { auto _e = data_directory_path(); if (_e) _o->data_directory_path = _e->str(); }
+}
+
+inline flatbuffers::Offset<BenchmarkStoragePaths> BenchmarkStoragePaths::Pack(flatbuffers::FlatBufferBuilder &_fbb, const BenchmarkStoragePathsT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
+  return CreateBenchmarkStoragePaths(_fbb, _o, _rehasher);
+}
+
+inline flatbuffers::Offset<BenchmarkStoragePaths> CreateBenchmarkStoragePaths(flatbuffers::FlatBufferBuilder &_fbb, const BenchmarkStoragePathsT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
+  (void)_rehasher;
+  (void)_o;
+  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const BenchmarkStoragePathsT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
+  auto _storage_file_path = _o->storage_file_path.empty() ? 0 : _fbb.CreateString(_o->storage_file_path);
+  auto _data_directory_path = _o->data_directory_path.empty() ? 0 : _fbb.CreateString(_o->data_directory_path);
+  return tflite::CreateBenchmarkStoragePaths(
+      _fbb,
+      _storage_file_path,
+      _data_directory_path);
+}
+
+
+inline bool operator==(const MinibenchmarkSettingsT &lhs, const MinibenchmarkSettingsT &rhs) {
+  return
+      (lhs.settings_to_test == rhs.settings_to_test) &&
+      ((lhs.model_file == rhs.model_file) || (lhs.model_file && rhs.model_file && *lhs.model_file == *rhs.model_file)) &&
+      ((lhs.storage_paths == rhs.storage_paths) || (lhs.storage_paths && rhs.storage_paths && *lhs.storage_paths == *rhs.storage_paths));
+}
+
+inline bool operator!=(const MinibenchmarkSettingsT &lhs, const MinibenchmarkSettingsT &rhs) {
+    return !(lhs == rhs);
+}
+
+
+inline MinibenchmarkSettingsT::MinibenchmarkSettingsT(const MinibenchmarkSettingsT &o)
+      : model_file((o.model_file) ? new tflite::ModelFileT(*o.model_file) : nullptr),
+        storage_paths((o.storage_paths) ? new tflite::BenchmarkStoragePathsT(*o.storage_paths) : nullptr) {
+  settings_to_test.reserve(o.settings_to_test.size());
+  for (const auto &v : o.settings_to_test) { settings_to_test.emplace_back((v) ? new tflite::TFLiteSettingsT(*v) : nullptr); }
+}
+
+inline MinibenchmarkSettingsT &MinibenchmarkSettingsT::operator=(MinibenchmarkSettingsT o) FLATBUFFERS_NOEXCEPT {
+  std::swap(settings_to_test, o.settings_to_test);
+  std::swap(model_file, o.model_file);
+  std::swap(storage_paths, o.storage_paths);
+  return *this;
+}
+
+inline MinibenchmarkSettingsT *MinibenchmarkSettings::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
+  auto _o = std::unique_ptr<MinibenchmarkSettingsT>(new MinibenchmarkSettingsT());
+  UnPackTo(_o.get(), _resolver);
+  return _o.release();
+}
+
+inline void MinibenchmarkSettings::UnPackTo(MinibenchmarkSettingsT *_o, const flatbuffers::resolver_function_t *_resolver) const {
+  (void)_o;
+  (void)_resolver;
+  { auto _e = settings_to_test(); if (_e) { _o->settings_to_test.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { if(_o->settings_to_test[_i]) { _e->Get(_i)->UnPackTo(_o->settings_to_test[_i].get(), _resolver); } else { _o->settings_to_test[_i] = std::unique_ptr<tflite::TFLiteSettingsT>(_e->Get(_i)->UnPack(_resolver)); }; } } }
+  { auto _e = model_file(); if (_e) { if(_o->model_file) { _e->UnPackTo(_o->model_file.get(), _resolver); } else { _o->model_file = std::unique_ptr<tflite::ModelFileT>(_e->UnPack(_resolver)); } } }
+  { auto _e = storage_paths(); if (_e) { if(_o->storage_paths) { _e->UnPackTo(_o->storage_paths.get(), _resolver); } else { _o->storage_paths = std::unique_ptr<tflite::BenchmarkStoragePathsT>(_e->UnPack(_resolver)); } } }
+}
+
+inline flatbuffers::Offset<MinibenchmarkSettings> MinibenchmarkSettings::Pack(flatbuffers::FlatBufferBuilder &_fbb, const MinibenchmarkSettingsT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
+  return CreateMinibenchmarkSettings(_fbb, _o, _rehasher);
+}
+
+inline flatbuffers::Offset<MinibenchmarkSettings> CreateMinibenchmarkSettings(flatbuffers::FlatBufferBuilder &_fbb, const MinibenchmarkSettingsT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
+  (void)_rehasher;
+  (void)_o;
+  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const MinibenchmarkSettingsT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
+  auto _settings_to_test = _o->settings_to_test.size() ? _fbb.CreateVector<flatbuffers::Offset<tflite::TFLiteSettings>> (_o->settings_to_test.size(), [](size_t i, _VectorArgs *__va) { return CreateTFLiteSettings(*__va->__fbb, __va->__o->settings_to_test[i].get(), __va->__rehasher); }, &_va ) : 0;
+  auto _model_file = _o->model_file ? CreateModelFile(_fbb, _o->model_file.get(), _rehasher) : 0;
+  auto _storage_paths = _o->storage_paths ? CreateBenchmarkStoragePaths(_fbb, _o->storage_paths.get(), _rehasher) : 0;
+  return tflite::CreateMinibenchmarkSettings(
+      _fbb,
+      _settings_to_test,
+      _model_file,
+      _storage_paths);
 }
 
 }  // namespace tflite
diff --git a/tensorflow/lite/schema/schema_generated.h b/tensorflow/lite/schema/schema_generated.h
index 0a2b1ad6ba0..c541afc41bd 100755
--- a/tensorflow/lite/schema/schema_generated.h
+++ b/tensorflow/lite/schema/schema_generated.h
@@ -4052,10 +4052,10 @@ struct QuantizationParameters FLATBUFFERS_FINAL_CLASS : private flatbuffers::Tab
            verifier.VerifyVector(scale()) &&
            VerifyOffset(verifier, VT_ZERO_POINT) &&
            verifier.VerifyVector(zero_point()) &&
-           VerifyField<uint8_t>(verifier, VT_DETAILS_TYPE) &&
+           VerifyField<uint8_t>(verifier, VT_DETAILS_TYPE, 1) &&
            VerifyOffset(verifier, VT_DETAILS) &&
            VerifyQuantizationDetails(verifier, details(), details_type()) &&
-           VerifyField<int32_t>(verifier, VT_QUANTIZED_DIMENSION) &&
+           VerifyField<int32_t>(verifier, VT_QUANTIZED_DIMENSION, 4) &&
            verifier.EndTable();
   }
   QuantizationParametersT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -4396,12 +4396,12 @@ struct DimensionMetadata FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int8_t>(verifier, VT_FORMAT) &&
-           VerifyField<int32_t>(verifier, VT_DENSE_SIZE) &&
-           VerifyField<uint8_t>(verifier, VT_ARRAY_SEGMENTS_TYPE) &&
+           VerifyField<int8_t>(verifier, VT_FORMAT, 1) &&
+           VerifyField<int32_t>(verifier, VT_DENSE_SIZE, 4) &&
+           VerifyField<uint8_t>(verifier, VT_ARRAY_SEGMENTS_TYPE, 1) &&
            VerifyOffset(verifier, VT_ARRAY_SEGMENTS) &&
            VerifySparseIndexVector(verifier, array_segments(), array_segments_type()) &&
-           VerifyField<uint8_t>(verifier, VT_ARRAY_INDICES_TYPE) &&
+           VerifyField<uint8_t>(verifier, VT_ARRAY_INDICES_TYPE, 1) &&
            VerifyOffset(verifier, VT_ARRAY_INDICES) &&
            VerifySparseIndexVector(verifier, array_indices(), array_indices_type()) &&
            verifier.EndTable();
@@ -4493,6 +4493,10 @@ struct SparsityParametersT : public flatbuffers::NativeTable {
   std::vector<int32_t> traversal_order{};
   std::vector<int32_t> block_map{};
   std::vector<std::unique_ptr<tflite::DimensionMetadataT>> dim_metadata{};
+  SparsityParametersT() = default;
+  SparsityParametersT(const SparsityParametersT &o);
+  SparsityParametersT(SparsityParametersT&&) FLATBUFFERS_NOEXCEPT = default;
+  SparsityParametersT &operator=(SparsityParametersT o) FLATBUFFERS_NOEXCEPT;
 };
 
 struct SparsityParameters FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
@@ -4591,6 +4595,10 @@ struct TensorT : public flatbuffers::NativeTable {
   bool is_variable = false;
   std::unique_ptr<tflite::SparsityParametersT> sparsity{};
   std::vector<int32_t> shape_signature{};
+  TensorT() = default;
+  TensorT(const TensorT &o);
+  TensorT(TensorT&&) FLATBUFFERS_NOEXCEPT = default;
+  TensorT &operator=(TensorT o) FLATBUFFERS_NOEXCEPT;
 };
 
 struct Tensor FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
@@ -4634,13 +4642,13 @@ struct Tensor FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     return VerifyTableStart(verifier) &&
            VerifyOffset(verifier, VT_SHAPE) &&
            verifier.VerifyVector(shape()) &&
-           VerifyField<int8_t>(verifier, VT_TYPE) &&
-           VerifyField<uint32_t>(verifier, VT_BUFFER) &&
+           VerifyField<int8_t>(verifier, VT_TYPE, 1) &&
+           VerifyField<uint32_t>(verifier, VT_BUFFER, 4) &&
            VerifyOffset(verifier, VT_NAME) &&
            verifier.VerifyString(name()) &&
            VerifyOffset(verifier, VT_QUANTIZATION) &&
            verifier.VerifyTable(quantization()) &&
-           VerifyField<uint8_t>(verifier, VT_IS_VARIABLE) &&
+           VerifyField<uint8_t>(verifier, VT_IS_VARIABLE, 1) &&
            VerifyOffset(verifier, VT_SPARSITY) &&
            verifier.VerifyTable(sparsity()) &&
            VerifyOffset(verifier, VT_SHAPE_SIGNATURE) &&
@@ -4781,12 +4789,12 @@ struct Conv2DOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int8_t>(verifier, VT_PADDING) &&
-           VerifyField<int32_t>(verifier, VT_STRIDE_W) &&
-           VerifyField<int32_t>(verifier, VT_STRIDE_H) &&
-           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION) &&
-           VerifyField<int32_t>(verifier, VT_DILATION_W_FACTOR) &&
-           VerifyField<int32_t>(verifier, VT_DILATION_H_FACTOR) &&
+           VerifyField<int8_t>(verifier, VT_PADDING, 1) &&
+           VerifyField<int32_t>(verifier, VT_STRIDE_W, 4) &&
+           VerifyField<int32_t>(verifier, VT_STRIDE_H, 4) &&
+           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION, 1) &&
+           VerifyField<int32_t>(verifier, VT_DILATION_W_FACTOR, 4) &&
+           VerifyField<int32_t>(verifier, VT_DILATION_H_FACTOR, 4) &&
            verifier.EndTable();
   }
   Conv2DOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -4898,14 +4906,14 @@ struct Conv3DOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int8_t>(verifier, VT_PADDING) &&
-           VerifyField<int32_t>(verifier, VT_STRIDE_D) &&
-           VerifyField<int32_t>(verifier, VT_STRIDE_W) &&
-           VerifyField<int32_t>(verifier, VT_STRIDE_H) &&
-           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION) &&
-           VerifyField<int32_t>(verifier, VT_DILATION_D_FACTOR) &&
-           VerifyField<int32_t>(verifier, VT_DILATION_W_FACTOR) &&
-           VerifyField<int32_t>(verifier, VT_DILATION_H_FACTOR) &&
+           VerifyField<int8_t>(verifier, VT_PADDING, 1) &&
+           VerifyField<int32_t>(verifier, VT_STRIDE_D, 4) &&
+           VerifyField<int32_t>(verifier, VT_STRIDE_W, 4) &&
+           VerifyField<int32_t>(verifier, VT_STRIDE_H, 4) &&
+           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION, 1) &&
+           VerifyField<int32_t>(verifier, VT_DILATION_D_FACTOR, 4) &&
+           VerifyField<int32_t>(verifier, VT_DILATION_W_FACTOR, 4) &&
+           VerifyField<int32_t>(verifier, VT_DILATION_H_FACTOR, 4) &&
            verifier.EndTable();
   }
   Conv3DOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -5017,12 +5025,12 @@ struct Pool2DOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int8_t>(verifier, VT_PADDING) &&
-           VerifyField<int32_t>(verifier, VT_STRIDE_W) &&
-           VerifyField<int32_t>(verifier, VT_STRIDE_H) &&
-           VerifyField<int32_t>(verifier, VT_FILTER_WIDTH) &&
-           VerifyField<int32_t>(verifier, VT_FILTER_HEIGHT) &&
-           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION) &&
+           VerifyField<int8_t>(verifier, VT_PADDING, 1) &&
+           VerifyField<int32_t>(verifier, VT_STRIDE_W, 4) &&
+           VerifyField<int32_t>(verifier, VT_STRIDE_H, 4) &&
+           VerifyField<int32_t>(verifier, VT_FILTER_WIDTH, 4) &&
+           VerifyField<int32_t>(verifier, VT_FILTER_HEIGHT, 4) &&
+           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION, 1) &&
            verifier.EndTable();
   }
   Pool2DOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -5129,13 +5137,13 @@ struct DepthwiseConv2DOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Tab
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int8_t>(verifier, VT_PADDING) &&
-           VerifyField<int32_t>(verifier, VT_STRIDE_W) &&
-           VerifyField<int32_t>(verifier, VT_STRIDE_H) &&
-           VerifyField<int32_t>(verifier, VT_DEPTH_MULTIPLIER) &&
-           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION) &&
-           VerifyField<int32_t>(verifier, VT_DILATION_W_FACTOR) &&
-           VerifyField<int32_t>(verifier, VT_DILATION_H_FACTOR) &&
+           VerifyField<int8_t>(verifier, VT_PADDING, 1) &&
+           VerifyField<int32_t>(verifier, VT_STRIDE_W, 4) &&
+           VerifyField<int32_t>(verifier, VT_STRIDE_H, 4) &&
+           VerifyField<int32_t>(verifier, VT_DEPTH_MULTIPLIER, 4) &&
+           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION, 1) &&
+           VerifyField<int32_t>(verifier, VT_DILATION_W_FACTOR, 4) &&
+           VerifyField<int32_t>(verifier, VT_DILATION_H_FACTOR, 4) &&
            verifier.EndTable();
   }
   DepthwiseConv2DOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -5227,7 +5235,7 @@ struct ConcatEmbeddingsOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Ta
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_NUM_CHANNELS) &&
+           VerifyField<int32_t>(verifier, VT_NUM_CHANNELS, 4) &&
            VerifyOffset(verifier, VT_NUM_COLUMNS_PER_CHANNEL) &&
            verifier.VerifyVector(num_columns_per_channel()) &&
            VerifyOffset(verifier, VT_EMBEDDING_DIM_PER_CHANNEL) &&
@@ -5307,7 +5315,7 @@ struct LSHProjectionOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int8_t>(verifier, VT_TYPE) &&
+           VerifyField<int8_t>(verifier, VT_TYPE, 1) &&
            verifier.EndTable();
   }
   LSHProjectionOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -5369,9 +5377,9 @@ struct SVDFOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_RANK) &&
-           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION) &&
-           VerifyField<uint8_t>(verifier, VT_ASYMMETRIC_QUANTIZE_INPUTS) &&
+           VerifyField<int32_t>(verifier, VT_RANK, 4) &&
+           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION, 1) &&
+           VerifyField<uint8_t>(verifier, VT_ASYMMETRIC_QUANTIZE_INPUTS, 1) &&
            verifier.EndTable();
   }
   SVDFOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -5438,8 +5446,8 @@ struct RNNOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION) &&
-           VerifyField<uint8_t>(verifier, VT_ASYMMETRIC_QUANTIZE_INPUTS) &&
+           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION, 1) &&
+           VerifyField<uint8_t>(verifier, VT_ASYMMETRIC_QUANTIZE_INPUTS, 1) &&
            verifier.EndTable();
   }
   RNNOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -5506,9 +5514,9 @@ struct SequenceRNNOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<uint8_t>(verifier, VT_TIME_MAJOR) &&
-           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION) &&
-           VerifyField<uint8_t>(verifier, VT_ASYMMETRIC_QUANTIZE_INPUTS) &&
+           VerifyField<uint8_t>(verifier, VT_TIME_MAJOR, 1) &&
+           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION, 1) &&
+           VerifyField<uint8_t>(verifier, VT_ASYMMETRIC_QUANTIZE_INPUTS, 1) &&
            verifier.EndTable();
   }
   SequenceRNNOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -5585,10 +5593,10 @@ struct BidirectionalSequenceRNNOptions FLATBUFFERS_FINAL_CLASS : private flatbuf
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<uint8_t>(verifier, VT_TIME_MAJOR) &&
-           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION) &&
-           VerifyField<uint8_t>(verifier, VT_MERGE_OUTPUTS) &&
-           VerifyField<uint8_t>(verifier, VT_ASYMMETRIC_QUANTIZE_INPUTS) &&
+           VerifyField<uint8_t>(verifier, VT_TIME_MAJOR, 1) &&
+           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION, 1) &&
+           VerifyField<uint8_t>(verifier, VT_MERGE_OUTPUTS, 1) &&
+           VerifyField<uint8_t>(verifier, VT_ASYMMETRIC_QUANTIZE_INPUTS, 1) &&
            verifier.EndTable();
   }
   BidirectionalSequenceRNNOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -5670,10 +5678,10 @@ struct FullyConnectedOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Tabl
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION) &&
-           VerifyField<int8_t>(verifier, VT_WEIGHTS_FORMAT) &&
-           VerifyField<uint8_t>(verifier, VT_KEEP_NUM_DIMS) &&
-           VerifyField<uint8_t>(verifier, VT_ASYMMETRIC_QUANTIZE_INPUTS) &&
+           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION, 1) &&
+           VerifyField<int8_t>(verifier, VT_WEIGHTS_FORMAT, 1) &&
+           VerifyField<uint8_t>(verifier, VT_KEEP_NUM_DIMS, 1) &&
+           VerifyField<uint8_t>(verifier, VT_ASYMMETRIC_QUANTIZE_INPUTS, 1) &&
            verifier.EndTable();
   }
   FullyConnectedOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -5740,7 +5748,7 @@ struct SoftmaxOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<float>(verifier, VT_BETA) &&
+           VerifyField<float>(verifier, VT_BETA, 4) &&
            verifier.EndTable();
   }
   SoftmaxOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -5797,8 +5805,8 @@ struct ConcatenationOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_AXIS) &&
-           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION) &&
+           VerifyField<int32_t>(verifier, VT_AXIS, 4) &&
+           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION, 1) &&
            verifier.EndTable();
   }
   ConcatenationOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -5860,8 +5868,8 @@ struct AddOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION) &&
-           VerifyField<uint8_t>(verifier, VT_POT_SCALE_INT16) &&
+           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION, 1) &&
+           VerifyField<uint8_t>(verifier, VT_POT_SCALE_INT16, 1) &&
            verifier.EndTable();
   }
   AddOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -5918,7 +5926,7 @@ struct MulOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION) &&
+           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION, 1) &&
            verifier.EndTable();
   }
   MulOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -5970,7 +5978,7 @@ struct L2NormOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION) &&
+           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION, 1) &&
            verifier.EndTable();
   }
   L2NormOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -6037,10 +6045,10 @@ struct LocalResponseNormalizationOptions FLATBUFFERS_FINAL_CLASS : private flatb
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_RADIUS) &&
-           VerifyField<float>(verifier, VT_BIAS) &&
-           VerifyField<float>(verifier, VT_ALPHA) &&
-           VerifyField<float>(verifier, VT_BETA) &&
+           VerifyField<int32_t>(verifier, VT_RADIUS, 4) &&
+           VerifyField<float>(verifier, VT_BIAS, 4) &&
+           VerifyField<float>(verifier, VT_ALPHA, 4) &&
+           VerifyField<float>(verifier, VT_BETA, 4) &&
            verifier.EndTable();
   }
   LocalResponseNormalizationOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -6127,11 +6135,11 @@ struct LSTMOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION) &&
-           VerifyField<float>(verifier, VT_CELL_CLIP) &&
-           VerifyField<float>(verifier, VT_PROJ_CLIP) &&
-           VerifyField<int8_t>(verifier, VT_KERNEL_TYPE) &&
-           VerifyField<uint8_t>(verifier, VT_ASYMMETRIC_QUANTIZE_INPUTS) &&
+           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION, 1) &&
+           VerifyField<float>(verifier, VT_CELL_CLIP, 4) &&
+           VerifyField<float>(verifier, VT_PROJ_CLIP, 4) &&
+           VerifyField<int8_t>(verifier, VT_KERNEL_TYPE, 1) &&
+           VerifyField<uint8_t>(verifier, VT_ASYMMETRIC_QUANTIZE_INPUTS, 1) &&
            verifier.EndTable();
   }
   LSTMOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -6223,11 +6231,11 @@ struct UnidirectionalSequenceLSTMOptions FLATBUFFERS_FINAL_CLASS : private flatb
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION) &&
-           VerifyField<float>(verifier, VT_CELL_CLIP) &&
-           VerifyField<float>(verifier, VT_PROJ_CLIP) &&
-           VerifyField<uint8_t>(verifier, VT_TIME_MAJOR) &&
-           VerifyField<uint8_t>(verifier, VT_ASYMMETRIC_QUANTIZE_INPUTS) &&
+           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION, 1) &&
+           VerifyField<float>(verifier, VT_CELL_CLIP, 4) &&
+           VerifyField<float>(verifier, VT_PROJ_CLIP, 4) &&
+           VerifyField<uint8_t>(verifier, VT_TIME_MAJOR, 1) &&
+           VerifyField<uint8_t>(verifier, VT_ASYMMETRIC_QUANTIZE_INPUTS, 1) &&
            verifier.EndTable();
   }
   UnidirectionalSequenceLSTMOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -6324,12 +6332,12 @@ struct BidirectionalSequenceLSTMOptions FLATBUFFERS_FINAL_CLASS : private flatbu
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION) &&
-           VerifyField<float>(verifier, VT_CELL_CLIP) &&
-           VerifyField<float>(verifier, VT_PROJ_CLIP) &&
-           VerifyField<uint8_t>(verifier, VT_MERGE_OUTPUTS) &&
-           VerifyField<uint8_t>(verifier, VT_TIME_MAJOR) &&
-           VerifyField<uint8_t>(verifier, VT_ASYMMETRIC_QUANTIZE_INPUTS) &&
+           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION, 1) &&
+           VerifyField<float>(verifier, VT_CELL_CLIP, 4) &&
+           VerifyField<float>(verifier, VT_PROJ_CLIP, 4) &&
+           VerifyField<uint8_t>(verifier, VT_MERGE_OUTPUTS, 1) &&
+           VerifyField<uint8_t>(verifier, VT_TIME_MAJOR, 1) &&
+           VerifyField<uint8_t>(verifier, VT_ASYMMETRIC_QUANTIZE_INPUTS, 1) &&
            verifier.EndTable();
   }
   BidirectionalSequenceLSTMOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -6411,8 +6419,8 @@ struct ResizeBilinearOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Tabl
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<uint8_t>(verifier, VT_ALIGN_CORNERS) &&
-           VerifyField<uint8_t>(verifier, VT_HALF_PIXEL_CENTERS) &&
+           VerifyField<uint8_t>(verifier, VT_ALIGN_CORNERS, 1) &&
+           VerifyField<uint8_t>(verifier, VT_HALF_PIXEL_CENTERS, 1) &&
            verifier.EndTable();
   }
   ResizeBilinearOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -6474,8 +6482,8 @@ struct ResizeNearestNeighborOptions FLATBUFFERS_FINAL_CLASS : private flatbuffer
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<uint8_t>(verifier, VT_ALIGN_CORNERS) &&
-           VerifyField<uint8_t>(verifier, VT_HALF_PIXEL_CENTERS) &&
+           VerifyField<uint8_t>(verifier, VT_ALIGN_CORNERS, 1) &&
+           VerifyField<uint8_t>(verifier, VT_HALF_PIXEL_CENTERS, 1) &&
            verifier.EndTable();
   }
   ResizeNearestNeighborOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -6532,7 +6540,7 @@ struct CallOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<uint32_t>(verifier, VT_SUBGRAPH) &&
+           VerifyField<uint32_t>(verifier, VT_SUBGRAPH, 4) &&
            verifier.EndTable();
   }
   CallOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -6812,9 +6820,9 @@ struct SkipGramOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_NGRAM_SIZE) &&
-           VerifyField<int32_t>(verifier, VT_MAX_SKIP_SIZE) &&
-           VerifyField<uint8_t>(verifier, VT_INCLUDE_ALL_NGRAMS) &&
+           VerifyField<int32_t>(verifier, VT_NGRAM_SIZE, 4) &&
+           VerifyField<int32_t>(verifier, VT_MAX_SKIP_SIZE, 4) &&
+           VerifyField<uint8_t>(verifier, VT_INCLUDE_ALL_NGRAMS, 1) &&
            verifier.EndTable();
   }
   SkipGramOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -6876,7 +6884,7 @@ struct SpaceToDepthOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_BLOCK_SIZE) &&
+           VerifyField<int32_t>(verifier, VT_BLOCK_SIZE, 4) &&
            verifier.EndTable();
   }
   SpaceToDepthOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -6928,7 +6936,7 @@ struct DepthToSpaceOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_BLOCK_SIZE) &&
+           VerifyField<int32_t>(verifier, VT_BLOCK_SIZE, 4) &&
            verifier.EndTable();
   }
   DepthToSpaceOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -6985,8 +6993,8 @@ struct SubOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION) &&
-           VerifyField<uint8_t>(verifier, VT_POT_SCALE_INT16) &&
+           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION, 1) &&
+           VerifyField<uint8_t>(verifier, VT_POT_SCALE_INT16, 1) &&
            verifier.EndTable();
   }
   SubOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -7043,7 +7051,7 @@ struct DivOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION) &&
+           VerifyField<int8_t>(verifier, VT_FUSED_ACTIVATION_FUNCTION, 1) &&
            verifier.EndTable();
   }
   DivOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -7134,7 +7142,7 @@ struct EmbeddingLookupSparseOptions FLATBUFFERS_FINAL_CLASS : private flatbuffer
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int8_t>(verifier, VT_COMBINER) &&
+           VerifyField<int8_t>(verifier, VT_COMBINER, 1) &&
            verifier.EndTable();
   }
   EmbeddingLookupSparseOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -7191,8 +7199,8 @@ struct GatherOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_AXIS) &&
-           VerifyField<int32_t>(verifier, VT_BATCH_DIMS) &&
+           VerifyField<int32_t>(verifier, VT_AXIS, 4) &&
+           VerifyField<int32_t>(verifier, VT_BATCH_DIMS, 4) &&
            verifier.EndTable();
   }
   GatherOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -7366,7 +7374,7 @@ struct ReducerOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<uint8_t>(verifier, VT_KEEP_DIMS) &&
+           VerifyField<uint8_t>(verifier, VT_KEEP_DIMS, 1) &&
            verifier.EndTable();
   }
   ReducerOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -7480,7 +7488,7 @@ struct SplitOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_NUM_SPLITS) &&
+           VerifyField<int32_t>(verifier, VT_NUM_SPLITS, 4) &&
            verifier.EndTable();
   }
   SplitOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -7532,7 +7540,7 @@ struct SplitVOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_NUM_SPLITS) &&
+           VerifyField<int32_t>(verifier, VT_NUM_SPLITS, 4) &&
            verifier.EndTable();
   }
   SplitVOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -7604,11 +7612,11 @@ struct StridedSliceOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_BEGIN_MASK) &&
-           VerifyField<int32_t>(verifier, VT_END_MASK) &&
-           VerifyField<int32_t>(verifier, VT_ELLIPSIS_MASK) &&
-           VerifyField<int32_t>(verifier, VT_NEW_AXIS_MASK) &&
-           VerifyField<int32_t>(verifier, VT_SHRINK_AXIS_MASK) &&
+           VerifyField<int32_t>(verifier, VT_BEGIN_MASK, 4) &&
+           VerifyField<int32_t>(verifier, VT_END_MASK, 4) &&
+           VerifyField<int32_t>(verifier, VT_ELLIPSIS_MASK, 4) &&
+           VerifyField<int32_t>(verifier, VT_NEW_AXIS_MASK, 4) &&
+           VerifyField<int32_t>(verifier, VT_SHRINK_AXIS_MASK, 4) &&
            verifier.EndTable();
   }
   StridedSliceOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -7724,8 +7732,8 @@ struct CastOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int8_t>(verifier, VT_IN_DATA_TYPE) &&
-           VerifyField<int8_t>(verifier, VT_OUT_DATA_TYPE) &&
+           VerifyField<int8_t>(verifier, VT_IN_DATA_TYPE, 1) &&
+           VerifyField<int8_t>(verifier, VT_OUT_DATA_TYPE, 1) &&
            verifier.EndTable();
   }
   CastOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -7899,7 +7907,7 @@ struct ArgMaxOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int8_t>(verifier, VT_OUTPUT_TYPE) &&
+           VerifyField<int8_t>(verifier, VT_OUTPUT_TYPE, 1) &&
            verifier.EndTable();
   }
   ArgMaxOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -7951,7 +7959,7 @@ struct ArgMinOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int8_t>(verifier, VT_OUTPUT_TYPE) &&
+           VerifyField<int8_t>(verifier, VT_OUTPUT_TYPE, 1) &&
            verifier.EndTable();
   }
   ArgMinOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -8286,9 +8294,9 @@ struct TransposeConvOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int8_t>(verifier, VT_PADDING) &&
-           VerifyField<int32_t>(verifier, VT_STRIDE_W) &&
-           VerifyField<int32_t>(verifier, VT_STRIDE_H) &&
+           VerifyField<int8_t>(verifier, VT_PADDING, 1) &&
+           VerifyField<int32_t>(verifier, VT_STRIDE_W, 4) &&
+           VerifyField<int32_t>(verifier, VT_STRIDE_H, 4) &&
            verifier.EndTable();
   }
   TransposeConvOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -8389,7 +8397,7 @@ struct SparseToDenseOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<uint8_t>(verifier, VT_VALIDATE_INDICES) &&
+           VerifyField<uint8_t>(verifier, VT_VALIDATE_INDICES, 1) &&
            verifier.EndTable();
   }
   SparseToDenseOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -8519,7 +8527,7 @@ struct ShapeOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int8_t>(verifier, VT_OUT_TYPE) &&
+           VerifyField<int8_t>(verifier, VT_OUT_TYPE, 1) &&
            verifier.EndTable();
   }
   ShapeOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -8664,10 +8672,10 @@ struct FakeQuantOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<float>(verifier, VT_MIN) &&
-           VerifyField<float>(verifier, VT_MAX) &&
-           VerifyField<int32_t>(verifier, VT_NUM_BITS) &&
-           VerifyField<uint8_t>(verifier, VT_NARROW_RANGE) &&
+           VerifyField<float>(verifier, VT_MIN, 4) &&
+           VerifyField<float>(verifier, VT_MAX, 4) &&
+           VerifyField<int32_t>(verifier, VT_NUM_BITS, 4) &&
+           VerifyField<uint8_t>(verifier, VT_NARROW_RANGE, 1) &&
            verifier.EndTable();
   }
   FakeQuantOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -8739,8 +8747,8 @@ struct PackOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_VALUES_COUNT) &&
-           VerifyField<int32_t>(verifier, VT_AXIS) &&
+           VerifyField<int32_t>(verifier, VT_VALUES_COUNT, 4) &&
+           VerifyField<int32_t>(verifier, VT_AXIS, 4) &&
            verifier.EndTable();
   }
   PackOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -8836,7 +8844,7 @@ struct OneHotOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_AXIS) &&
+           VerifyField<int32_t>(verifier, VT_AXIS, 4) &&
            verifier.EndTable();
   }
   OneHotOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -9049,8 +9057,8 @@ struct UnpackOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_NUM) &&
-           VerifyField<int32_t>(verifier, VT_AXIS) &&
+           VerifyField<int32_t>(verifier, VT_NUM, 4) &&
+           VerifyField<int32_t>(verifier, VT_AXIS, 4) &&
            verifier.EndTable();
   }
   UnpackOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -9341,7 +9349,7 @@ struct LeakyReluOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<float>(verifier, VT_ALPHA) &&
+           VerifyField<float>(verifier, VT_ALPHA, 4) &&
            verifier.EndTable();
   }
   LeakyReluOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -9432,7 +9440,7 @@ struct MirrorPadOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int8_t>(verifier, VT_MODE) &&
+           VerifyField<int8_t>(verifier, VT_MODE, 1) &&
            verifier.EndTable();
   }
   MirrorPadOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -9484,7 +9492,7 @@ struct UniqueOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int8_t>(verifier, VT_IDX_OUT_TYPE) &&
+           VerifyField<int8_t>(verifier, VT_IDX_OUT_TYPE, 1) &&
            verifier.EndTable();
   }
   UniqueOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -9697,8 +9705,8 @@ struct ReverseSequenceOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Tab
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_SEQ_DIM) &&
-           VerifyField<int32_t>(verifier, VT_BATCH_DIM) &&
+           VerifyField<int32_t>(verifier, VT_SEQ_DIM, 4) &&
+           VerifyField<int32_t>(verifier, VT_BATCH_DIM, 4) &&
            verifier.EndTable();
   }
   ReverseSequenceOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -9877,8 +9885,8 @@ struct IfOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_THEN_SUBGRAPH_INDEX) &&
-           VerifyField<int32_t>(verifier, VT_ELSE_SUBGRAPH_INDEX) &&
+           VerifyField<int32_t>(verifier, VT_THEN_SUBGRAPH_INDEX, 4) &&
+           VerifyField<int32_t>(verifier, VT_ELSE_SUBGRAPH_INDEX, 4) &&
            verifier.EndTable();
   }
   IfOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -9935,7 +9943,7 @@ struct CallOnceOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_INIT_SUBGRAPH_INDEX) &&
+           VerifyField<int32_t>(verifier, VT_INIT_SUBGRAPH_INDEX, 4) &&
            verifier.EndTable();
   }
   CallOnceOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -9992,8 +10000,8 @@ struct WhileOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_COND_SUBGRAPH_INDEX) &&
-           VerifyField<int32_t>(verifier, VT_BODY_SUBGRAPH_INDEX) &&
+           VerifyField<int32_t>(verifier, VT_COND_SUBGRAPH_INDEX, 4) &&
+           VerifyField<int32_t>(verifier, VT_BODY_SUBGRAPH_INDEX, 4) &&
            verifier.EndTable();
   }
   WhileOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -10294,9 +10302,9 @@ struct BatchMatMulOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<uint8_t>(verifier, VT_ADJ_X) &&
-           VerifyField<uint8_t>(verifier, VT_ADJ_Y) &&
-           VerifyField<uint8_t>(verifier, VT_ASYMMETRIC_QUANTIZE_INPUTS) &&
+           VerifyField<uint8_t>(verifier, VT_ADJ_X, 1) &&
+           VerifyField<uint8_t>(verifier, VT_ADJ_Y, 1) &&
+           VerifyField<uint8_t>(verifier, VT_ASYMMETRIC_QUANTIZE_INPUTS, 1) &&
            verifier.EndTable();
   }
   BatchMatMulOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -10363,8 +10371,8 @@ struct CumsumOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<uint8_t>(verifier, VT_EXCLUSIVE) &&
-           VerifyField<uint8_t>(verifier, VT_REVERSE) &&
+           VerifyField<uint8_t>(verifier, VT_EXCLUSIVE, 1) &&
+           VerifyField<uint8_t>(verifier, VT_REVERSE, 1) &&
            verifier.EndTable();
   }
   CumsumOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -10509,9 +10517,9 @@ struct HashtableOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_TABLE_ID) &&
-           VerifyField<int8_t>(verifier, VT_KEY_DTYPE) &&
-           VerifyField<int8_t>(verifier, VT_VALUE_DTYPE) &&
+           VerifyField<int32_t>(verifier, VT_TABLE_ID, 4) &&
+           VerifyField<int8_t>(verifier, VT_KEY_DTYPE, 1) &&
+           VerifyField<int8_t>(verifier, VT_VALUE_DTYPE, 1) &&
            verifier.EndTable();
   }
   HashtableOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -10850,8 +10858,8 @@ struct RandomOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int64_t>(verifier, VT_SEED) &&
-           VerifyField<int64_t>(verifier, VT_SEED2) &&
+           VerifyField<int64_t>(verifier, VT_SEED, 8) &&
+           VerifyField<int64_t>(verifier, VT_SEED2, 8) &&
            verifier.EndTable();
   }
   RandomOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -10970,7 +10978,7 @@ struct GeluOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<uint8_t>(verifier, VT_APPROXIMATE) &&
+           VerifyField<uint8_t>(verifier, VT_APPROXIMATE, 1) &&
            verifier.EndTable();
   }
   GeluOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -11061,7 +11069,7 @@ struct UnsortedSegmentProdOptions FLATBUFFERS_FINAL_CLASS : private flatbuffers:
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int32_t>(verifier, VT_NUM_SEGMENTS) &&
+           VerifyField<int32_t>(verifier, VT_NUM_SEGMENTS, 4) &&
            verifier.EndTable();
   }
   UnsortedSegmentProdOptionsT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -11128,11 +11136,11 @@ struct OperatorCode FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<int8_t>(verifier, VT_DEPRECATED_BUILTIN_CODE) &&
+           VerifyField<int8_t>(verifier, VT_DEPRECATED_BUILTIN_CODE, 1) &&
            VerifyOffset(verifier, VT_CUSTOM_CODE) &&
            verifier.VerifyString(custom_code()) &&
-           VerifyField<int32_t>(verifier, VT_VERSION) &&
-           VerifyField<int32_t>(verifier, VT_BUILTIN_CODE) &&
+           VerifyField<int32_t>(verifier, VT_VERSION, 4) &&
+           VerifyField<int32_t>(verifier, VT_BUILTIN_CODE, 4) &&
            verifier.EndTable();
   }
   OperatorCodeT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -11608,17 +11616,17 @@ struct Operator FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<uint32_t>(verifier, VT_OPCODE_INDEX) &&
+           VerifyField<uint32_t>(verifier, VT_OPCODE_INDEX, 4) &&
            VerifyOffset(verifier, VT_INPUTS) &&
            verifier.VerifyVector(inputs()) &&
            VerifyOffset(verifier, VT_OUTPUTS) &&
            verifier.VerifyVector(outputs()) &&
-           VerifyField<uint8_t>(verifier, VT_BUILTIN_OPTIONS_TYPE) &&
+           VerifyField<uint8_t>(verifier, VT_BUILTIN_OPTIONS_TYPE, 1) &&
            VerifyOffset(verifier, VT_BUILTIN_OPTIONS) &&
            VerifyBuiltinOptions(verifier, builtin_options(), builtin_options_type()) &&
            VerifyOffset(verifier, VT_CUSTOM_OPTIONS) &&
            verifier.VerifyVector(custom_options()) &&
-           VerifyField<int8_t>(verifier, VT_CUSTOM_OPTIONS_FORMAT) &&
+           VerifyField<int8_t>(verifier, VT_CUSTOM_OPTIONS_FORMAT, 1) &&
            VerifyOffset(verifier, VT_MUTATING_VARIABLE_INPUTS) &&
            verifier.VerifyVector(mutating_variable_inputs()) &&
            VerifyOffset(verifier, VT_INTERMEDIATES) &&
@@ -12206,6 +12214,10 @@ struct SubGraphT : public flatbuffers::NativeTable {
   std::vector<int32_t> outputs{};
   std::vector<std::unique_ptr<tflite::OperatorT>> operators{};
   std::string name{};
+  SubGraphT() = default;
+  SubGraphT(const SubGraphT &o);
+  SubGraphT(SubGraphT&&) FLATBUFFERS_NOEXCEPT = default;
+  SubGraphT &operator=(SubGraphT o) FLATBUFFERS_NOEXCEPT;
 };
 
 struct SubGraph FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
@@ -12409,7 +12421,7 @@ struct Metadata FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     return VerifyTableStart(verifier) &&
            VerifyOffset(verifier, VT_NAME) &&
            verifier.VerifyString(name()) &&
-           VerifyField<uint32_t>(verifier, VT_BUFFER) &&
+           VerifyField<uint32_t>(verifier, VT_BUFFER, 4) &&
            verifier.EndTable();
   }
   MetadataT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -12484,7 +12496,7 @@ struct TensorMap FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
     return VerifyTableStart(verifier) &&
            VerifyOffset(verifier, VT_NAME) &&
            verifier.VerifyString(name()) &&
-           VerifyField<uint32_t>(verifier, VT_TENSOR_INDEX) &&
+           VerifyField<uint32_t>(verifier, VT_TENSOR_INDEX, 4) &&
            verifier.EndTable();
   }
   TensorMapT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -12542,6 +12554,10 @@ struct SignatureDefT : public flatbuffers::NativeTable {
   std::vector<std::unique_ptr<tflite::TensorMapT>> outputs{};
   std::string signature_key{};
   uint32_t subgraph_index = 0;
+  SignatureDefT() = default;
+  SignatureDefT(const SignatureDefT &o);
+  SignatureDefT(SignatureDefT&&) FLATBUFFERS_NOEXCEPT = default;
+  SignatureDefT &operator=(SignatureDefT o) FLATBUFFERS_NOEXCEPT;
 };
 
 struct SignatureDef FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
@@ -12575,7 +12591,7 @@ struct SignatureDef FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
            verifier.VerifyVectorOfTables(outputs()) &&
            VerifyOffset(verifier, VT_SIGNATURE_KEY) &&
            verifier.VerifyString(signature_key()) &&
-           VerifyField<uint32_t>(verifier, VT_SUBGRAPH_INDEX) &&
+           VerifyField<uint32_t>(verifier, VT_SUBGRAPH_INDEX, 4) &&
            verifier.EndTable();
   }
   SignatureDefT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
@@ -12653,6 +12669,10 @@ struct ModelT : public flatbuffers::NativeTable {
   std::vector<int32_t> metadata_buffer{};
   std::vector<std::unique_ptr<tflite::MetadataT>> metadata{};
   std::vector<std::unique_ptr<tflite::SignatureDefT>> signature_defs{};
+  ModelT() = default;
+  ModelT(const ModelT &o);
+  ModelT(ModelT&&) FLATBUFFERS_NOEXCEPT = default;
+  ModelT &operator=(ModelT o) FLATBUFFERS_NOEXCEPT;
 };
 
 struct Model FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
@@ -12694,7 +12714,7 @@ struct Model FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
   }
   bool Verify(flatbuffers::Verifier &verifier) const {
     return VerifyTableStart(verifier) &&
-           VerifyField<uint32_t>(verifier, VT_VERSION) &&
+           VerifyField<uint32_t>(verifier, VT_VERSION, 4) &&
            VerifyOffset(verifier, VT_OPERATOR_CODES) &&
            verifier.VerifyVector(operator_codes()) &&
            verifier.VerifyVectorOfTables(operator_codes()) &&
@@ -13005,6 +13025,20 @@ inline flatbuffers::Offset<DimensionMetadata> CreateDimensionMetadata(flatbuffer
       _array_indices);
 }
 
+inline SparsityParametersT::SparsityParametersT(const SparsityParametersT &o)
+      : traversal_order(o.traversal_order),
+        block_map(o.block_map) {
+  dim_metadata.reserve(o.dim_metadata.size());
+  for (const auto &v : o.dim_metadata) { dim_metadata.emplace_back((v) ? new tflite::DimensionMetadataT(*v) : nullptr); }
+}
+
+inline SparsityParametersT &SparsityParametersT::operator=(SparsityParametersT o) FLATBUFFERS_NOEXCEPT {
+  std::swap(traversal_order, o.traversal_order);
+  std::swap(block_map, o.block_map);
+  std::swap(dim_metadata, o.dim_metadata);
+  return *this;
+}
+
 inline SparsityParametersT *SparsityParameters::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
   auto _o = std::unique_ptr<SparsityParametersT>(new SparsityParametersT());
   UnPackTo(_o.get(), _resolver);
@@ -13037,6 +13071,29 @@ inline flatbuffers::Offset<SparsityParameters> CreateSparsityParameters(flatbuff
       _dim_metadata);
 }
 
+inline TensorT::TensorT(const TensorT &o)
+      : shape(o.shape),
+        type(o.type),
+        buffer(o.buffer),
+        name(o.name),
+        quantization((o.quantization) ? new tflite::QuantizationParametersT(*o.quantization) : nullptr),
+        is_variable(o.is_variable),
+        sparsity((o.sparsity) ? new tflite::SparsityParametersT(*o.sparsity) : nullptr),
+        shape_signature(o.shape_signature) {
+}
+
+inline TensorT &TensorT::operator=(TensorT o) FLATBUFFERS_NOEXCEPT {
+  std::swap(shape, o.shape);
+  std::swap(type, o.type);
+  std::swap(buffer, o.buffer);
+  std::swap(name, o.name);
+  std::swap(quantization, o.quantization);
+  std::swap(is_variable, o.is_variable);
+  std::swap(sparsity, o.sparsity);
+  std::swap(shape_signature, o.shape_signature);
+  return *this;
+}
+
 inline TensorT *Tensor::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
   auto _o = std::unique_ptr<TensorT>(new TensorT());
   UnPackTo(_o.get(), _resolver);
@@ -16312,6 +16369,25 @@ inline flatbuffers::Offset<Operator> CreateOperator(flatbuffers::FlatBufferBuild
       _intermediates);
 }
 
+inline SubGraphT::SubGraphT(const SubGraphT &o)
+      : inputs(o.inputs),
+        outputs(o.outputs),
+        name(o.name) {
+  tensors.reserve(o.tensors.size());
+  for (const auto &v : o.tensors) { tensors.emplace_back((v) ? new tflite::TensorT(*v) : nullptr); }
+  operators.reserve(o.operators.size());
+  for (const auto &v : o.operators) { operators.emplace_back((v) ? new tflite::OperatorT(*v) : nullptr); }
+}
+
+inline SubGraphT &SubGraphT::operator=(SubGraphT o) FLATBUFFERS_NOEXCEPT {
+  std::swap(tensors, o.tensors);
+  std::swap(inputs, o.inputs);
+  std::swap(outputs, o.outputs);
+  std::swap(operators, o.operators);
+  std::swap(name, o.name);
+  return *this;
+}
+
 inline SubGraphT *SubGraph::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
   auto _o = std::unique_ptr<SubGraphT>(new SubGraphT());
   UnPackTo(_o.get(), _resolver);
@@ -16435,6 +16511,23 @@ inline flatbuffers::Offset<TensorMap> CreateTensorMap(flatbuffers::FlatBufferBui
       _tensor_index);
 }
 
+inline SignatureDefT::SignatureDefT(const SignatureDefT &o)
+      : signature_key(o.signature_key),
+        subgraph_index(o.subgraph_index) {
+  inputs.reserve(o.inputs.size());
+  for (const auto &v : o.inputs) { inputs.emplace_back((v) ? new tflite::TensorMapT(*v) : nullptr); }
+  outputs.reserve(o.outputs.size());
+  for (const auto &v : o.outputs) { outputs.emplace_back((v) ? new tflite::TensorMapT(*v) : nullptr); }
+}
+
+inline SignatureDefT &SignatureDefT::operator=(SignatureDefT o) FLATBUFFERS_NOEXCEPT {
+  std::swap(inputs, o.inputs);
+  std::swap(outputs, o.outputs);
+  std::swap(signature_key, o.signature_key);
+  std::swap(subgraph_index, o.subgraph_index);
+  return *this;
+}
+
 inline SignatureDefT *SignatureDef::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
   auto _o = std::unique_ptr<SignatureDefT>(new SignatureDefT());
   UnPackTo(_o.get(), _resolver);
@@ -16470,6 +16563,34 @@ inline flatbuffers::Offset<SignatureDef> CreateSignatureDef(flatbuffers::FlatBuf
       _subgraph_index);
 }
 
+inline ModelT::ModelT(const ModelT &o)
+      : version(o.version),
+        description(o.description),
+        metadata_buffer(o.metadata_buffer) {
+  operator_codes.reserve(o.operator_codes.size());
+  for (const auto &v : o.operator_codes) { operator_codes.emplace_back((v) ? new tflite::OperatorCodeT(*v) : nullptr); }
+  subgraphs.reserve(o.subgraphs.size());
+  for (const auto &v : o.subgraphs) { subgraphs.emplace_back((v) ? new tflite::SubGraphT(*v) : nullptr); }
+  buffers.reserve(o.buffers.size());
+  for (const auto &v : o.buffers) { buffers.emplace_back((v) ? new tflite::BufferT(*v) : nullptr); }
+  metadata.reserve(o.metadata.size());
+  for (const auto &v : o.metadata) { metadata.emplace_back((v) ? new tflite::MetadataT(*v) : nullptr); }
+  signature_defs.reserve(o.signature_defs.size());
+  for (const auto &v : o.signature_defs) { signature_defs.emplace_back((v) ? new tflite::SignatureDefT(*v) : nullptr); }
+}
+
+inline ModelT &ModelT::operator=(ModelT o) FLATBUFFERS_NOEXCEPT {
+  std::swap(version, o.version);
+  std::swap(operator_codes, o.operator_codes);
+  std::swap(subgraphs, o.subgraphs);
+  std::swap(description, o.description);
+  std::swap(buffers, o.buffers);
+  std::swap(metadata_buffer, o.metadata_buffer);
+  std::swap(metadata, o.metadata);
+  std::swap(signature_defs, o.signature_defs);
+  return *this;
+}
+
 inline ModelT *Model::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
   auto _o = std::unique_ptr<ModelT>(new ModelT());
   UnPackTo(_o.get(), _resolver);
@@ -19246,6 +19367,11 @@ inline bool ModelBufferHasIdentifier(const void *buf) {
       buf, ModelIdentifier());
 }
 
+inline bool SizePrefixedModelBufferHasIdentifier(const void *buf) {
+  return flatbuffers::BufferHasIdentifier(
+      buf, ModelIdentifier(), true);
+}
+
 inline bool VerifyModelBuffer(
     flatbuffers::Verifier &verifier) {
   return verifier.VerifyBuffer<tflite::Model>(ModelIdentifier());
diff --git a/tensorflow/lite/tools/cmake/modules/flatbuffers.cmake b/tensorflow/lite/tools/cmake/modules/flatbuffers.cmake
index d9f1465c190..642856f360d 100644
--- a/tensorflow/lite/tools/cmake/modules/flatbuffers.cmake
+++ b/tensorflow/lite/tools/cmake/modules/flatbuffers.cmake
@@ -23,7 +23,7 @@ OverridableFetchContent_Declare(
   flatbuffers
   GIT_REPOSITORY https://github.com/google/flatbuffers
   # Sync with tensorflow/third_party/flatbuffers/workspace.bzl
-  GIT_TAG v2.0.5
+  GIT_TAG v2.0.6
   GIT_SHALLOW TRUE
   GIT_PROGRESS TRUE
   SOURCE_DIR "${CMAKE_BINARY_DIR}/flatbuffers"
diff --git a/third_party/flatbuffers/build_defs.bzl b/third_party/flatbuffers/build_defs.bzl
index 9fcdc712120..24630fc203b 100644
--- a/third_party/flatbuffers/build_defs.bzl
+++ b/third_party/flatbuffers/build_defs.bzl
@@ -439,7 +439,6 @@ def flatbuffer_py_library(
         include_paths = include_paths,
     )
 
-    # TODO(b/235550563): Remove the concatnation rule with 2.0.6 update.
     all_srcs_no_include = "{}_srcs_no_include".format(name)
     _gen_flatbuffer_srcs(
         name = all_srcs_no_include,
@@ -449,17 +448,10 @@ def flatbuffer_py_library(
         no_includes = True,
         include_paths = include_paths,
     )
-    concat_py_srcs = "{}_generated".format(name)
-    _concat_flatbuffer_py_srcs(
-        name = concat_py_srcs,
-        deps = [
-            ":{}".format(all_srcs_no_include),
-        ],
-    )
     native.py_library(
         name = name,
         srcs = [
-            ":{}".format(concat_py_srcs),
+            ":{}_generated.py".format(name),
         ],
         srcs_version = "PY3",
         deps = deps + [
